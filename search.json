[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis Estadístico con Ordenador de Datos Médicos",
    "section": "",
    "text": "Bienvenido!\n\nA quién va dirigido este libro\nEste libro de texto está dirigido a estudiantes de medicina, residentes y otros profesionales de la salud que deseen aprender a utilizar el lenguaje de programación R para realizar análisis estadísticos en medicina. También es adecuado para cualquier persona interesada en aprender a usar R para el análisis estadístico en general, con un enfoque en aplicaciones médicas.\nEste libro de texto pretende ser autocontenido y no requiere experiencia previa con el lenguaje de programación R. Sin embargo, asume que el lector tiene un conocimiento básico de matemáticas y estadística introductoria. Si el lector desea profundizar en este lenguaje de programación y en estadística, recomendamos los siguientes libros:\n\nUsing R for Introductory Statistics (2nd Edition)\n\nR for Data Science (2nd Edition)\n\nggplot2: Elegant Graphics for Data Analysis (3rd edition)\n\nPractical Statistics for Medical Research\n\n\n\nReproducibilidad y licencia\nThis textbook was made using Quarto which is an open-source scientific and technical publishing system built on Pandoc. To learn more about Quarto books visit https://quarto.org/docs/books.\nThe online version of the textbook is hosted by Netlify and the material is free to use for non-commercial purposes, and is licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 4.0 License.",
    "crumbs": [
      "Bienvenido!"
    ]
  },
  {
    "objectID": "TEMA-1.html",
    "href": "TEMA-1.html",
    "title": "1  TEMA 1: PRUEBAS DIAGNÓSTICAS Y CURVAS ROC",
    "section": "",
    "text": "1.1 Introducción\nEste tema usa material traducido del siguiente libro: https://practical-stats-med-r.netlify.app/\nCuando hayamos terminado este Capítulo, deberíamos ser capaces de:\nLas pruebas diagnósticas son necesarias para estimar la precisión de test y pruebas diagnósticas en la clínica médica.\nPor ejemplo, gracias a métodos estadísticos propios del ámbito de la bioestadística podemos estimar la precisión diagnóstica de la mamografía digital (prueba índice) en la detección del cáncer de mama, utilizando la histopatología como “estándar de oro”, en mujeres mayores de 40 años. Así mismo podemos estimar la probabilidad post-prueba del cáncer de mama cuando la mamografía digital es positiva o negativa dado el conocimiento previo de una probabilidad de cáncer pre-prueba.\nA lo largo del tema vamos a necesitar cargar los siguientes paquetes estadísticos: ggmosaic, epiR, pubh, TeachingDemos, scales, here y tidyverse. Si no los tenemos instalados, debemos instalarlos primero. Aquí hay un ejemplo de cómo instalar y cargar estos paquetes:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>TEMA 1: PRUEBAS DIAGNÓSTICAS Y CURVAS ROC</span>"
    ]
  },
  {
    "objectID": "TEMA-1.html#test-diagnósticos-en-tablas-de-contingencia-2x2",
    "href": "TEMA-1.html#test-diagnósticos-en-tablas-de-contingencia-2x2",
    "title": "1  TEMA 1: PRUEBAS DIAGNÓSTICAS Y CURVAS ROC",
    "section": "1.2 Test Diagnósticos en Tablas de contingencia 2x2",
    "text": "1.2 Test Diagnósticos en Tablas de contingencia 2x2\nGeneralmente, el estado de la enfermedad de un individuo es una variable dicotómica; el individuo tiene la enfermedad (\\(Resultado+\\)) o no tiene la enfermedad (\\(Resultado-\\)) según lo definido por el estándar de referencia (o “estándar de oro”). La prueba diagnóstica bajo evaluación (también denominada prueba índice) puede medirse con una variable dicotómica (por ejemplo, presencia o ausencia de anomalías mamarias mediante una mamografía) o una variable continua (por ejemplo, nivel de glucosa en ayunas para el diagnóstico de diabetes), que puede transformarse en una variable dicotómica eligiendo un valor de corte (umbral) óptimo que distinga los resultados de prueba positivos (\\(Prueba+\\)) de los negativos (\\(Prueba-\\))[1,2]\nSi la prueba índice da un resultado dicotómico para cada participante en un estudio, los datos pueden tabularse en una tabla de 2 x 2 del resultado de la prueba (\\(Prueba+\\), \\(Prueba-\\)) frente al estado de la enfermedad “verdadero” (\\(Resultado+\\), \\(Resultado-\\)). Por ejemplo, el resultado de la mamografía digital para diagnosticar cáncer de mama comparado con la biopsia/cirugía de “estándar de oro” e histopatología en 1220 mujeres con sospecha de cáncer de mama son los siguientes:\n\nUna tabla 2 × 2 que informa la clasificación cruzada de individuos por el resultado de la prueba índice y de referencia.\n\n\n\n\n\n\n\n\n\n\n\nResultado según el estándar de referencia\n\n\n\n\n\n\n\n\n\\(Resultado+\\) (Enfermedad presente)\n\\(Resultado-\\) (Enfermedad ausente)\nTotales\n\n\nResultado de la prueba índice\n\\(Prueba+\\)\nVP=890\nFP=110\nVP+FP=1000\n\n\n\n\\(Prueba-\\)\nFN=20\nVN=200\nVN+FN=220\n\n\n\nTotales\nVP+FN=910\nVN+FP=310\nN=1220 (VP+VN+FP+FN)\n\n\n\ndonde\nVP: verdadero positivo; prueba positiva y enfermedad presente (Prueba+ Resultado+)\nFP = falso positivo; prueba positiva y enfermedad ausente (Prueba+ Resultado-)\nFN = falso negativo; prueba negativa y enfermedad presente (Prueba- Resultado+)\nVN = verdadero negativo; prueba negativa y enfermedad ausente (Prueba- Resultado-)\n\n1.2.1 Medidas de precisión diagnóstica\nLa Sensibilidad (Se) de una prueba diagnóstica se refiere a la capacidad de la prueba para identificar correctamente a aquellos individuos con la enfermedad. Se define como la proporción de resultados de prueba verdaderos positivos entre los individuos que tienen la enfermedad [3].\nSe = \\(\\frac{VP}{VP+FN}=\\frac{890}{910}=0.978\\) o \\(97.8%\\)\nLa Especificidad (Sp) de una prueba diagnóstica se refiere a la capacidad de la prueba para identificar correctamente a aquellos pacientes sin la enfermedad. Se define como la proporción de resultados de prueba verdaderos negativos entre los individuos que no tienen la enfermedad.\nSp = \\(\\frac{VN}{VN+FP}=\\frac{200}{310}=0.645\\) o \\(64.5%\\)\nEl Valor predictivo positivo (VPP) es la probabilidad de que los individuos con un resultado positivo en la prueba diagnóstica realmente tengan la enfermedad. Se define como la proporción de resultados de prueba verdaderos positivos entre los individuos que tienen una prueba positiva.\nVPP = \\(\\frac{VP}{VP+FP}=\\frac{890}{1000}=0.890\\) o \\(89.0%\\)\nEl Valor predictivo negativo (VPN) es la probabilidad de que los individuos con un resultado negativo en la prueba diagnóstica estén realmente libres de la enfermedad. Se define como la proporción de resultados de prueba verdaderos negativos entre los individuos que tienen una prueba negativa.\nVPN = \\(\\frac{VN}{VN+FN}=\\frac{200}{220}=0.909\\) o \\(90.9%\\)\n\n\n1.2.2 La influencia de la prevalencia de la enfermedad en los valores predictivos\nLos valores predictivos positivos y negativos están influenciados por la prevalencia de la enfermedad en la población que se está examinando. El uso de la misma prueba en una población con una mayor prevalencia (por ejemplo, mujeres mayores de 55 años) aumenta el valor predictivo positivo. Por el contrario, una mayor prevalencia da como resultado una disminución del valor predictivo negativo. Por lo tanto, al considerar los valores predictivos de las pruebas diagnósticas o de cribado, debemos tener en cuenta la influencia de la prevalencia de la enfermedad [4].\nY otras medidas diagnósticas útiles son las siguientes:\nMás medidas de precisión diagnóstica\nLa Prevalencia aparente es la proporción de individuos con un resultado positivo en la prueba.\nPrevalencia aparente = \\(\\frac{VP + FP}{N}=\\frac{1000}{1220}=0.820\\) o \\(82.0%\\)\nLa Prevalencia verdadera es la proporción de individuos que están realmente enfermos.\nPrevalencia verdadera = \\(\\frac{VP + FN}{N}=\\frac{910}{1220}=0.746\\) o \\(74.6%\\)\nLa Razón de verosimilitud para un resultado de prueba positivo (RV+) es la verosimilitud (probabilidad) de que un individuo que tiene la enfermedad dé positivo dividida por la verosimilitud (probabilidad) de que un individuo que no tiene la enfermedad dé positivo. Se calcula como la sensibilidad dividida por 1 menos el valor de la especificidad [6].\nRV+ = \\(\\frac{Se}{1-Sp}=\\frac{0.978}{1-0.645}=\\frac{0.978}{0.355}= 2.755\\)\nLa Razón de verosimilitud para un resultado de prueba negativo (RV-) es la probabilidad de que un individuo que tiene la enfermedad dé negativo dividida por la probabilidad de que un individuo que no tiene la enfermedad dé negativo. Se calcula como 1 menos la sensibilidad dividida por el valor de la especificidad.\nRV- = \\(\\frac{1-Se}{Sp}=\\frac{1-0.978}{0.645}=\\frac{0.022}{0.645}= 0.034\\)\nLa Precisión diagnóstica (eficacia), expresada como una proporción de sujetos clasificados correctamente (VP+VN) entre todos los sujetos (N). La precisión diagnóstica se ve afectada por la prevalencia de la enfermedad.\nPrecisión = \\(\\frac{VP + VN}{N}=\\frac{890 + 200}{1220}=\\frac{1090}{1220}= 0.893\\) o \\(89.3%\\)%\nEn R:\n\ntb1 &lt;- as.table(\n  rbind(c(890, 110), c(20, 200))\n  )\n\ndimnames(tb1) &lt;- list(\n  Test = c(\"Test +\", \"Test -\"),\n  Outcome = c(\"Outcome +\", \"Outcome -\")\n)\n\ntb1\n\n        Outcome\nTest     Outcome + Outcome -\n  Test +       890       110\n  Test -        20       200\n\nepi.tests(tb1, digits=3)\n\n          Outcome +    Outcome -      Total\nTest +          890          110       1000\nTest -           20          200        220\nTotal           910          310       1220\n\nPoint estimates and 95% CIs:\n--------------------------------------------------------------\nApparent prevalence *                  0.820 (0.797, 0.841)\nTrue prevalence *                      0.746 (0.720, 0.770)\nSensitivity *                          0.978 (0.966, 0.987)\nSpecificity *                          0.645 (0.589, 0.698)\nPositive predictive value *            0.890 (0.869, 0.909)\nNegative predictive value *            0.909 (0.863, 0.944)\nPositive likelihood ratio              2.756 (2.371, 3.204)\nNegative likelihood ratio              0.034 (0.022, 0.053)\nFalse T+ proportion for true D- *      0.355 (0.302, 0.411)\nFalse T- proportion for true D+ *      0.022 (0.013, 0.034)\nFalse T+ proportion for T+ *           0.110 (0.091, 0.131)\nFalse T- proportion for T- *           0.091 (0.056, 0.137)\nCorrectly classified proportion *      0.893 (0.875, 0.910)\n--------------------------------------------------------------\n* Exact CIs\n\n\nA partir de esta tabla de contingencia, podemos crear un gráfico de mosaico básico.\n\n\n1.2.3 Gráfico de mosaico para una tabla 2x2\n\nmosaicplot(t(tb1), col = c(\"goldenrod1\", \"firebrick\"), \n           cex.axis = 0.9, main=NULL)\n\n\n\n\n\n\n\n\n\nepi.tests(tb1, digits = 3)\n\n          Outcome +    Outcome -      Total\nTest +          890          110       1000\nTest -           20          200        220\nTotal           910          310       1220\n\nPoint estimates and 95% CIs:\n--------------------------------------------------------------\nApparent prevalence *                  0.820 (0.797, 0.841)\nTrue prevalence *                      0.746 (0.720, 0.770)\nSensitivity *                          0.978 (0.966, 0.987)\nSpecificity *                          0.645 (0.589, 0.698)\nPositive predictive value *            0.890 (0.869, 0.909)\nNegative predictive value *            0.909 (0.863, 0.944)\nPositive likelihood ratio              2.756 (2.371, 3.204)\nNegative likelihood ratio              0.034 (0.022, 0.053)\nFalse T+ proportion for true D- *      0.355 (0.302, 0.411)\nFalse T- proportion for true D+ *      0.022 (0.013, 0.034)\nFalse T+ proportion for T+ *           0.110 (0.091, 0.131)\nFalse T- proportion for T- *           0.091 (0.056, 0.137)\nCorrectly classified proportion *      0.893 (0.875, 0.910)\n--------------------------------------------------------------\n* Exact CIs\n\n\n\n\n1.2.4 Teoremas de Probabilidad Total, Bayes y Valores predictivos o Probabilidad a Posteriori\nCuando se trata de un paciente individual, las medidas importantes no son la sensibilidad o la especificidad, sino los valores predictivos. Estos nos dicen la probabilidad de que un paciente con un resultado positivo (o negativo) en la prueba realmente tenga (o no tenga) la enfermedad. La clave para responder esta pregunta está en el teorema de Bayes. Primero vamos a definir algunos términos y luego proporcionamos una breve revisión del teorema de Bayes.\nProbabilidad previa (sinónimos: probabilidad pre-prueba, prevalencia) es la probabilidad de que el paciente tenga la enfermedad antes de una prueba diagnóstica particular. Combina todo el conocimiento sobre el paciente, incluida la historia del paciente, los hallazgos físicos, los resultados de pruebas diagnósticas previas y la prevalencia de la enfermedad en la población.\nProbabilidad a posteriori (probabilidad post-prueba, valor predictivo) es la probabilidad de enfermedad después de una prueba diagnóstica particular, que tiene en cuenta tanto la probabilidad previa como los resultados de la prueba.\nTeorema de Bayes Si A1, A2, …, y An son n eventos mutuamente excluyentes y exhaustivos, de modo que \\[P(A1 \\cup A2 \\cup \\dots \\cup A_{n}) = P(A1)+P(A2)+\\dots+P(A_{n}) = 1\\] Entonces el teorema de Bayes establece \\[P(A_{i} | B) = \\frac{P(B | A_{i})P(A_{i})}{P(B | A1)P(A1) + \\dots + P(B | A_{n})P(A_{n})}\\] para cada i, \\(1 \\le i \\le n\\).\nEn un entorno clínico, a menudo hay n = 2 eventos, como “enfermo” y “no enfermo”. La utilidad del teorema de Bayes radica en su capacidad para invertir las condiciones. Por ejemplo, calcular P(D+ \\(|\\) T+) a partir de P(T+ \\(|\\) D+) (la condición se invierte), aquí T+ = B y D+ = A1 en el teorema de Bayes.\nEn otras palabras, la probabilidad de que un paciente con un resultado positivo en la prueba esté realmente enfermo se puede calcular a partir de la probabilidad de que un paciente con la enfermedad tenga un resultado positivo en la prueba. Esto último es la sensibilidad de la prueba diagnóstica. Ahora la conexión entre nuestra pregunta sobre el estado de la enfermedad del paciente y las características de la prueba queda clara.\nLa pregunta se puede expresar matemáticamente:\n\\(P (D+ | T+) =\\) Probabilidad de que un paciente con un resultado positivo en la prueba realmente tenga la enfermedad. Esto se denomina el valor predictivo de una prueba positiva o valor predictivo positivo (VPP) y \\(P (D- | T-) =\\) Probabilidad de que un paciente con un resultado negativo en la prueba realmente no tenga la enfermedad. Esto se denomina el valor predictivo de una prueba negativa o valor predictivo negativo (VPN)\nSegún el teorema de Bayes,\n\\[PPV = P(D+ | T+) = \\frac{P(T+ | D+)P(D+)}{P(T+ | D+)P(D+) + P(T+ | D-)P(D-)}\\] y \\[NPV = P(D- | T-) = \\frac{P(T- | D-)P(D-)}{P(T- | D-)P(D-) + P(T- | D+)P(D+)}\\]\ndonde\n\\(P(D+)=\\) Probabilidad de que el paciente tenga la enfermedad antes de la prueba – probabilidad previa, (prevalencia, probabilidad pre-prueba) \\(P (D-) = 1 - P (D+),\\) \\(P (T+ | D+) =\\) Probabilidad condicional de verdadero positivo, sensibilidad, \\(P (T- | D-) =\\) Probabilidad condicional de verdadero negativo, especificidad, \\(P (T+ | D-) =\\) Probabilidad condicional de falso positivo = 1 - especificidad, \\(P (T- | D+) =\\) Probabilidad condicional de falso negativo = 1 – sensibilidad.\nTodos los términos en las ecuaciones (1) y (2) son necesarios. Excepto por la prevalencia, todos los demás términos están asociados con la prueba diagnóstica en sí. Los médicos juzgan la prevalencia probable (probabilidad pre-prueba) de la enfermedad en cuestión (para un grupo de pacientes con características similares al paciente particular que tienen delante) y aplican la sensibilidad y especificidad conocidas de la prueba diagnóstica (de estudios de investigación) para obtener la probabilidad post-prueba del paciente particular de tener la enfermedad en cuestión.\nLos intervalos de confianza para la sensibilidad, la especificidad y los valores predictivos se pueden calcular mediante los métodos habituales para proporciones binomiales. A menudo, los métodos basados en la aproximación normal a la distribución binomial (por ejemplo, IC del 95%: p \\(\\pm\\) 1.96 \\(\\sqrt{(pq/N)}\\)) serán inexactos debido a su simetría, y los métodos exactos u otras aproximaciones serán mejores, como por ejemplo binom.test y fisher.test en R.\nLEER: Altman & Bland. Pruebas diagnósticas 2: valores predictivos [4]\n\n\n1.2.5 Las Razones de Verosimilitud (RV)\nLa razón de verosimilitud (RV), junto con la sensibilidad y la especificidad, puede considerarse una propiedad de la propia prueba que no cambia con la prevalencia de la enfermedad.\nEn nuestro ejemplo, RV+ = 2.756, lo que significa que un resultado positivo en la mamografía digital es aproximadamente 2.8 veces más probable de ser un verdadero positivo que un falso positivo.\nDe manera similar, RV- = 0.034, lo que significa que un resultado negativo en la mamografía digital es aproximadamente 0.034 veces más probable de ser un falso negativo que un verdadero negativo. Esto también puede interpretarse como: una mujer sin cáncer de mama tiene aproximadamente 29.4 (= 1/0.034) veces más probabilidades de tener un resultado negativo en la mamografía digital que una mujer con cáncer de mama.\nEn la práctica clínica, una RV+ más alta es deseable para las pruebas utilizadas para “confirmar” una enfermedad, mientras que una RV- más baja es preferible para las pruebas utilizadas para “descartar” la posibilidad de que el individuo tenga la enfermedad.\n\n\n1.2.6 Aplicación de las RV (revisando la probabilidad de enfermedad)\nPrimero necesitamos recordar la definición de odds.\nOdds es una razón de probabilidades. Para ser coherentes con la primera sección, sea D+ el evento de que un paciente tiene una enfermedad particular y T el resultado de la prueba (puede ser T+ o T-). La probabilidad de que el paciente tenga la enfermedad es P(D+) y de no tener la enfermedad es P(D-). Entonces, el odds a favor de la enfermedad es la razón de la probabilidad de tener la enfermedad a la probabilidad de no tener la enfermedad\n\\(Odds\\) a favor de la enfermedad = \\(P(D+) / P(D-)\\).\nA diferencia de la probabilidad, el odds no necesita estar entre 0 y 1. Puede ser cualquier número no negativo.\nLa razón de verosimilitud es una razón de probabilidades condicionales de tener los resultados de la prueba (condicionadas a los escenarios de tener la enfermedad y no tener la enfermedad), una forma alternativa de evaluar el rendimiento de una prueba diagnóstica.\nSi P(D+) es la probabilidad previa, entonces el odds definido anteriormente es el odds previo. De manera similar, la razón de probabilidades posteriores se denomina odds posterior. A partir de este punto, omitiremos la frase “a favor de la enfermedad”. A menos que se indique lo contrario, el odds se refiere al odds a favor de la enfermedad.\n\\(\\text{odds posterior = odds previo} \\times \\text{razón de verosimilitud}\\).\nLa razón por la que agregamos deliberadamente el concepto de razón de verosimilitud es para relacionar directamente la sensibilidad y la especificidad con el odds posterior, a partir del cual se puede calcular la probabilidad posterior. La razón de verosimilitud modifica el odds previo en odds posterior. La cantidad en que cambiarán los odds depende de la precisión (sensibilidad y especificidad) de la prueba.\nSi T es positivo, entonces,\n\\(RV+ = \\frac{P(T+ | D+)}{P(T+ | D-)} = \\frac{Sensibilidad}{1 - Especificidad}\\).\nEsto evalúa cuánto más probable es que ocurra un resultado positivo en una persona con la enfermedad que en una persona sin la enfermedad.\nSi T es negativo, entonces,\n\\(RV- = \\frac{P(T- | D+)}{P(T- | D-)} = \\frac{1 - Sensibilidad}{Especificidad}\\).\nEvalúa cuánto más probable es que ocurra un resultado negativo en una persona sin la enfermedad que en una persona con la enfermedad.\nUna vez que conocemos el odds previo, la calidad de la prueba y el resultado de la prueba, el odds posterior se puede obtener de la ecuación anterior, y por lo tanto se puede estimar la probabilidad posterior.\nLas razones de verosimilitud positivas (RV+) corresponden a las pendientes de la curva ROC (se discutirá a continuación). La pendiente de la curva ROC representa el cambio en la sensibilidad por un cambio infinitesimal en el porcentaje de falsos positivos.\n\n\n1.2.7 Probabilidad post-prueba y el Nomograma de Fagan\nEl Nomograma de Fagan es una herramienta gráfica que utiliza las razones de verosimilitud para estimar la probabilidad post-prueba de una enfermedad dada una probabilidad pre-prueba y el resultado de una prueba diagnóstica. Fue desarrollado por el Dr. Terry Fagan en la década de 1970 y es ampliamente utilizado en medicina clínica para ayudar a los médicos a interpretar los resultados de las pruebas diagnósticas. Para calcular la probabilidad post-prueba sin utilizar el teorema de Bayes directamente, podemos usar el Nomograma de Fagan. El nomograma de Fagan nos permite convertir las probabilidades pre-prueba en probabilidades post-prueba sin necesidad de usar odds.\nEl odds pre-prueba se computa a partir de la probabilidad pre-prueba (prevalencia) utilizando la fórmula: \\(odds \\ pre \\text{-} prueba = \\frac{probabilidad \\ pre \\text{-} prueba}{1 - probabilidad \\ pre \\text{-} prueba}\\)\nEl odds pre-prueba de un diagnóstico particular, multiplicado por la razón de verosimilitud de la prueba diagnóstica, determina el odds post-prueba.\nPor lo tanto, \\(odds \\ post \\text{-} prueba = RV \\times odds \\ pre \\text{-} prueba\\)\nEl odds post-prueba proporcionan una estimación actualizada del odds de que el paciente tenga la condición o enfermedad después de tener en cuenta el resultado de la prueba diagnóstica. Si el resultado de la prueba es positivo, usamos la RV+ para este cálculo. Si el resultado de la prueba es negativo, usamos la RV- en su lugar. En ambos escenarios, el odds se refiere al odds a favor de que la enfermedad esté presente.\nLa probabilidad post-prueba se puede derivar del odds post-prueba utilizando la fórmula: \\(probabilidad \\ post \\text{-} prueba = \\frac{odds \\ post \\text{-} prueba}{odds \\ post \\text{-} prueba + 1}\\)\nLa RV se utiliza comúnmente en la toma de decisiones basada en el Teorema de Bayes. La RV+ nos dice cuánto aumentan los odds de que la condición o enfermedad esté presente dado un resultado positivo en la prueba.\n\nRV+ mayor que 1: Aumenta los odds post-prueba.\nRV+ de 1: No hay cambio en los odds post-prueba (los odds post-prueba son iguales a los odds pre-prueba).\n\nEl nomograma suele consistir en tres escalas paralelas que representan la probabilidad pre-prueba, la razón de verosimilitud y la probabilidad post-prueba. Podemos estimar visualmente la probabilidad post-prueba de un resultado de diagnóstico positivo trazando una línea desde la probabilidad pre-prueba conocida, a través de la RV+ y leyendo la probabilidad post-prueba.\nSupongamos que la prevalencia (probabilidad pre-prueba) de cáncer de mama en una población específica de mujeres mayores de 40 años es del 74.6%. ¿Cuál es la probabilidad post-prueba de cáncer de mama para esta población cuando la mamografía digital es positiva?\nEn R:\n\nfagan.plot(probs.pre.test = 0.746, LR = 2.756)\n\n\n\n\n\n\n\nFigure 1.1: El impacto de un resultado positivo de mamografía digital con una RV+ de 2.76 en la probabilidad post-prueba de una paciente para cáncer de mama, partiendo de una probabilidad pre-prueba inicial del 78% en el Nomograma de Fagan.\n\n\n\n\n\nLa RV- nos dice cuánto disminuyen los odds de que la condición o enfermedad esté presente dado un resultado negativo en la prueba.\n\nRV- menor que 1: Disminuye los odds post-prueba.\nRV- de 1: No hay cambio en la probabilidad (los odds post-prueba son iguales a los odds pre-prueba).\n\n¿Cuál es la probabilidad post-prueba de cáncer de mama para la misma población cuando la mamografía digital es negativa?\n\\(odds \\ post \\text{-} prueba = RV\\text{-} \\times odds \\ pre \\text{-} prueba = 0.034 \\times 3.55 = 0.1207\\)\nLa odds post prueba es 0.1207. Para convertir esto en probabilidad post-prueba, usamos la fórmula que se deriva facilmente de la definición de odds: \\(odds = \\frac{probabilidad}{1 - probabilidad}\\), entonces \\(probabilidad = \\frac{odds}{odds + 1}\\)\n\\(probabilidad \\ post \\text{-} prueba = \\frac{odds \\ post \\text{-} prueba}{odds \\ post \\text{-} prueba + 1} = \\frac{0.1207}{0.1207 + 1} = \\frac{0.1207}{1.1207} = 0.1077 \\ o \\ 10.77%\\)\nEn R:\n\nfagan.plot(probs.pre.test = 0.746, LR = 0.034)\n\n\n\n\n\n\n\nFigure 1.2: El impacto de un resultado negativo de mamografía digital con una RV- de 0.034 en la probabilidad post-prueba de una paciente para cáncer de mama, partiendo de una probabilidad pre-prueba inicial del 74.6% en el Nomograma de Fagan.\n\n\n\n\n\nTambién podemos usar las funciones epi.nomogram() y nomogrammer() que nos permiten calcular la probabilidad post-prueba y trazar nomogramas de Fagan con {ggplot2}, respectivamente:\n\nepi.nomogram(se = NA, \n             sp = NA, \n             lr = c(2.756, 0.034),\n             pre.pos = 0.746,\n             verbose = FALSE)\n\nGiven a positive test result, the post-test probability of being outcome positive is 0.89 \nGiven a negative test result, the post-test probability of being outcome positive is 0.09 \n\n# nomogrammer es una función de R que crea un nomograma de Fagan\nsource(\"nomogrammer.r\")\n\nnomogrammer(Prevalence = 0.746,\n            Plr = 2.756,\n            Nlr = 0.034,\n            Detail = TRUE,\n            NullLine = TRUE)\n\n\n\n\n\n\n\nFigure 1.3: El impacto de un resultado positivo (línea azul) y negativo (línea roja) de mamografía digital con una RV+ de 2.756 y una RV- de 0.034 en la probabilidad post-prueba de una paciente para cáncer de mama, respectivamente, partiendo de una probabilidad pre-prueba inicial del 74.6% en el Nomograma de Fagan. La línea gris discontinua que va desde la probabilidad previa a través de RV = 1 ilustra la probabilidad posterior si se mantuviera sin cambios.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>TEMA 1: PRUEBAS DIAGNÓSTICAS Y CURVAS ROC</span>"
    ]
  },
  {
    "objectID": "TEMA-1.html#receiver-operating-characteristic-roc-curve",
    "href": "TEMA-1.html#receiver-operating-characteristic-roc-curve",
    "title": "1  TEMA 1: PRUEBAS DIAGNÓSTICAS Y CURVAS ROC",
    "section": "1.3 Receiver Operating Characteristic (ROC) curve",
    "text": "1.3 Receiver Operating Characteristic (ROC) curve\nCuando el resultado de una prueba diagnóstica se mide en una escala continua, la sensibilidad y la especificidad varían con diferentes puntos de corte (umbrales). Por lo tanto, debe seleccionarse un punto de corte conveniente para calcular las medidas de precisión diagnóstica de la prueba. El análisis de la curva de la característica operativa del receptor (ROC) puede utilizarse para ayudar en esta decisión [2].\nPuede encontrar los siguientes sitios web útiles al estudiar las curvas ROC:\n-http://www.anaesthetist.com/mnm/stats/roc/Findex.htm\n-http://gim.unmc.edu/dxtests/Default.htm\nEs deseable que una prueba diagnóstica tenga alta sensibilidad y también alta especificidad. En otras palabras, nos gustaría que el resultado de la prueba se acercara lo más posible a lo ideal: un resultado positivo significa “enfermo” y un resultado negativo significa “no enfermo”. Desafortunadamente, existe una compensación entre sensibilidad y especificidad: a medida que la sensibilidad aumenta, la especificidad disminuye, y viceversa. La relación entre sensibilidad y especificidad en una prueba diagnóstica es análoga a la relación entre el error tipo I y el error tipo II en las pruebas de hipótesis.\nUna curva ROC es una representación gráfica que muestra la capacidad diagnóstica de una prueba, o sistema de clasificación binaria, al variar su umbral de discriminación. La curva traza la Tasa de Verdaderos Positivos (TVP) frente a la Tasa de Falsos Positivos (TFP) en distintos umbrales. La TVP también se conoce como sensibilidad, y la TFP se calcula como 1 - especificidad.\n\nSensibilidad (TVP): La proporción de casos positivos reales que son correctamente identificados.\n\\[Sensibilidad = \\frac{Verdaderos\\;Positivos}{Verdaderos\\;Positivos + Falsos\\;Negativos}\\]\nEspecificidad: La proporción de casos negativos reales que son correctamente identificados.\n\\[Especificidad = \\frac{Verdaderos\\;Negativos}{Verdaderos\\;Negativos + Falsos\\;Positivos}\\]\nTasa de Falsos Positivos (TFP): La proporción de casos negativos reales que son incorrectamente identificados como positivos.\n\\[TFP = 1 - Especificidad = \\frac{Falsos\\;Positivos}{Verdaderos\\;Negativos + Falsos\\;Positivos}\\]\n\n\n1.3.1 ¿Cómo se construye?\n\nUna prueba diagnóstica continua proporciona una puntuación numérica. Para cada valor de puntuación posible, se establece un umbral.\nLos puntos de datos con puntuaciones por encima del umbral se clasifican como “positivos”, y aquellos por debajo se clasifican como “negativos”.\nPara cada umbral, se calculan la sensibilidad y la especificidad (y por lo tanto, la TFP).\nEstos pares (TFP, Sensibilidad) se grafican. Una curva continua se forma al conectar estos puntos.\n\nUna prueba perfecta tendría un punto en la esquina superior izquierda del gráfico, con una sensibilidad de 1 y una TFP de 0. Esto significa que tiene una tasa de verdaderos positivos del 100% y una tasa de falsos positivos del 0%. Una prueba inútil seguiría la línea diagonal de (0,0) a (1,1), lo que significa que su capacidad para distinguir entre casos positivos y negativos no es mejor que el azar.\n\n\n1.3.2 Interpretación del AUC\nEl AUC (Area Under the Curve o Área Bajo la Curva) es un valor escalar único que representa el rendimiento diagnóstico general de una prueba. Es el área debajo de la curva ROC, con un rango de 0 a 1. Un valor de AUC más alto indica una prueba con mejor rendimiento.\n\nAUC = 1.0: Prueba perfecta. Distingue perfectamente entre casos positivos y negativos.\nAUC \\(\\ge\\) 0.9: Prueba excelente. Muy precisa en sus predicciones.\n0.8 \\(\\le\\) AUC &lt; 0.9: Prueba buena. Generalmente considerada una herramienta diagnóstica útil y confiable.\n0.7 \\(\\le\\) AUC &lt; 0.8: Prueba aceptable/regular. Tiene algún valor diagnóstico, pero con una mayor probabilidad de errores de clasificación.\n0.6 \\(\\le\\) AUC &lt; 0.7: Prueba deficiente. Valor diagnóstico limitado.\nAUC = 0.5: Prueba inútil. Las predicciones no son mejores que el azar (como lanzar una moneda).\n\nEl área bajo la curva ROC mide la discriminación, es decir, la capacidad de la prueba para clasificar correctamente a aquellos con y sin la enfermedad. Supongamos que conocemos el estado de cada paciente con respecto a la enfermedad. El área bajo una curva ROC es la proporción de pares de pacientes seleccionados aleatoriamente (uno enfermo, uno no enfermo) que son correctamente clasificados (ordenados) por la prueba. El área bajo la curva ROC es una medida global de la precisión de la prueba. Alternativamente, el área bajo la curva ROC puede interpretarse como la sensibilidad promedio en todas las posibles especificidades.\nLas curvas ROC se utilizan en muchas otras situaciones además de las pruebas de diagnóstico clínico; una de ellas es la evaluación de la adecuación de un modelo de regresión logística, por ejemplo. Existen muchas herramientas de software para el análisis ROC, utilizando lenguajes de una variedad de áreas de contenido. Los métodos habituales para las pruebas de diagnóstico clínico se basan en el artículo clásico: Hanley JA, McNeil BJ. The meaning and use of the area under the receiver operating characteristic (ROC) curve. Radiology 1982; 143: 29-36 [7].\n\n\n1.3.3 Encontrar un Punto de Corte Apropiado\nEl punto más cercano a la esquina superior izquierda de la curva ROC a veces se elige como punto de corte porque optimiza la sensibilidad y la especificidad. Sin embargo, la tarea de encontrar un punto de corte apropiado a veces es más complicada y requiere juicio clínico. Deben tenerse en cuenta factores como el costo y el beneficio. Por ejemplo, cuando el costo de un resultado falso positivo es alto (como una cirugía innecesaria), queremos que la prueba sea más específica (alta especificidad); cuando la situación se invierte, queremos que la prueba sea más sensible (alta sensibilidad).\nEl índice de Youden es una métrica comúnmente utilizada para encontrar el punto de corte óptimo en una curva ROC. Se define como: \\[J = Sensibilidad + Especificidad - 1\\] El índice de Youden varía entre 0 y 1, donde 1 indica una prueba perfecta (sensibilidad y especificidad ambas iguales a 1), y 0 indica una prueba que no tiene valor diagnóstico (sensibilidad y especificidad ambas iguales a 0.5). El punto de corte que maximiza el índice de Youden es a menudo considerado como el punto óptimo, ya que equilibra la sensibilidad y la especificidad.\nEl paquete pROC en R proporciona una función conveniente coords() para encontrar el punto de corte óptimo basado en varios criterios, incluido el índice de Youden. En R puedes usar el siguiente código para encontrar el punto de corte óptimo:\n\nlibrary(pROC)\nset.seed(123) # para reproducibilidad\n\n# 1. Simulación de datos\n# Estado real de los sujetos (0 = control, 1 = caso)\ntrue_status &lt;- rbinom(100, 1, 0.5)\n\n# Puntuaciones para la prueba diagnóstica\n# Los casos (true_status = 1) tienen puntuaciones más altas en promedio\nscores &lt;- rnorm(100, mean = ifelse(true_status == 1, 1, 0), sd = 1)\n\n# 2. Creación y cálculo de la curva ROC\n# 'roc' crea el objeto de la curva ROC\nroc_obj &lt;- roc(true_status, scores)\n\n# 3. Visualización y análisis\n# Graficar la curva ROC con un título más descriptivo\nplot(roc_obj,\n     main = \"Curva ROC para la prueba diagnóstica\",\n     xlab = \"Tasa de Falsos Positivos (1 - Especificidad)\",\n     ylab = \"Tasa de Verdaderos Positivos (Sensibilidad)\",\n     col = \"blue\", # Color de la línea\n     lwd = 2) # Grosor de la línea\n\n# Calcular y mostrar el valor del Área Bajo la Curva (AUC)\nauc_value &lt;- auc(roc_obj)\nlegend(\"bottomright\",\n       legend = paste(\"AUC =\", round(auc_value, 2)),\n       bty = \"n\", # Sin caja alrededor de la leyenda\n       cex = 1.2)\n\n# 4. Encontrar y graficar el punto de corte óptimo\n# Encontrar las coordenadas del punto de corte óptimo usando el índice de Youden\noptimal_coords &lt;- coords(roc_obj, \"best\", ret = c(\"specificity\", \"sensitivity\", \"threshold\"), best.method = \"youden\")\noptimal_specificity &lt;- optimal_coords[\"specificity\"]\noptimal_sensitivity &lt;- optimal_coords[\"sensitivity\"]\noptimal_threshold &lt;- optimal_coords[\"threshold\"]\n\n# Graficar el punto óptimo en la curva\npoints(x = optimal_specificity, y = optimal_sensitivity, col = \"red\", pch = 19, cex = 1.5)\n\n# Añadir una etiqueta al punto óptimo\ntext(x = 1 - optimal_specificity + 0.1, y = optimal_sensitivity,\n     labels = paste(\"Umbral óptimo:\", round(optimal_threshold, 2)),\n     pos = 4, # Posición del texto (a la derecha)\n     col = \"red\")\n\n\n\n\n\n\n\n# Mostrar los valores del punto de corte óptimo\nprint(\"Valores del punto de corte óptimo (índice de Youden):\")\n\n[1] \"Valores del punto de corte óptimo (índice de Youden):\"\n\nprint(optimal_coords)\n\n  specificity sensitivity threshold\n1   0.6226415   0.7234043 0.2738415",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>TEMA 1: PRUEBAS DIAGNÓSTICAS Y CURVAS ROC</span>"
    ]
  },
  {
    "objectID": "TEMA-1.html#comparación-de-dos-pruebas-diagnósticas",
    "href": "TEMA-1.html#comparación-de-dos-pruebas-diagnósticas",
    "title": "1  TEMA 1: PRUEBAS DIAGNÓSTICAS Y CURVAS ROC",
    "section": "1.4 Comparación de Dos Pruebas Diagnósticas",
    "text": "1.4 Comparación de Dos Pruebas Diagnósticas\nLa prueba de DeLong es una prueba no paramétrica ampliamente utilizada para comparar el Área Bajo la Curva (AUC) de dos o más curvas ROC (Receiver Operating Characteristic) correlacionadas. Es particularmente valiosa cuando tienes, por ejemplo, múltiples pruebas de diagnóstico aplicadas al mismo conjunto de pacientes y quieres ver si el rendimiento de una prueba (medido por el AUC) es significativamente mejor que el de otra. El paquete pROC proporciona una implementación conveniente de la prueba de DeLong [8].\n\n1.4.1 Base matemática de la prueba de DeLong\nLa prueba de De Long se basa en la teoría de las U-estadísticas. Esencialmente, calcula la covarianza entre los AUC empíricos de dos (o más) curvas ROC. Esta covarianza es crucial porque al comparar curvas ROC correlacionadas (por ejemplo, de los mismos sujetos), se viola el supuesto de independencia requerido por pruebas más simples.https://www.jstor.org/stable/2531595\nAquí tienes un resumen simplificado de las ideas matemáticas clave:\n\nAUC como U-estadística: El AUC puede expresarse como una U-estadística. Para una sola curva ROC generada a partir de un conjunto de \\(n\\) sujetos enfermos (casos) y \\(m\\) sujetos no enfermos (controles), el AUC es una medida de la probabilidad de que un sujeto enfermo elegido al azar tenga una puntuación de prueba más alta que un sujeto no enfermo elegido al azar.\n\nSean \\(X_i\\) las puntuaciones de la prueba para sujetos no enfermos (\\(i=1, \\dots, n\\)) y \\(Y_j\\) las puntuaciones de la prueba para sujetos enfermos (\\(j=1, \\dots, m\\)).\nEl AUC empírico, a menudo calculado usando la regla trapezoidal, puede expresarse formalmente en términos de pares de observaciones:\n\\[\\text{AUC} = \\frac{1}{nm} \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\mathbb{I}(Y_j &gt; X_i) + \\frac{1}{2nm} \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\mathbb{I}(Y_j = X_i)\n\\] donde \\(\\mathbb{I}(\\cdot)\\) es la función indicadora (1 si la condición es verdadera, 0 en caso contrario), \\(n\\) es el número de sujetos no enfermos, \\(m\\) es el número de sujetos enfermos, \\(X_i\\) son las puntuaciones para los sujetos no enfermos, y \\(Y_j\\) son las puntuaciones para los sujetos enfermos. Esta fórmula refleja la idea de que por cada par de sujeto enfermo y no enfermo, contamos si la puntuación del sujeto enfermo es mayor (contribuyendo 1), igual (contribuyendo 0.5) o menor (contribuyendo 0).\nEs decir, el AUC es la proporción de veces que una puntuación de un sujeto enfermo es mayor que la de un sujeto no enfermo, más la mitad de las veces que son iguales. Es importante destacar que es una U-estadística porque se basa en todas las combinaciones posibles de pares (sujeto enfermo, sujeto no enfermo).\nEspecíficamente, la suma doble recorre todos los pares posibles, y cada par contribuye a la estadística según si el sujeto enfermo tiene una puntuación mayor, igual o menor que el sujeto no enfermo. Es decir, es una estadística basada en rangos. Esencialmente, es una medida de ordenamiento entre dos grupos. Es por eso que el AUC es insensible a las transformaciones monotónicas de las puntuaciones de la prueba.\nEs importante destacar que es una U-estadística porque se basa en todas las combinaciones posibles de pares (sujeto enfermo, sujeto no enfermo). Específicamente, la suma doble recorre todos los pares posibles, y cada par contribuye a la estadística según si el sujeto enfermo tiene una puntuación mayor, igual o menor que el sujeto no enfermo. Es decir, es una estadística basada en rangos. Esencialmente, es una medida de ordenamiento entre dos grupos. Es por eso que el AUC es insensible a las transformaciones monotónicas de las puntuaciones de la prueba.\n\nVarianza y covarianza de los AUC: El método de DeLong proporciona una forma de estimar la varianza de un solo AUC y, lo que es más importante, la covarianza entre dos AUC correlacionados. Aquí es donde entra en juego la teoría de las U-estadísticas. La varianza de una U-estadística se puede estimar de manera eficiente, y esta estimación se puede extender a la covarianza entre dos U-estadísticas que comparten datos comunes.\n\nEl núcleo de la prueba de DeLong implica calcular los componentes estructurales de las U-estadísticas, que son esencialmente medidas de cómo cada observación individual contribuye al AUC general. Estos componentes se utilizan luego para construir la matriz de varianza-covarianza de los AUC.\nPara dos curvas ROC, por ejemplo, ROC1 y ROC2, con AUCs \\(AUC_1\\) y \\(AUC_2\\), la prueba de De Long tiene como objetivo calcular la varianza de su diferencia:\n\\[\\text{Var}(AUC_1 - AUC_2) = \\text{Var}(AUC_1) + \\text{Var}(AUC_2) - 2 \\cdot \\text{Cov}(AUC_1, AUC_2)\\]\nEl artículo de DeLong proporciona las fórmulas específicas para estimar \\(\\text{Var}(AUC_1)\\), \\(\\text{Var}(AUC_2)\\) y \\(\\text{Cov}(AUC_1, AUC_2)\\) basadas en los rangos de las observaciones. Esto implica definir valores de “colocación” específicos para cada observación que reflejan su contribución al AUC.\n\nEstadístico Z y valor p: Una vez que se estima \\(\\text{Var}(AUC_1 - AUC_2)\\), se calcula un estadístico Z:\n\n\\[\nZ = \\frac{AUC_1 - AUC_2}{\\sqrt{\\text{Var}(AUC_1 - AUC_2)}}\n\\]\nBajo la hipótesis nula de que no hay diferencia entre los AUC verdaderos (\\(AUC_1 = AUC_2\\)), el estadístico Z sigue aproximadamente una distribución normal estándar. Este estadístico Z se usa luego para calcular un valor p, que indica la probabilidad de observar una diferencia tan extrema, o más extrema, como la observada, asumiendo que la hipótesis nula es verdadera. En el contexto de la prueba de De Long, las hipótesis se establecen de la siguiente manera:\n\n\\(H_0\\): no hay diferencia entre dos AUC (\\(AUC_{A} = AUC_{B}\\))\n\\(H_1\\): hay diferencia entre dos AUC (\\(AUC_{A} \\neq AUC_{B}\\))\n\nEn R, la función roc.test() del paquete pROC implementa la prueba de DeLong de manera eficiente, manejando todos los cálculos de varianza y covarianza internamente. Simplemente proporcionas dos objetos ROC (creados con la función roc()) y especificas el método como “Delong”.\n\nlibrary(pROC)\nset.seed(123) # para reproducibilidad\n\n# Estado real (0 = control, 1 = caso)\ntrue_status &lt;- rbinom(200, 1, 0.5)\n\n# Puntuaciones para dos pruebas de diagnóstico (Modelo A y Modelo B)\n# El Modelo A es ligeramente mejor que el Modelo B\nscores_A &lt;- rnorm(200, mean = ifelse(true_status == 1, 1, 0), sd = 1)\nscores_B &lt;- rnorm(200, mean = ifelse(true_status == 1, 0.8, 0), sd = 1)\n\n# Crear objetos ROC\nroc_A &lt;- roc(response = true_status, predictor = scores_A, ci = TRUE, of = \"auc\")\nroc_B &lt;- roc(response = true_status, predictor = scores_B, ci = TRUE, of = \"auc\")\n\n# Imprimir AUCs y sus intervalos de confianza\nprint(roc_A)\n\n\nCall:\nroc.default(response = true_status, predictor = scores_A, ci = TRUE,     of = \"auc\")\n\nData: scores_A in 103 controls (true_status 0) &lt; 97 cases (true_status 1).\nArea under the curve: 0.751\n95% CI: 0.6833-0.8187 (DeLong)\n\nprint(roc_B)\n\n\nCall:\nroc.default(response = true_status, predictor = scores_B, ci = TRUE,     of = \"auc\")\n\nData: scores_B in 103 controls (true_status 0) &lt; 97 cases (true_status 1).\nArea under the curve: 0.6619\n95% CI: 0.5867-0.7371 (DeLong)\n\n\n\n\n1.4.2 Realizando la prueba de De Long\nAhora, usamos la función roc.test() del paquete pROC con method = \"delong\" y paired = TRUE (ya que nuestros datos son de los mismos sujetos).\n\n#install.packages(\"pROC\")\nlibrary(pROC)\ndelong_result &lt;- roc.test(roc_A, roc_B, method = \"delong\", paired = TRUE)\n# Imprimir el resultado de la prueba\nprint(delong_result)\n\n\n    DeLong's test for two correlated ROC curves\n\ndata:  roc_A and roc_B\nZ = 1.7734, p-value = 0.07616\nalternative hypothesis: true difference in AUC is not equal to 0\n95 percent confidence interval:\n -0.009370521  0.187530866\nsample estimates:\nAUC of roc1 AUC of roc2 \n  0.7509759   0.6618957 \n\n\n\n\n1.4.3 Interpretando los resultados\nLa salida de la función roc.test() proporciona:\n\nEstadístico Z: Este es el estadístico de prueba calculado.\nValor p: La probabilidad de observar tal diferencia (o más extrema) en los AUC si no hubiera una verdadera diferencia entre los modelos. Un valor p pequeño (típicamente &lt; 0.05) indica una diferencia estadísticamente significativa.\nHipótesis alternativa: Especifica la hipótesis que se está probando (por ejemplo, “la verdadera diferencia en AUC no es igual a 0”).\nEstimaciones de la muestra: Los valores de AUC para cada curva ROC.\n\nEn nuestro ejemplo, el valor p de 0.07616 sugiere ninguna diferencia estadísticamente significativa entre el AUC del Modelo A y el Modelo B a un nivel de significanción de 0.05.\nA menudo es útil visualizar las curvas ROC junto con la prueba estadística.\n\nplot(roc_A, col = \"blue\", main = \"Comparación de Curvas ROC\")\nlines(roc_B, col = \"red\")\nlegend(\"bottomright\",\n       legend = c(paste(\"Modelo A (AUC =\", round(roc_A$auc, 3), \")\"),\n                  paste(\"Modelo B (AUC =\", round(roc_B$auc, 3), \")\")),\n       col = c(\"blue\", \"red\"), lwd = 2)\n\n\n\n\n\n\n\n\nEsta visualización ayuda a comprender intuitivamente el rendimiento de los modelos que se comparan mediante la prueba de De Long.\n\n\n1.4.4 Ejemplo: Comparación de dos cuestionarios de cribado de EPOC usando la prueba de DeLong\nQueremos comparar dos cuestionarios de cribado para la enfermedad pulmonar obstructiva crónica (EPOC) en fumadores mayores de 45 años en el ámbito de la atención primaria:\n\nCuestionario International Primary Care Airways Group (IPAG) (Puntuación: 0-38)\nCuestionario COPD Population Screener (COPDPS) (Puntuación: 0-10)\n\nCada participante recibió ambos cuestionarios (diseño ‘completamente emparejado’). El diagnóstico de EPOC se basó en el criterio espirométrico (FEV1/FVC &lt; 0.7 tras broncodilatación), el estado clínico (historia médica, síntomas y examen físico) y la exclusión de otras enfermedades.\nNecesitamos cargar los siguientes paquetes:\n\nlibrary(pROC)\nlibrary(plotROC)\nlibrary(epiR)\nlibrary(ggsci)\nlibrary(here)\nlibrary(tidyverse)\n\nOtros paquetes relevantes: OptimalCutpoints, cutpointr\nImportamos los datos copd en R:\n\nlibrary(readxl)\ndat &lt;- read_excel(here(\"data\", \"copd.xlsx\"))\n\n\n\n\n\n\n\n\n\nFigure 1.4: Table with data from “copd” file.\n\n\n\n\nInspeccionamos los datos y el tipo de variables:\n\nglimpse(dat)\n\nRows: 2,587\nColumns: 3\n$ IPAG      &lt;dbl&gt; 11, 15, 4, 7, 13, 15, 13, 14, 4, 21, 17, 11, 10, 17, 9, 18, …\n$ COPDPS    &lt;dbl&gt; 4, 3, 2, 2, 4, 4, 2, 2, 2, 6, 5, 2, 2, 4, 2, 4, 2, 5, 2, 3, …\n$ diagnosis &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nUso de puntos de corte y la curva ROC\nSegún estudios previos, los puntos de corte para una respuesta positiva son:\n\n\\(\\ge 17\\) para el cuestionario IPAG\n\\(\\ge 5\\) para el cuestionario COPDPS.\n\nPodemos evaluar estos valores de corte calculando sus medidas asociadas de precisión diagnóstica (es decir, Se, Sp, VPP, VPN).\n\ndat &lt;- dat |&gt;  \n  mutate(IPAG_cat = cut(IPAG, c(0, 17, 38), labels=c(\"-\",\"+\"), \n                        include.lowest = TRUE, right=FALSE),\n         COPDPS_cat = cut(COPDPS, c(0, 5, 10), labels=c(\"-\",\"+\"), \n                          include.lowest = TRUE, right=FALSE))\n\ndat &lt;- as.data.frame(dat)\n\n# we need to create a roc object for each questionnaire\nroc1 &lt;- roc(dat$diagnosis, dat$IPAG)\nroc2 &lt;- roc(dat$diagnosis, dat$COPDPS)\n\n\n1.4.4.1 Cuestionario IPAG\nA. El uso de un valor de corte: puntuación IPAG \\(\\ge 17\\)\nPrimero, encontraremos los recuentos de individuos en cada uno de los cuatro posibles resultados en una tabla 2x2 para el punto de corte de 17:\n\ntable(dat$IPAG_cat, dat$diagnosis)\n\n   \n       0    1\n  - 1670   70\n  +  644  203\n\n\nA continuación, reformateamos la tabla de la siguiente manera:\n\ntb1 &lt;- as.table(\n  rbind(c(203, 644), c(70, 1670))\n  )\n\ndimnames(tb1) &lt;- list(\n  Test = c(\"+\", \"_\"),\n  Outcome = c(\"+\", \"-\")\n)\n\ntb1\n\n    Outcome\nTest    +    -\n   +  203  644\n   _   70 1670\n\n\n\nepi.tests(tb1, digits = 3)\n\n          Outcome +    Outcome -      Total\nTest +          203          644        847\nTest -           70         1670       1740\nTotal           273         2314       2587\n\nPoint estimates and 95% CIs:\n--------------------------------------------------------------\nApparent prevalence *                  0.327 (0.309, 0.346)\nTrue prevalence *                      0.106 (0.094, 0.118)\nSensitivity *                          0.744 (0.687, 0.794)\nSpecificity *                          0.722 (0.703, 0.740)\nPositive predictive value *            0.240 (0.211, 0.270)\nNegative predictive value *            0.960 (0.949, 0.969)\nPositive likelihood ratio              2.672 (2.428, 2.940)\nNegative likelihood ratio              0.355 (0.290, 0.436)\nFalse T+ proportion for true D- *      0.278 (0.260, 0.297)\nFalse T- proportion for true D+ *      0.256 (0.206, 0.313)\nFalse T+ proportion for T+ *           0.760 (0.730, 0.789)\nFalse T- proportion for T- *           0.040 (0.031, 0.051)\nCorrectly classified proportion *      0.724 (0.706, 0.741)\n--------------------------------------------------------------\n* Exact CIs\n\n\nLos resultados utilizando el punto de corte de 17 arrojan una Se = 0.744 (0.687 - 0.794) y una Sp = 0.722 (0.703 - 0.740). Observamos que la probabilidad de la ausencia de EPOC dado un resultado negativo de la prueba es alta, NPV = 0.960 (IC 95%: 0.949, 0.969) en esta muestra con fumadores.\nB. El área bajo la curva ROC del cuestionario IPAG\nCalculemos el AUC de ROC para el cuestionario IPAG:\n\nauc(roc1)\n\nArea under the curve: 0.7986\n\n\nEl intervalo de confianza del 95% de esta área es:\n\nci.auc(roc1)\n\n95% CI: 0.7687-0.8286 (DeLong)\n\n\nLa capacidad del cuestionario IPAG para discriminar entre individuos con y sin EPOC se muestra gráficamente mediante la curva ROC:\n\n# create the plot\ng1 &lt;- ggplot(dat, aes(d = diagnosis, m = IPAG)) + \n  geom_roc(n.cuts = 0, color = \"#0071BF\") +\n  theme(text = element_text(size = 14)) +\n  geom_abline(intercept = 0, slope = 1, linetype = 'dashed') +\n  scale_x_continuous(expand = c(0, 0.015)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"1 - Specificity\", y = \"Sensitivity\")\n\n# add annotations to the plot\ng1 + annotate(\"text\", x=0.70, y=0.30, \n             label=paste(\"AUC IPAG = \", 0.799, \n                         \"(95% CI = \", 0.769, \" - \", 0.829, \")\"))\n\n\n\n\n\n\n\nFigure 1.5: The ROC curve of IPAG questionnaire.\n\n\n\n\n\nEl AUC del cuestionario IPAG es igual a 0.799 (IC 95%: 0.769 - 0.829), lo que indica una prueba diagnóstica razonable.\nEl índice de Youden, definido como la suma de sensibilidad y especificidad menos 1, se utiliza a menudo junto con la curva ROC. El valor máximo del índice de Youden puede emplearse como criterio para seleccionar el punto de corte (umbral) óptimo para una prueba diagnóstica, como se muestra a continuación:\n\ncoords(roc1, \"best\", ret = c(\"threshold\", \"sensitivity\", \"specificity\"),\n       best.method=\"youden\")\n\n  threshold sensitivity specificity\n1      18.5   0.6739927   0.8063959\n\n\nObservamos que el punto de corte (umbral) óptimo para esta muestra es igual a 18.5, lo cual es ligeramente superior al valor de 17 que se obtuvo de otros estudios.\nTambién podemos calcular fácilmente el valor máximo del índice de Youden según la definición previa del índice de Youden:\n\n0.674 + 0.806 - 1\n\n[1] 0.48\n\n\n\n\n1.4.4.2 Cuestionario COPDPS\nA. El uso de un valor de corte: puntuación COPDPS \\(\\ge 5\\)\nPrimero, encontraremos los recuentos de individuos en cada uno de los cuatro posibles resultados en una tabla 2x2 para el punto de corte de 5:\n\ntable(dat$COPDPS_cat, dat$diagnosis)\n\n   \n       0    1\n  - 2089  121\n  +  225  152\n\n\nA continuación, reformateamos la tabla de la siguiente manera:\n\ntb2 &lt;- as.table(\n  rbind(c(152, 225), c(121, 2089))\n  )\n\ndimnames(tb2) &lt;- list(\n  Test = c(\"+\", \"_\"),\n  Outcome = c(\"+\", \"-\")\n)\n\ntb2\n\n    Outcome\nTest    +    -\n   +  152  225\n   _  121 2089\n\n\n\nepi.tests(tb2, digits = 3)\n\n          Outcome +    Outcome -      Total\nTest +          152          225        377\nTest -          121         2089       2210\nTotal           273         2314       2587\n\nPoint estimates and 95% CIs:\n--------------------------------------------------------------\nApparent prevalence *                  0.146 (0.132, 0.160)\nTrue prevalence *                      0.106 (0.094, 0.118)\nSensitivity *                          0.557 (0.496, 0.617)\nSpecificity *                          0.903 (0.890, 0.915)\nPositive predictive value *            0.403 (0.353, 0.455)\nNegative predictive value *            0.945 (0.935, 0.954)\nPositive likelihood ratio              5.726 (4.864, 6.741)\nNegative likelihood ratio              0.491 (0.430, 0.561)\nFalse T+ proportion for true D- *      0.097 (0.085, 0.110)\nFalse T- proportion for true D+ *      0.443 (0.383, 0.504)\nFalse T+ proportion for T+ *           0.597 (0.545, 0.647)\nFalse T- proportion for T- *           0.055 (0.046, 0.065)\nCorrectly classified proportion *      0.866 (0.853, 0.879)\n--------------------------------------------------------------\n* Exact CIs\n\n\nLos resultados utilizando el punto de corte de 5 arrojan Se = 0.577 (0.496 - 0.617) y Sp = 0.903 (0.890 - 0.915).\nB. El área bajo la curva ROC del cuestionario COPDPS\nEl AUC de la curva ROC del cuestionario COPDPS es:\n\nauc(roc2)\n\nArea under the curve: 0.7908\n\n\nEl intervalo de confianza del 95% de esta área es:\n\nci.auc(roc2)\n\n95% CI: 0.7602-0.8214 (DeLong)\n\n\nLa curva ROC del cuestionario COPDPS es la siguiente:\n\n# create the plot\ng2 &lt;- ggplot(dat, aes(d = diagnosis, m = COPDPS)) + \n  geom_roc(n.cuts = 0, color = \"#EFC000\") +\n  theme(text = element_text(size = 14)) +\n  geom_abline(intercept = 0, slope = 1, linetype = 'dashed') +\n  scale_x_continuous(expand = c(0, 0.015)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"1 - Specificity\", y = \"Sensitivity\")\n\n# add annotations to the plot\ng2 + annotate(\"text\", x=0.70, y=0.25, \n             label= paste(\"AUC COPDPS = \", 0.791, \n                          \"(95% CI = \", 0.760, \" - \", 0.821, \")\"))\n\n\n\n\n\n\n\nFigure 1.6: The ROC curve of COPDPS questionnaire.\n\n\n\n\n\nEl AUC del cuestionario COPDPS es igual a 0.791 (IC 95%: 0.760 - 0.821), lo que es un valor cercano al 0.799 del AUC del cuestionario IPAG.\nEl punto de corte óptimo utilizando el Índice de Youden como mejor método es:\n\ncoords(roc2, \"best\", ret = c(\"threshold\", \"sensitivity\", \"specificity\"),\n       best.method=\"youden\")\n\n  threshold sensitivity specificity\n1       4.5   0.5567766   0.9027658\n\n\nObservamos que el punto de corte (umbral) óptimo para esta muestra es igual a 4.5, lo cual es cercano al valor de 5 que se obtuvo de otros estudios.\nTambién podemos calcular el valor máximo del índice de Youden:\n\n0.557 + 0.903 - 1\n\n[1] 0.46\n\n\nComparación gráfica de curvas ROC\nPodemos trazar las curvas ROC para ambos cuestionarios en el mismo gráfico y comparar el área bajo las curvas:\n\n# prepare the data\nlongdata &lt;- melt_roc(dat, \"diagnosis\", c(\"IPAG\", \"COPDPS\"))\n\n# create the plot\ng &lt;- ggplot(longdata, aes(d = D, m = M, color = name)) + \n  geom_roc(n.cuts = 0) +\n  theme(text = element_text(size = 14),\n        legend.position=\"top\") +\n  geom_abline(intercept = 0, slope = 1, linetype = 'dashed') +\n  scale_x_continuous(expand = c(0, 0.015)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  scale_color_jco() +\n  labs(x = \"1 - Specificity\", y = \"Sensitivity\", colour=\"Questionnaire\")\n\n# add annotations to the plot\ng + annotate(\"text\", x=0.70, y=0.35, color = \"#0071BF\",\n             label=paste(\"AUC IPAG = \", 0.799, \n                         \" (95% CI = \", 0.769, \" - \", 0.829, \")\")) +\n  annotate(\"text\", x=0.70, y=0.28, color = \"#EFC000\",\n             label= paste(\"AUC COPDPS = \", 0.791, \n                          \" (95% CI = \", 0.760, \" - \", 0.821, \")\"))\n\n\n\n\n\n\n\nFigure 1.7: Graphical comparison between IPAG and COPDPS ROC curves.\n\n\n\n\n\nLos valores de AUC obtenidos de la curva ROC fueron 0.799 (IC 95%: 0.769 - 0.829) para el cuestionario IPAG y 0.791 (IC 95%: 0.760 - 0.821) para el cuestionario COPDPS. Por lo tanto, los dos cuestionarios tienen un rendimiento general similar en la muestra actual.\nBasado en la prueba de DeLong podemos describir la hipótesis nula y alternativa e interpretar el resultado. La prueba de DeLong se puede utilizar para comparar 2 áreas bajo la curva (AUCs). La hipótesis nula y alternativa son:\n\n\\(H_0\\): no hay diferencia entre dos AUC (\\(AUC_{IPAG} = AUC_{COPDPS}\\))\n\\(H_1\\): existe diferencia entre dos AUC (\\(AUC_{IPAG} \\neq AUC_{COPDPS}\\))\n\nEl test de Delong en R:\n\nroc.test(roc1, roc2, method=c(\"delong\"))\n\n\n    DeLong's test for two correlated ROC curves\n\ndata:  roc1 and roc2\nZ = 0.67525, p-value = 0.4995\nalternative hypothesis: true difference in AUC is not equal to 0\n95 percent confidence interval:\n -0.01488242  0.03052696\nsample estimates:\nAUC of roc1 AUC of roc2 \n  0.7986393   0.7908170 \n\n\nLa interpretación del resultado es la siguiente: No hubo una diferencia significativa en los valores de AUC con los dos cuestionarios (p = 0.4995 &gt; 0.05).\nEnlaces de interés:\nhttps://darwin.unmc.edu/dxtests/Default.htm\nhttps://epitools.ausvet.com.au/testevaluation\nhttps://www.medcalc.org/calc/diagnostic_test.php",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>TEMA 1: PRUEBAS DIAGNÓSTICAS Y CURVAS ROC</span>"
    ]
  },
  {
    "objectID": "TEMA-1.html#ejercicios-resueltos",
    "href": "TEMA-1.html#ejercicios-resueltos",
    "title": "1  TEMA 1: PRUEBAS DIAGNÓSTICAS Y CURVAS ROC",
    "section": "1.5 Ejercicios Resueltos",
    "text": "1.5 Ejercicios Resueltos\n-Ejercicio 1:\nSuponga que 100 individuos “conocidos” con la enfermedad y 1000 individuos “conocidos” libres de la enfermedad son examinados por una prueba diagnóstica con los siguientes resultados. Calcule la sensibilidad y la especificidad de la prueba diagnóstica [9].\n\n\n\n\n\n\n\n\n\n\nPrueba diagnóstica\n\n\n\n\n\n\nEstado real de la enfermedad\nT+\nT-\nTotal\n\n\nD+\n90 (VP)\n10 (FN)\n100\n\n\nD-\n200 (FP)\n800 (VN)\n1000\n\n\nTotal\n290\n810\n1100\n\n\n\nFuente: Schulzer M, Pruebas diagnósticas: una revisión estadística. Muscle & Nerve, 1994; 17: 815 - 819.\nRespuesta Ejercicio 1: Nota: Transponemos la tabla para que las filas representen los resultados de la prueba y las columnas el estado real de la enfermedad. - Sensibilidad (Se) = VP / (VP + FN) = 90 / (90 + 10) = 0.90 o 90% - Especificidad (Sp) = VN / (VN + FP) = 800 / (800 + 200) = 0.80 o 80% Usando R y epiR:\n\nlibrary(epiR)\ntb &lt;- as.table(\n  rbind(c(90, 200), c(10, 800))\n)\ndimnames(tb) &lt;- list(\n  Test = c(\"+\", \"-\"),\n  Outcome = c(\"+\", \"-\")\n)\nepi.tests(tb, digits = 3)\n\n          Outcome +    Outcome -      Total\nTest +           90          200        290\nTest -           10          800        810\nTotal           100         1000       1100\n\nPoint estimates and 95% CIs:\n--------------------------------------------------------------\nApparent prevalence *                  0.264 (0.238, 0.291)\nTrue prevalence *                      0.091 (0.075, 0.109)\nSensitivity *                          0.900 (0.824, 0.951)\nSpecificity *                          0.800 (0.774, 0.824)\nPositive predictive value *            0.310 (0.258, 0.367)\nNegative predictive value *            0.988 (0.977, 0.994)\nPositive likelihood ratio              4.500 (3.912, 5.177)\nNegative likelihood ratio              0.125 (0.069, 0.225)\nFalse T+ proportion for true D- *      0.200 (0.176, 0.226)\nFalse T- proportion for true D+ *      0.100 (0.049, 0.176)\nFalse T+ proportion for T+ *           0.690 (0.633, 0.742)\nFalse T- proportion for T- *           0.012 (0.006, 0.023)\nCorrectly classified proportion *      0.809 (0.785, 0.832)\n--------------------------------------------------------------\n* Exact CIs\n\n\n-Ejercicio 2:\nEl cáncer de cuello uterino es una enfermedad para la cual la probabilidad de contención es alta si se detecta a tiempo. La prueba de Papanicolaou es un procedimiento de detección ampliamente aceptado que puede detectar un cáncer aún asintomático; se le ha atribuido ser el principal responsable de la disminución de la tasa de mortalidad por cáncer de cuello uterino en los últimos años. Una prueba de competencia in situ realizada en 1972, 1973 y 1978 evaluó la competencia de los técnicos que examinan las muestras de Papanicolaou en busca de anomalías. Se examinó a técnicos en 306 laboratorios de citología en 44 estados de EE. UU. En general, el 16.25% de las pruebas realizadas en mujeres con cáncer resultaron en resultados falsos negativos (es decir, la prueba de una mujer que tiene cáncer de cuello uterino indica incorrectamente que no lo tiene). No todas las mujeres con resultados positivos realmente padecían cáncer de cuello uterino. De hecho, el 18.64% de las pruebas fueron resultados falsos positivos (es decir, la prueba es positiva pero la mujer no tiene cáncer de cuello uterino). Calcule la sensibilidad y la especificidad de la prueba de Papanicolaou [10].\nFuente: Pagano M, Gauvreau K y Pagano RR, Principles of Biostatistics. 2ª edición. Duxbury Press, 2000: página 136.\nRespuesta Ejercicio 2 - Sensibilidad (Se) = 1 - Falso Negativo = 1 - 0.1625 = 0.8375 o 83.75% - Especificidad (Sp) = 1 - Falso Positivo = 1 - 0.1864 = 0.8136 o 81.36% Usando R y epiR:\n\nlibrary(epiR)\ntb &lt;- as.table(\n  rbind(c(83.75, 18.64), c(16.25, 81.36))\n)\ndimnames(tb) &lt;- list(\n  Test = c(\"+\", \"-\"),\n  Outcome = c(\"+\", \"-\")\n)\nepi.tests(tb, digits = 3)\n\n          Outcome +    Outcome -      Total\nTest +         83.8         18.6      102.4\nTest -         16.2         81.4       97.6\nTotal         100.0        100.0      200.0\n\nPoint estimates and 95% CIs:\n--------------------------------------------------------------\nApparent prevalence *                  0.512 (0.440, 0.583)\nTrue prevalence *                      0.500 (0.429, 0.571)\nSensitivity *                          0.838 (0.750, 0.904)\nSpecificity *                          0.814 (0.723, 0.884)\nPositive predictive value *            0.818 (0.729, 0.887)\nNegative predictive value *            0.834 (0.745, 0.901)\nPositive likelihood ratio              4.493 (2.957, 6.828)\nNegative likelihood ratio              0.200 (0.127, 0.315)\nFalse T+ proportion for true D- *      0.186 (0.116, 0.277)\nFalse T- proportion for true D+ *      0.163 (0.096, 0.250)\nFalse T+ proportion for T+ *           0.182 (0.113, 0.271)\nFalse T- proportion for T- *           0.166 (0.099, 0.255)\nCorrectly classified proportion *      0.826 (0.766, 0.875)\n--------------------------------------------------------------\n* Exact CIs\n\n\n-Ejercicio 3:\nEntre 1820 sujetos disponibles en un estudio, 30 padecían tuberculosis y 1790 no. Se realizaron radiografías de tórax a todos los individuos; 73 tuvieron una radiografía positiva, lo que implicaba evidencia significativa de enfermedad inflamatoria, mientras que los resultados de los otros 1747 fueron negativos. Los datos de este estudio se presentan en la tabla a continuación. Según un informe, en 1987, hubo 9.3 casos de tuberculosis por cada 100,000 habitantes.\n¿Cuál es la probabilidad de que un individuo seleccionado al azar en 1987 tenga tuberculosis dado que su radiografía es positiva?\n¿Cuál es la probabilidad de que un individuo seleccionado al azar en 1987 no tenga tuberculosis dado que su radiografía es negativa?\n\n\n\n\nRadiografía\n\n\n\n\n\n\nTuberculosis\nNo\nSí\nTotal\n\n\nNegativo\n1739\n8\n1747\n\n\nPositivo\n51\n22\n73\n\n\nTotal\n1790\n30\n1820\n\n\n\nFuente: Pagano M, Gauvreau K y Pagano RR, Principles of Biostatistics. 2ª edición. Duxbury Press, 2000; página 138.\nLEER: Deeks y Altman. Pruebas diagnósticas 4: razones de verosimilitud. BMJ 2004;329:168-169 [6] https://www.bmj.com/content/329/7458/168\nA veces se afirma que la sensibilidad y la especificidad son características de la prueba diagnóstica en sí y que son invariables a la prevalencia de la enfermedad. Esto es cierto para una prueba diagnóstica particular en un entorno particular para un grupo particular de pacientes y ayuda a enfatizar que el VPP y el VPN pueden cambiar (a medida que cambia la probabilidad pre-prueba), pero la sensibilidad y la especificidad no (dado un entorno y un espectro de pacientes particulares). Sin embargo, no es cierto en general. Si la mezcla (espectro) de pacientes (leve vs. grave) con el trastorno objetivo varía cuando varía la prevalencia, entonces la sensibilidad y la especificidad cambiarán, así como el VPP y el VPN. La sensibilidad y la especificidad son características de la prueba en un entorno particular, que tiene una mezcla particular de pacientes con enfermedad leve versus grave.\nRespuesta Ejercicio 3: Calculando a mano: - Valor Predictivo Positivo (VPP) = VP / (VP + FP) = 22 / (22 + 73) = 0.231 o 23.1% - Valor Predictivo Negativo (VPN) = VN / (VN + FN) = 1739 / (1739 + 8) = 0.995 o 99.5%\nUsando R y epiR:\n\nlibrary(epiR)\ntb &lt;- as.table(\n  rbind(c(22, 73), c(8, 1739))\n)\ndimnames(tb) &lt;- list(\n  Test = c(\"-\", \"+\"),\n  Outcome = c(\"-\", \"+\")\n)\nepi.tests(tb, digits = 3)\n\n          Outcome +    Outcome -      Total\nTest +           22           73         95\nTest -            8         1739       1747\nTotal            30         1812       1842\n\nPoint estimates and 95% CIs:\n--------------------------------------------------------------\nApparent prevalence *                  0.052 (0.042, 0.063)\nTrue prevalence *                      0.016 (0.011, 0.023)\nSensitivity *                          0.733 (0.541, 0.877)\nSpecificity *                          0.960 (0.950, 0.968)\nPositive predictive value *            0.232 (0.151, 0.329)\nNegative predictive value *            0.995 (0.991, 0.998)\nPositive likelihood ratio              18.203 (13.330, 24.857)\nNegative likelihood ratio              0.278 (0.153, 0.503)\nFalse T+ proportion for true D- *      0.040 (0.032, 0.050)\nFalse T- proportion for true D+ *      0.267 (0.123, 0.459)\nFalse T+ proportion for T+ *           0.768 (0.671, 0.849)\nFalse T- proportion for T- *           0.005 (0.002, 0.009)\nCorrectly classified proportion *      0.956 (0.946, 0.965)\n--------------------------------------------------------------\n* Exact CIs\n\n\n-Ejercicio 4:\nEste ejercicio se basa en Una gammagrafía de ventilación-perfusión (V/Q scan) se utiliza para el diagnóstico de embolia pulmonar (EP). Algunos datos sobre sus características se dan en la Tabla 1 (de The PIOPED Investigators. Value of the ventilation/perfusion scan in acute pulmonary embolism. Results of the prospective investigation of pulmonary embolism diagnosis (PIOPED). J Am Med Assoc 263. 2753-9 (1990)) [11].\nTabla. La relación entre los resultados de las angiografías pulmonares y los resultados de la gammagrafía V/Q (incluyendo 150 pacientes con gammagrafías V/Q de baja probabilidad/casi normales/normales, sin (136) o angiografías no interpretables (14), y sin tromboembolismo clínicamente importante en el seguimiento).\n\n\n\n\n\n\n\n\nCategoría de la gammagrafía V/Q\nAngiograma\n\n\n\n\n\n\nEP presente\nEP ausente\n\n\nAlta probabilidad\n102\n14\n\n\nProbabilidad intermedia\n105\n217\n\n\nBaja probabilidad\n39\n273\n\n\nCasi normal / normal\n5\n126\n\n\nTotal\n251\n630\n\n\n\nUsando las razones de verosimilitud, calcule la probabilidad post-prueba de EP en los siguientes dos pacientes: -Una mujer anciana experimenta dificultad para respirar y molestias en el pecho 10 días después de la cirugía. La mayoría de los médicos estarían de acuerdo en que la probabilidad de que esta paciente tenga EP es bastante alta, alrededor del 70%. El resultado de su gammagrafía se informa como “probabilidad intermedia” de EP. ¿Cuál es la estimación post-prueba de su probabilidad de EP?\n-Otro paciente es un hombre de 28 años con dolor torácico no específico e hiperventilación después de completar un viaje en coche de 10 horas. Los resultados de un examen físico fueron normales, pero los resultados de la gammagrafía V/Q se informaron como “probabilidad intermedia” de EP. La estimación clínica de su probabilidad pre-prueba de EP es de aproximadamente el 20%. ¿Cuál es su probabilidad post-prueba?\nRespuesta Ejercicio 4: Calcule las razones de verosimilitud de esta tabla: - Razón de verosimilitud (LR) para alta probabilidad = Se / (1 - Sp) = (102 / 251) / (14 / 630) = 18.3 - LR para probabilidad intermedia = (105 / 251) / (217 / 630) = 1.2 - LR para baja probabilidad = (39 / 251) / (273 / 630) = 0.36 - LR para casi normal / normal = (5 / 251) / (126 / 630) = 0.1 -Usando el teorema de Bayes tendríamos que la Probabilidad post-prueba = (Probabilidad pre-prueba * LR) / (Probabilidad pre-prueba * LR + (1 - Probabilidad pre-prueba)). Por ejemplo para la situación intermedia tendríamos: Probabilidad pre-prueba intermedia = 0.70 (70%) y LR = 1.2 (probabilidad intermedia) Probabilidad post-prueba = (0.70 * 1.2) / (0.70 * 1.2 + (1 - 0.70)) = 0.74 (74%) Y así sucesivamente para todoas las situaciones. Vease en la siguiente tabla las probabilidades pre-prueba, razones de verosimilitud de los resultados de la gammagrafía de ventilación/perfusión, y probabilidades post-prueba en dos pacientes con embolia pulmonar.\n\n\n\n\n\n\n\n\nProbabilidad pre-prueba, % (Rango)\nResultado de la gammagrafía y razón de verosimilitud\nProbabilidad post-prueba, % (Rango)\n\n\n\n\nMujer de 78 años con disnea de aparición repentina después de cirugía abdominal\n\n\n\n\n(60) 70% (80)\nAlta probabilidad: LR = 18.3\n(96%) 97% (99%)\n\n\n(60) 70% (80)\nProbabilidad intermedia: LR = 1.2\n(64%) 74% (83%)\n\n\n(60) 70% (80)\nBaja probabilidad: LR = 0.36\n(35%) 46% (59%)\n\n\n(60) 70% (80)\nNormal/casi normal: LR = 0.1\n(13%) 19% (29%)\n\n\nHombre de 28 años con disnea y dolor torácico atípico\n\n\n\n\n(10) 20% (30)\nAlta probabilidad: LR = 18.3\n(67%) 82% (89%)\n\n\n(10) 20% (30)\nProbabilidad intermedia: LR = 1.2\n(12%) 23% (34%)\n\n\n(10) 20% (30)\nBaja probabilidad: LR = 0.36\n(4%) 8% (12%)\n\n\n(10) 20% (30)\nNormal/casi normal: LR = 0.1\n(1%) 2% (4%)\n\n\n\nLos valores entre paréntesis representan un rango plausible de probabilidades pre-prueba. Es decir, aunque la mejor estimación de la probabilidad pre-prueba es del 70%, valores del 60% al 80% también serían estimaciones razonables.\nEn R lo calculamos así:\n\nlibrary(epiR)\n# Función para calcular la probabilidad post-prueba usando el teorema de Bayes\npost_test_prob &lt;- function(pre_test_prob, lr) {\n  (pre_test_prob * lr) / (pre_test_prob * lr + (1 - pre_test_prob))\n}\n# Razones de verosimilitud\nlr_values &lt;- c(18.3, 1.2, 0.36, 0.1)\n# Probabilidades pre-prueba para los dos pacientes\npre_test_probs &lt;- list(c(0.60, 0.70, 0.80), c(0.10, 0.20, 0.30))\n# Calcular probabilidades post-prueba\nresults &lt;- lapply(pre_test_probs, function(pre_probs) {\n  sapply(lr_values, function(lr) {\n    sapply(pre_probs, function(pre) post_test_prob(pre, lr))\n  })\n})\n# Mostrar resultados\nresults\n\n[[1]]\n          [,1]      [,2]      [,3]      [,4]\n[1,] 0.9648506 0.6428571 0.3506494 0.1304348\n[2,] 0.9771167 0.7368421 0.4565217 0.1891892\n[3,] 0.9865229 0.8275862 0.5901639 0.2857143\n\n[[2]]\n          [,1]      [,2]       [,3]       [,4]\n[1,] 0.6703297 0.1176471 0.03846154 0.01098901\n[2,] 0.8206278 0.2307692 0.08256881 0.02439024\n[3,] 0.8869144 0.3396226 0.13366337 0.04109589\n\n\nTamaño de la muestra e intervalo de confianza para pruebas diagnósticas LEER: Simel et al. 1991 [5]\nhttps://pubmed.ncbi.nlm.nih.gov/1941027/\nEl artículo señala que las razones de verosimilitud son algebraicamente idénticas a las razones de riesgo. Esto sugiere una forma de obtener intervalos de confianza para las razones de verosimilitud y un marco para calcular el tamaño de la muestra para estudios de procedimientos diagnósticos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>TEMA 1: PRUEBAS DIAGNÓSTICAS Y CURVAS ROC</span>"
    ]
  },
  {
    "objectID": "TEMA-2.html",
    "href": "TEMA-2.html",
    "title": "2  TEMA 2: ANÁLISIS DE LA VARIANZA",
    "section": "",
    "text": "2.1 Introducción al ANOVA\nCuando hayamos terminado este Capítulo, deberíamos ser capaces de:\nEl Análisis de Varianza (ANOVA) es una prueba estadística fundamental en las ciencias de la salud para comparar las medias de tres o más grupos. En lugar de realizar múltiples pruebas t de Student, que aumentan el riesgo de errores de Tipo I (falsos positivos), el ANOVA evalúa si existe una diferencia significativa general entre los grupos en una sola prueba. El contenido de este tema está basado en el uso del software JAMOVI https://www.jamovi.org/ y tutoriales estadísticos de JAMOVI [1].\nEl principio básico del ANOVA es descomponer la variabilidad total de los datos en dos componentes:\nEl estadístico F del ANOVA es la relación entre estas dos varianzas. Un valor F grande con un p-valor bajo sugiere que la variabilidad entre los grupos es significativamente mayor que la variabilidad dentro de ellos, lo que indica que al menos una de las medias de los grupos es diferente [2]. Esta descomposición de varianzas del test de ANOVA se presenta generalmente en una tabla, que explicaremos en detalle y la estimaremos con la función summary(aov()) en R.\nEn función del diseño del experimento o la pregunta del investigador y sus aplicaciones en salud, exiten diferentes tipos de ANOVA:\nFuente: Martínez-González MÁ et al. Bioestadística amigable. 4th ed. Madrid, Spain: Elsevier; 2020.[3]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TEMA 2: ANÁLISIS DE LA VARIANZA</span>"
    ]
  },
  {
    "objectID": "TEMA-2.html#introducción-al-anova",
    "href": "TEMA-2.html#introducción-al-anova",
    "title": "2  TEMA 2: ANÁLISIS DE LA VARIANZA",
    "section": "",
    "text": "Variabilidad entre grupos: La varianza explicada por las diferencias entre las medias de los grupos.\nVariabilidad dentro de los grupos: La varianza residual o aleatoria que existe dentro de cada grupo (debida al azar).\n\n\n\n\n\n\n\n\n\n\n\nTipo de ANOVA\nDescripción\nEjemplo de aplicación en salud\n\n\n\n\nANOVA de un factor (One-way ANOVA)\nCompara las medias de tres o más grupos independientes con una sola variable independiente (factor).\nComparar el efecto de tres dietas diferentes (dieta A, dieta B, dieta C) sobre la pérdida de peso.\n\n\nANOVA de dos factores (Two-way ANOVA)\nEvalúa el efecto de dos variables independientes sobre una variable dependiente. Permite analizar el efecto de cada factor por separado y la interacción entre ambos.\nEstudiar el efecto de un medicamento (dosis alta vs. dosis baja) y el género (masculino vs. femenino) en la presión arterial.\n\n\nANOVA de medidas repetidas (Repeated Measures ANOVA)\nSe utiliza cuando se mide a los mismos sujetos en tres o más ocasiones o condiciones. Es una extensión de la prueba t de muestras pareadas.\nMedir los niveles de glucosa en sangre de un grupo de pacientes antes, durante y después de un tratamiento.\n\n\n\n\n\n2.1.1 Condiciones generales de aplicabilidad del test ANOVA\nPara que los resultados del ANOVA sean válidos, deben cumplirse ciertas suposiciones:\n\nIndependencia de las observaciones: Las mediciones de un sujeto no deben influir en las de otro. Esto se garantiza con un diseño experimental adecuado, como la asignación aleatoria.\nNormalidad: Los datos de la variable dependiente (generalmente cuantitativa) dentro de cada grupo deben seguir una distribución aproximadamente normal.\nHomogeneidad de varianzas (Homocedasticidad): La varianza de los datos debe ser similar en todos los grupos.\n\nSi no se cumplen estas suposiciones, especialmente la normalidad, se puede recurrir a alternativas no paramétricas como el test de Kruskal-Wallis [4].\n\n\n2.1.2 Explicación de los componentes de la tabla ANOVA\nLa tabla ANOVA es una herramienta clave para resumir los resultados del análisis de varianza. Aquí tienes un ejemplo de cómo se vería una tabla ANOVA típica:\n\n\n\n\n\nFuente de Variación\nSS\nDf\nMS\nF\nPvalor\n\n\n\n\nEntre Grupos (Between)\n$$SS_{B} = \\sum_{i=1}^{k} n_i (\\bar{y_i} - \\bar{\\bar{y}})^2$$\n$$Df_{1} = k - 1$$\n$$MS_{B} = \\frac{SS_{B}}{Df_{1}}$$\n$$F = \\frac{MS_{B}}{MS_{W}}$$\n$$F&gt;F_{critica}$$\n\n\nDentro de Grupos (Within/Error)\n$$SS_{W} = \\sum_{i=1}^{k}\\sum_{j=1}^{n_i} (y_{ij} - \\bar{y_i})^2$$\n$$Df_{2} = N - k$$\n$$MS_{W} = \\frac{SS_{W}}{Df_{2}}$$\n\n\n\n\nTotal\n$$SS_{Total} = \\sum_{i=1}^{k}\\sum_{j=1}^{n_i} (y_{ij} - \\bar{\\bar{y}})^2$$\n$$Df_{Total} = N - 1$$\n\n\n\n\n\n\n\n\nLeyenda:\n\\(k\\): Número de grupos.\n\\(N\\): Número total de observaciones.\n\\(\\bar{y_i}\\): Media del grupo \\(i\\).\n\\(\\bar{\\bar{y}}\\): Media general.\n\\(y_{ij}\\): Observación \\(j\\) en el grupo \\(i\\).\nA continuación, se explica cada componente de la tabla ANOVA:\nFuentes de Variación\n1. Entre Grupos (Between Groups): Representa la variabilidad que existe entre las medias de los diferentes grupos que estás comparando. Si esta variabilidad es grande, es probable que los grupos sean significativamente diferentes.\n2. Dentro de Grupos (Within Groups):\nRepresenta la variabilidad que existe dentro de cada grupo individual. Es la variabilidad “aleatoria” o no explicada por el tratamiento o factor de interés.\n3. Total: Es la suma de la variabilidad entre y dentro de los grupos, representando la variabilidad total de todos los datos.\nSuma de Cuadrados (SS)\n1. Suma de Cuadrados Entre Grupos (\\(SS_{Between}\\)): Mide la variabilidad entre las medias de los grupos.\n2. Suma de Cuadrados Dentro de Grupos (\\(SS_{Within}\\)): Mide la variabilidad dentro de cada grupo.\n3. Suma de Cuadrados Total (\\(SS_{Total}\\)): La suma de las dos anteriores (\\(SS_{Total} = SS_{Between} + SS_{Within}\\)).\nGrados de Libertad (Df)\n1. Entre Grupos (Df1): Es el número de grupos menos 1. Si tienes 3 grupos, Df1 será 2. \\(Df_{1} = k - 1\\) (donde \\(k\\) es el número de grupos)\n2. Dentro de Grupos (Df2): Es el número total de observaciones menos el número de grupos. Si tienes 3 grupos y 18 observaciones en total, Df2 será 15 (\\(18-3=15\\)). \\(Df_{2} = N - k\\) (donde \\(N\\) es el número total de observaciones y \\(k\\) es el número de grupos)\n3. Total (Df_Total): Es el número total de observaciones menos 1. \\(Df_{Total} = N - 1\\)\nMedia de Cuadrados (MS)\nLa Media de Cuadrados es la Suma de Cuadrados dividida por sus grados de libertad. Representa una estimación de la varianza.\n\nMedia de Cuadrados Entre Grupos (\\(MS_{Between}\\)): \\(MS_{Between} = SS_{Between} / Df_{1}\\)\n\nMedia de Cuadrados Dentro de Grupos (\\(MS_{Within}\\)): \\(MS_{Within} = SS_{Within} / Df_{2}\\)\n\nEstadístico F\nEl estadístico F es el corazón del ANOVA. Es una razón que compara la variabilidad entre los grupos con la variabilidad dentro de ellos.\n\\(F = MS_{Between} / MS_{Within}\\)\nUn valor F grande sugiere que la variabilidad entre los grupos es mucho mayor que la variabilidad aleatoria dentro de ellos, lo que apoya la idea de que las medias de los grupos son realmente diferentes. El valor de F se compara con un valor crítico de la distribución F para determinar la significación estadística.\nP-valor: (Pr(&gt;F))\nEl p-valor es la probabilidad de observar un valor F tan extremo o más extremo que el calculado, si la hipótesis nula fuera verdadera. Se obtiene de la distribución F con \\(Df1\\) y \\(Df2\\) grados de libertad. \\[P = P(F_{Df1, Df2} &gt; F_{crítico})\\] Si p-valor \\(&lt;\\alpha\\) (nivel de significación, generalmente 0.05), se rechaza la hipótesis nula y concluyes que hay una diferencia estadísticamente significativa entre las medias de al menos dos de los grupos. Si el p-valor &gt;0.05, no se tiene suficiente evidencia ara rechazar la H0, lo que significa que las diferencias observadas entre las medias podrían deberse simplemente al azar.\nEta cuadrada generalizada\nEta (\\(\\eta_G^2\\)) es una medida del tamaño del efecto en el análisis de varianza (ANOVA). Su objetivo es cuantificar la proporción de la varianza total en la variable dependiente que puede ser explicada por un factor (variable independiente), independientemente del diseño de la investigación. A diferencia de la eta cuadrada (\\(\\eta^2\\)) y la eta cuadrada parcial (\\(\\eta_p^2\\)), la eta cuadrada generalizada está diseñada para ser comparable entre diferentes tipos de estudios. Por esta razón, se considera una medida más robusta y es la preferida en muchos campos de investigación. La eta cuadrada (\\(\\eta^2\\)) y la eta cuadrada parcial (\\(\\eta_p^2\\)), aunque útiles, tienen una limitación importante: sus valores pueden ser influenciados por el diseño del estudio. El valor de la eta cuadrada generalizada va de 0 a 1. Cuanto más cerca esté el valor de 1, mayor es la proporción de la varianza de la variable dependiente que es explicada por el factor.\nValores típicos de referencia (guía, no reglas estrictas):\nPequeño: \\(\\eta_G^2 = 0.01\\)\nMediano: \\(\\eta_G^2 = 0.06\\)\nGrande: \\(\\eta_G^2 = 0.14\\)\nEn la práctica, reportar la \\(\\eta_G^2\\) junto con el p-valor del ANOVA proporciona una imagen completa: así el p-valor te dice si un efecto es estadísticamente significativo, mientras que el tamaño del efecto (\\(\\eta_G^2\\)) te dice cuán importante o sustancial es ese efecto en la práctica.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TEMA 2: ANÁLISIS DE LA VARIANZA</span>"
    ]
  },
  {
    "objectID": "TEMA-2.html#anova-de-un-factor-o-una-sola-vía-en-r-oneway-anova",
    "href": "TEMA-2.html#anova-de-un-factor-o-una-sola-vía-en-r-oneway-anova",
    "title": "2  TEMA 2: ANÁLISIS DE LA VARIANZA",
    "section": "2.2 ANOVA de un factor o una sola vía en R (ONEWAY ANOVA)",
    "text": "2.2 ANOVA de un factor o una sola vía en R (ONEWAY ANOVA)\n\n2.2.1 Computación e interpretación del resultado\nEl análisis de varianza (ANOVA) es una técnica estadística popular para comparar resultados entre múltiples grupos, pero utilizarla eficazmente en R puede ser abrumador debido a la multitud de funciones y opciones disponibles. En esta práctica pretendemos motrar las herramientas esenciales y los flujos de trabajo para realizar ANOVA (de un factor) en R, desde la codificación, hasta la visualización, y la elaboración de informes.\nLos pasos genéricos a seguir para su realización de un ANOVA son los siguientes:\n\nRealizar el ANOVA: Si el valor p es menor que 0.05, se rechaza la hipótesis nula de que todas las medias son iguales. Esto significa que hay una diferencia significativa entre al menos dos grupos.\nRealizar comparaciones post-hoc: Si el ANOVA es significativo, se necesitan pruebas post-hoc (como la prueba de Tukey) para determinar qué grupos específicos son diferentes entre sí. El ANOVA solo indica que “hay una diferencia”, no dónde está.\nCalcular e interpretar el tamaño del efecto: Medidas como la eta cuadrada generalizada (\\(\\eta_G^2\\)) o el omega cuadrado (\\(\\omega^2\\)) indican la magnitud del efecto de la variable independiente. Esto es crucial para entender la importancia clínica del hallazgo, más allá de la significación estadística.\n\nLos siguientes pasos ayudan a implementar practicamente un ANOVA de un factor en R.\n\npacman::p_load(tidyverse, ggpubr, rstatix, emmeans, performance)\n\nPrimero, debemos obtener los datos de un ejemplo basado en un escenario hipotético, donde tenemos un ensayo clínico con 18 participantes que han asignados aleatoriamente a uno de tres grupos de medicamentos: placebo, anxifree o joyzepam.\nEl objetivo del ensayo era determinar si alguno de los dos medicamentos podía mejorar el estado de ánimo en comparación con el placebo. Cada grupo estaba compuesto por seis participantes y el resultado principal fue el cambio en el estado de ánimo a lo largo del ensayo\n\ndata &lt;-  tibble::tribble(\n    ~id, ~drug, ~cbt, ~mood_gain,\n    1L, \"placebo\", \"no.therapy\", 0.5,\n    2L, \"placebo\", \"no.therapy\", 0.3,\n    3L, \"placebo\", \"no.therapy\", 0.1,\n    4L, \"anxifree\", \"no.therapy\", 0.6,\n    5L, \"anxifree\", \"no.therapy\", 0.4,\n    6L, \"anxifree\", \"no.therapy\", 0.2,\n    7L, \"joyzepam\", \"no.therapy\", 1.4,\n    8L, \"joyzepam\", \"no.therapy\", 1.7,\n    9L, \"joyzepam\", \"no.therapy\", 1.3,\n    10L, \"placebo\", \"CBT\", 0.6,\n    11L, \"placebo\", \"CBT\", 0.9,\n    12L, \"placebo\", \"CBT\", 0.3,\n    13L, \"anxifree\", \"CBT\", 1.1,\n    14L, \"anxifree\", \"CBT\", 0.8,\n    15L, \"anxifree\", \"CBT\", 1.2,\n    16L, \"joyzepam\", \"CBT\", 1.8,\n    17L, \"joyzepam\", \"CBT\", 1.3,\n    18L, \"joyzepam\", \"CBT\", 1.4\n  ) %&gt;%\n  mutate(across(c(id, drug, cbt), as.factor)) %&gt;%\n  select(-cbt)\n\nAhora, echemos un vistazo rápido a los datos:\n\ndata %&gt;%\n  flextable::flextable() %&gt;%\n  flextable::autofit()\n\niddrugmood_gain1placebo0.52placebo0.33placebo0.14anxifree0.65anxifree0.46anxifree0.27joyzepam1.48joyzepam1.79joyzepam1.310placebo0.611placebo0.912placebo0.313anxifree1.114anxifree0.815anxifree1.216joyzepam1.817joyzepam1.318joyzepam1.4\n\n\nVisualizamos los datos: Gráficos de cajas y bigotes usando la función ggboxplot() del paquete ggpubr:\n\ndata %&gt;%\n  ggpubr::ggboxplot(\n    y = \"mood_gain\",\n    x = \"drug\",\n    color = \"drug\",\n    add = c(\"dotplot\"),\n    add.params = list(\n      position = position_jitter(w = 0.09, h = 0.04)\n    ),\n    palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\")\n  ) +\n  theme(\n    legend.position = \"none\",\n    axis.title.x = element_blank()\n  )\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n# Describir los datos\nsummary(data)\n\n       id           drug     mood_gain     \n 1      : 1   anxifree:6   Min.   :0.1000  \n 2      : 1   joyzepam:6   1st Qu.:0.4250  \n 3      : 1   placebo :6   Median :0.8500  \n 4      : 1                Mean   :0.8833  \n 5      : 1                3rd Qu.:1.3000  \n 6      : 1                Max.   :1.8000  \n (Other):12                                \n\n# Medias por grupo\nlibrary(dplyr)\nattach(data)\ndata %&gt;%\n  group_by(drug) %&gt;%\n  summarise(media = mean(mood_gain), sd = sd(mood_gain))\n\n# A tibble: 3 × 3\n  drug     media    sd\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 anxifree 0.717 0.392\n2 joyzepam 1.48  0.214\n3 placebo  0.45  0.281\n\n\nDe inmediato, podemos ver que parece haber una diferencia entre los grupos de medicamentos, con joyzepam mostrando una ganancia de estado de ánimo promedio más alta que anxifree y el placebo. Sin embargo, si bien una diferencia bruta entre grupos proporciona una idea de la magnitud de un efecto, necesitamos estadísticas que nos ayuden a determinar si es probable que la diferencia represente un efecto real en lugar de solo una variación aleatoria. Para evaluar si las diferencias observadas entre los tres grupos de tratamiento son estadísticamente significativas, realizaremos un ANOVA de un factor.\nPar calcular el ANOVA (de un factor) en R usamos el paquete rstatix con la función rstatix::anova_test [5]:\n\nrstatixaov &lt;-\n  data %&gt;%\n  rstatix::anova_test(dv = mood_gain, between = drug, wid = id)\nrstatixaov\n\nANOVA Table (type II tests)\n\n  Effect DFn DFd      F        p p&lt;.05   ges\n1   drug   2  15 18.611 8.65e-05     * 0.713\n\n\nMejoramos la salida de resultados como sigue:\n\nrstatixaov %&gt;%\n  tibble::as_tibble() %&gt;%\n  mutate(p = ifelse(p &lt; 0.001, \"&lt; .001\", signif(p, 2))) %&gt;%\n  mutate(across(where(is.numeric), round, 2)) %&gt;%\n  select(-`p&lt;.05`) %&gt;%\n  flextable::flextable() %&gt;%\n  flextable::autofit()\n\nEffectDFnDFdFpgesdrug21518.61&lt; .0010.71\n\n\nLos resultados revelan un efecto estadísticamente significativo de los tratamientos farmacológicos en el cambio de estado de ánimo. El pequeño valor p (&lt;0.001) indica que es muy poco probable (&lt;0.1 % de probabilidad) obtener estos resultados si los medicamentos no tuvieran un efecto real. Además, el elevado valor de eta cuadrada generalizada (\\(\\eta_G^{2}\\) = 0.71) sugiere que los tratamientos farmacológicos representaron el 71 % de la varianza en las puntuaciones de estado de ánimo. Este gran tamaño del efecto proporciona evidencia de que los medicamentos impactaron sustancialmente el estado de ánimo. Si bien el análisis general proporciona evidencia del efecto del medicamento, todavía no sabemos qué tratamientos farmacológicos específicos condujeron a una ganancia de estado de ánimo superior en comparación con otros. Nuestra visualización anterior nos da algunas pistas, pero para explorarlo formalmente, necesitamos realizar comparaciones a posterior por pares post-hoc análisis.\n\n\n2.2.2 Comparaciones post-hoc: Family Wise Error\nLas comparaciones post-hoc son pruebas estadísticas realizadas para determinar qué pares específicos de grupos de medicamentos difieren significativamente entre sí, al tiempo que se garantiza que el riesgo general de falsos positivos siga siendo bajo. Cuando un ANOVA de una vía da un resultado significativo, solo te dice que existe al menos una diferencia entre las medias de los grupos, pero no te dice cuáles grupos son diferentes. Para saberlo, se realizan pruebas de comparación múltiple. El problema es que cada prueba individual aumenta la probabilidad de cometer un error de Tipo I, un fenómeno conocido como tasa de error familiar y en inglés (Family Wise Error: FWER).\nLa FWER es la probabilidad de cometer al menos un error de tipo I (falso positivo) en una serie o “familia” de pruebas de hipótesis. Cuando se realiza una sola prueba de hipótesis, el riesgo de cometer un error de tipo I está controlado por tu nivel de significación, \\(\\alpha\\) (por ejemplo, \\(\\alpha = 0.05\\)). Sin embargo, cuando realizas múltiples comparaciones (como en un análisis post-hoc después de un ANOVA), el riesgo de cometer al menos un error de tipo I aumenta con cada prueba adicional. Por lo tanto si realizamos 20 pruebas de hipótesis con un \\(\\alpha\\) de 0.05 y todas las hipótesis nulas son verdaderas, la probabilidad de no cometer un solo error de tipo I es \\((1 - 0.05)^{20} \\approx 0.358\\). Esto significa que la probabilidad de cometer al menos un error de tipo I es \\(1 - 0.358 = 0.642\\), lo que es inaceptablemente alto. Para controlar la FWER, se aplican ajustes a los valores p o al nivel de significación. Los métodos más comunes son:\n\n2.2.2.1 Corrección de Bonferroni\nEs el método más simple y conservador. Divide el nivel de significación original (\\(\\alpha\\)) entre el número de comparaciones (\\(m\\)). \\[\\alpha_{ajustado} = \\frac{\\alpha}{m}\\]\nSi el p-valor de una prueba es menor que este nuevo \\(\\alpha_{ajustado}\\), se considera significativo.\nDe igual forma, si en lugar de \\(\\alpha_{ajustado}\\) usamos como criterio el p-valor, este se puede multiplicar por el número de comparaciones:\\(\\text{p-valor\\ ajustado}=\\text{p-valor\\ original}\\times K\\), donde K es el número de comparaciones, para corregir la significacion.\nLa prueba de Bonferroni es un método muy simple y fácil de entender: ajusta el nivel de significación (\\(\\alpha\\)) dividiéndolo por el número de comparaciones que se van a realizar [6].\n\nCuándo usarla:\nCuando tienes un número reducido de comparaciones planeadas (por ejemplo, solo quieres comparar un grupo de tratamiento con el grupo de control).\nEs útil para un control estricto del error de Tipo I, pero puede ser demasiado conservadora y aumentar el riesgo de errores de Tipo II (falsos negativos).\n\n\n\n2.2.2.2 Holm-Bonferroni\nProcedimiento de Holm-Bonferroni: Es una mejora de la corrección de Bonferroni. Es menos conservador y, por lo tanto, más potente. Ajusta los p-valores de manera secuencial.\n1. Se ordenan los p-valores de menor a mayor.\n2. Cada p-valor se compara con un \\(\\alpha\\) ajustado, que aumenta secuencialmente.\n3. El proceso se detiene en la primera prueba que no es significativa, y ninguna de las pruebas restantes se considera significativa.\nLa prueba de Bonferroni es un método muy simple y fácil de entender: ajusta el nivel de significación (\\(\\alpha\\)) dividiéndolo por el número de comparaciones que se van a realizar [6].\n\nCuándo usarla:\n\nCuando tienes un número reducido de comparaciones planeadas (por ejemplo, solo quieres comparar un grupo de tratamiento con el grupo de control).\nEs útil para un control estricto del error de Tipo I, pero puede ser demasiado conservadora y aumentar el riesgo de errores de Tipo II (falsos negativos).\n\n\n\n\n2.2.2.3 Sidak\nContraste de Sidak es un método para controlar la Tasa de Error Familiar (FWER). Se utiliza cuando se realizan múltiples pruebas de hipótesis para reducir la probabilidad de cometer al menos un error de Tipo I (un falso positivo) en el conjunto de todas las pruebas. El método de Sidak es una alternativa menos conservadora y, por lo tanto, más potente que la corrección de Bonferroni. El método de Sidak se basa en el supuesto de que las múltiples pruebas de hipótesis son estadísticamente independientes. Si esta suposición se cumple, la probabilidad de cometer al menos un error de Tipo I se puede calcular de manera más precisa que con el método de Bonferroni. El método ajusta el nivel de significación (\\(\\alpha\\)) para cada prueba individual a un nuevo valor más pequeño (\\(\\alpha_{Sidak}\\)) para asegurar que la FWER general se mantenga en el nivel deseado.\nLa fórmula para el \\(\\alpha\\) ajustado de Sidak es: \\[\\alpha_{Sidak} = 1 - (1 - \\alpha)^{1/m}\\] donde: * \\(\\alpha\\) es la FWER deseada (por ejemplo, 0.05). * \\(m\\) es el número total de comparaciones.\nPara cada prueba individual, si su valor p es menor que \\(\\alpha_{Sidak}\\), se rechaza la hipótesis nula.\nSidak vs. Bonferroni La corrección de Bonferroni es un método más simple y conservador. Se deriva de una desigualdad matemática y no requiere la suposición de independencia. Su fórmula para el \\(\\alpha\\) ajustado es: \\[\\alpha_{Bonferroni} = \\frac{\\alpha}{m}\\]\nDebido a que el método de Sidak se basa en un cálculo de probabilidad más preciso, su \\(\\alpha\\) ajustado es ligeramente mayor que el de Bonferroni, lo que le otorga mayor potencia estadística (menor probabilidad de pasar por alto un efecto real) mientras sigue controlando la FWER.\n\n\n\n\n\n\n\n\nCaracterística\nCorrección de Sidak\nCorrección de Bonferroni\n\n\n\n\nFórmula\n\\(1 - (1 - \\alpha)^{1/m}\\)\n\\(\\alpha/m\\)\n\n\nSupuesto\nRequiere que las pruebas sean independientes\nNo requiere un supuesto de independencia\n\n\nConservadurismo\nMenos conservador\nMuy conservador\n\n\nPotencia Estadística\nMayor\nMenor\n\n\n\nEn la práctica, la diferencia entre ambos métodos es mínima para un número pequeño de comparaciones. Sin embargo, el método de Sidak es teóricamente superior cuando se cumple el supuesto de independencia. Para un enfoque secuencial aún más potente, a menudo se prefiere el método de Holm-Bonferroni.\n\n\n2.2.2.4 Tukey\nTest de Tukey (HSD) El test de Tukey, también conocido como la Diferencia Honestamente Significativa (HSD), es el método preferido cuando el objetivo es comparar todos los pares de medias de grupo. Es muy potente para este tipo de comparaciones y se basa en la distribución del rango studentizado. La prueba de Tukey (Honest Significant Difference) es una de las más utilizadas y recomendadas siempre que el tamaño de los grupos sea homogeneo. Es una prueba conservadora que controla la tasa de error familiar (la probabilidad de cometer al menos un error de Tipo I en todas las comparaciones) de manera efectiva, lo que la hace ideal para la mayoría de las situaciones [7].\nCuándo usarla: * Cuando se cumplen los supuestos del ANOVA (normalidad de los residuos y homogeneidad de las varianzas).\n* Cuando quieres comparar todos los pares posibles de grupos.\n* Para estudios con un tamaño de muestra similar en todos los grupos.\nIdeal para: Comparaciones por pares. Potencia: Es más potente que el test de Scheffé cuando solo se comparan pares. Flexibilidad: Está diseñado específicamente para comparaciones de dos en dos. Si los tamaños de muestra son desiguales, se utiliza una versión modificada llamada Tukey-Kramer. Supuesto: Requiere que la varianza sea homogénea.\n\n\n2.2.2.5 Test de Scheffé\nTest de Scheffé El test de Scheffé es un método más flexible y conservador. Es el único test que puede controlar la FWER para todas las comparaciones posibles, no solo las de pares. Permite realizar contrastes complejos (por ejemplo, comparar la media del Grupo 1 con la media combinada del Grupo 2 y 3).\nIdeal para: Contrastes complejos y todas las comparaciones posibles. Potencia: Es menos potente que el test de Tukey para comparaciones por pares. Por esta razón, no se recomienda si el único interés son los pares. Flexibilidad: Es el método más flexible, ya que puede manejar contrastes de cualquier tipo. También funciona con tamaños de muestra desiguales sin necesidad de ajustes adicionales. Supuesto: Requiere que la varianza sea homogénea.\n\n\n2.2.2.6 Test de Dunnett\nEl test de Dunnett es un procedimiento de comparación múltiple utilizado para comparar varios grupos de tratamiento con un único grupo de control. Es una alternativa a realizar múltiples pruebas t, lo que aumentaría el riesgo de un error de Tipo I (falso positivo). El test de Dunnett está diseñado específicamente para la estructura de comparaciones de “uno a muchos”. Debido a que tiene en cuenta las correlaciones entre las comparaciones es menos conservador que Bonferroni y tiene una mayor capacidad para detectar una diferencia real si existe. Para realizar el test de Dunnett en R, necesitarás el paquete multcomp.\n\n\n2.2.2.7 Prueba de Dunn\nLa prueba de Dunn es la comparación post-hoc más utilizada para la prueba de Kruskal-Wallis. No es una prueba para usar después de un ANOVA, sino la opción correcta cuando la prueba de Kruskal-Wallis es significativa. Cuándo usarla:\nExclusivamente como prueba post-hoc para la prueba no paramétrica de Kruskal-Wallis.\nCuando los datos no cumplen los supuestos de normalidad o homogeneidad de varianzas requeridos por el ANOVA.\n\n\n2.2.2.8 Resumen de las pruebas post-hoc\nCuando te enfrentas a una decisión sobre qué prueba post-hoc usar, la elección depende principalmente del tipo de datos que tienes y las comparaciones que deseas realizar. Aquí tienes un resumen práctico en forma de tabla para ayudarte a elegir la prueba más adecuada. En general, si tu ANOVA es significativo y los supuestos se cumplen (grupos homogeneos en tamaño), la prueba de Tukey y la prueba de Holm son tus mejores opciones para comparar todos los pares de grupos. Si lo que quieres es comparar los grupos con respecto a un único grupo control, entonces test de Dunnett es la opción adecuada. Si tus supuestos no se cumplen y has recurrido a la prueba de Kruskal-Wallis, la prueba de Dunn es la elección adecuada para las comparaciones post-hoc.\n\n\n\n\n\n\n\n\n\nPrueba Post-Hoc\nTipo de Datos\nTipo de Comparaciones\nCuándo Usarla\n\n\n\n\nHolm\nParamétricos (después de un ANOVA)\nMúltiples comparaciones por pares\nCuando quieres un control de la FWER más potente que Bonferroni. Es una excelente opción de propósito general.\n\n\nTukey\nParamétricos (después de un ANOVA)\nTodos los pares de medias\nCuando tu único interés es saber qué pares de grupos difieren entre sí. Es la prueba más potente para este propósito.\n\n\nScheffé\nParamétricos (después de un ANOVA)\nContrastes complejos o todas las comparaciones posibles\nCuando quieres comparar combinaciones de grupos (e.g., Grupo A vs. Grupo B+C). Es muy flexible, pero menos potente para pares.\n\n\nBonferroni\nParamétricos (después de un ANOVA)\nMúltiples comparaciones\nCuando necesitas una corrección simple y muy conservadora. Útil para un número pequeño de pruebas.\n\n\nDunnett\nParamétricos (después de un ANOVA)\nMúltiples comparaciones con respecto a un solo grupo control\nEs menos conservador que Bonferroni y tiene una mayor capacidad para detectar una diferencia real si existe. Esto reduce el riesgo de un error de Tipo II.\n\n\nDunn\nNo paramétricos (después de Kruskal-Wallis)\nMúltiples comparaciones por pares\nCuando los datos no cumplen los supuestos de normalidad o varianza igual. Es el equivalente no paramétrico de Tukey/Holm.\n\n\nSidak\nParamétricos (después de un ANOVA)\nMúltiples comparaciones\nEs una alternativa a Bonferroni, ligeramente más potente, si asumes que las pruebas son independientes.\n\n\n\nPara ejecutar comparaciones por pares se puede usar la función rstatix::emmeans_test():\n\n# Cargar librerías necesarias\n# Si no las tienes instaladas, ejecuta:\n # install.packages(\"rstatix\")\n # install.packages(\"flextable\")\n # install.packages(\"dplyr\")\n # install.packages(\"purrr\") # Para la función map_dfr\n\nlibrary(rstatix)\nlibrary(flextable)\nlibrary(dplyr)\nlibrary(purrr)\n\n# Supongamos que tienes un data.frame llamado 'data' con las variables 'mood_gain' y 'drug'.\n\n# Lista de métodos de ajuste a iterar\nmethods &lt;- c(\"holm\", \"bonferroni\", \"tukey\", \"sidak\", \"scheffe\", \"dunn\")\n\n# Crear una función para procesar cada método\nrun_test_and_summarize &lt;- function(method) {\n  # Ejecutar el test de comparaciones múltiples\n  test_result &lt;- rstatix::emmeans_test(mood_gain ~ drug,\n    data = data,\n    p.adjust.method = method,\n    detailed = TRUE\n  ) %&gt;%\n    mutate(\n      # Añadir una columna con el método de ajuste\n      method = method,\n      # Redondear los valores numéricos\n      across(where(is.numeric), signif, 2)\n    ) %&gt;%\n    # Seleccionar las columnas de interés y reordenar\n    select(method, group1, group2, p.adj) %&gt;%\n    arrange(p.adj)\n\n  return(test_result)\n}\n\n# Usar map_dfr para aplicar la función a cada método y combinar los resultados en un solo data.frame\nsummary_table &lt;- purrr::map_dfr(methods, run_test_and_summarize)\n\n# Crear y mostrar la tabla final con flextable\nsummary_table %&gt;%\n  flextable::flextable() %&gt;%\n  flextable::autofit()\n\nmethodgroup1group2p.adjholmjoyzepamplacebo0.000091holmanxifreejoyzepam0.001100holmanxifreeplacebo0.150000bonferronijoyzepamplacebo0.000091bonferronianxifreejoyzepam0.001700bonferronianxifreeplacebo0.450000tukeyjoyzepamplacebo0.000091tukeyanxifreejoyzepam0.001700tukeyanxifreeplacebo0.390000sidakjoyzepamplacebo0.000091sidakanxifreejoyzepam0.001700sidakanxifreeplacebo0.390000scheffejoyzepamplacebo0.000130scheffeanxifreejoyzepam0.002200scheffeanxifreeplacebo0.340000dunnjoyzepamplacebo0.000087dunnanxifreejoyzepam0.001600dunnanxifreeplacebo0.340000\n\n# Resumen resultados usando Holm\ntable2 &lt;- rstatix::emmeans_test(mood_gain ~ drug,\n    data = data,\n    p.adjust.method = \"holm\",\n    detailed = TRUE\n  )\ntable2 %&gt;%\n  flextable::flextable() %&gt;%\n  flextable::autofit()\n\nterm.y.group1group2null.valueestimatesedfconf.lowconf.highstatisticpp.adjp.adj.signifdrugmood_gainanxifreejoyzepam0-0.76666670.175857715-1.1414985-0.3918349-4.3595860.000560525020.00112105004**drugmood_gainanxifreeplacebo00.26666670.175857715-0.10816510.64149851.5163780.150213062950.15021306295nsdrugmood_gainjoyzepamplacebo01.03333330.1758577150.65850151.40816515.8759630.000030467880.00009140365****\n\n\nLos resultados proporcionan evidencia de una diferencia en la ganancia de estado de ánimo entre joyzepam y anxifree (diff = 0.77), así como entre joyzepam y placebo (diff = 1), pero no entre anxifree y placebo (diff = 0.27).\nComparando los tratamientos versus placebo usamos el método de Dunnett:\n\n# install.packages(\"multcomp\") # Si no tienes instalado el paquete\n# Cargar el paquete 'multcomp'\nlibrary(multcomp)\n# Establecer \"Placebo\" como el nivel de referencia\ndata$drug &lt;- relevel(data$drug, ref = \"placebo\")\n# Realizar un ANOVA de una vía\nanova_model &lt;- aov(mood_gain ~ drug, data = data)\n# Mostrar el resumen del ANOVA\nsummary(anova_model)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ndrug         2  3.453  1.7267   18.61 8.65e-05 ***\nResiduals   15  1.392  0.0928                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Realizar el test de Dunnett\ndunnett_test &lt;- glht(anova_model, linfct = mcp(drug = \"Dunnett\"))\n# Mostrar el resumen del test de Dunnett\nsummary(dunnett_test)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Dunnett Contrasts\n\n\nFit: aov(formula = mood_gain ~ drug, data = data)\n\nLinear Hypotheses:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \nanxifree - placebo == 0   0.2667     0.1759   1.516    0.253    \njoyzepam - placebo == 0   1.0333     0.1759   5.876 5.89e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n\n\n2.2.3 Comprobando las asunciones del test ANOVA\nPara garantizar la validez de los resultados de un ANOVA de un factor, se deben probar varias suposiciones clave. En primer lugar, se supone que los residuos están distribuidos normalmente, lo que a menudo se evalúa visualmente a través de gráficos de residuos. En segundo lugar, la suposición de homogeneidad de varianzas requiere varianzas de población iguales entre los grupos, lo que normalmente se verifica con la prueba de Levene y los gráficos de residuos. En tercer lugar, las observaciones deben ser independientes, no relacionadas y no influenciadas entre sí, lo que generalmente se satisface a través de un diseño experimental y una aleatorización adecuados. Los participantes del ensayo no estaban relacionados y se asignaron aleatoriamente a cada grupo, por lo que es seguro asumir que cada observación es independiente.\nSin embargo, verifiquemos las suposiciones de normalidad e igualdad de varianza usando la función performance::check_models:\n\n# homogeneidad de la varianza\nassumptions &lt;-\n  performance::check_model(lm(mood_gain ~ drug, data = data),\n    check = c(\"homogeneity\", \"normality\")\n  )\nassumptions\n\n\n\n\n\n\n\n\nAquí no vemos violaciones importantes a las suposiciones de igualdad de varianza y normalidad, lo que nos da la confianza de que nuestros resultados son válidos.\n\n\n2.2.4 Redacción de resultados para revista biomédica\nAquí hay un ejemplo para redactar los resultados del ANOVA y de la comparación por pares para su publicación en una revista científica:\n“Un ANOVA de un factor reveló una diferencia significativa en la ganancia de estado de ánimo entre los tres grupos, F(2, 15) = 20.3, p &lt; 0.01, \\(\\eta_G^{2}\\) = 0.71. Se realizaron comparaciones por pares post-hoc utilizando el método de Holm para controlar la tasa de error familiar en las múltiples comparaciones. Los valores p ajustados por Holm indicaron que el grupo joyzepam tuvo una ganancia de estado de ánimo significativamente mayor (M = 1.57, SD = 0.25) en comparación con el placebo (M = 0.45, SD = 0.21) y el grupo anxifree (M = 0.73, SD = 0.36). No hubo una diferencia significativa entre el grupo anxifree y el grupo placebo”.\nAquí se explica cómo poner toda la información más relevante en un solo gráfico que combina la visualización de los datos, el ANOVA y las comparaciones por pares. Para ello, usaremos la función rstatix::add_xy_position() para agregar posiciones xy al marco de datos de rstatix y luego crear un gráfico de caja con el paquete ggpubr. Este gráfico sería un complemento ideal para un artículo científico, ya que combina la visualización de los datos con el ANOVA y las comparaciones por pares, proporcionando una representación clara de las diferencias entre los grupos.\n\n# agregar posición xy al marco de datos de rstatix\nrstatixcomp &lt;- rstatix::emmeans_test(mood_gain ~ drug,\n  data = data,\n  p.adjust.method = \"holm\",\n  detailed = TRUE\n)\nstat_test &lt;-   rstatixcomp %&gt;% rstatix::add_xy_position(x = \"drug\")\n# gráfico de caja usando el paquete ggpubr, agregar medias, ANOVA y resultados por pares\nlibrary(ggpubr)\ndata %&gt;%\n  ggpubr::ggboxplot(\n    y = \"mood_gain\",\n    x = \"drug\",\n    color = \"drug\",\n    add = c(\"dotplot\"),\n    add.params = list(\n      position = position_jitter(w = 0.09, h = 0.04),\n      size = .8\n    ),\n    palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\")\n  ) +\n  scale_y_continuous(breaks = seq(.5, 2, .5)) +\n  coord_cartesian(ylim = c(0.1, 2.3)) +\n  theme(\n    legend.position = \"none\",\n    axis.title.x = element_blank()\n  ) +\n  labs(y = \"Ganancia de estado de ánimo\") +\n  stat_summary(\n    geom = \"point\",\n    fun.y = \"mean\",\n    col = \"black\",\n    size = 2.5,\n    shape = 24,\n  ) +\n  ggpubr::stat_pvalue_manual(stat_test,\n    label = \"p.adj.signif\",\n    tip.length = 0.01,\n    hide.ns = T,\n    bracket.nudge.y = -.03\n  ) +\n  ggpubr::stat_anova_test(label = \"as_detailed_italic\", label.y.npc = 1)\n\n\n\n\n\n\n\n\nEste gráfico combina la visualización de los datos con el ANOVA y las comparaciones post-hoc, proporcionando una representación clara de las diferencias entre los grupos. Las barras de error indican la variabilidad dentro de cada grupo, mientras que las anotaciones muestran los resultados del ANOVA y las comparaciones por pares.\n\n\n2.2.5 Reflexiones finales\nCon tantas opciones disponibles, ejecutar ANOVA en R puede parecer desalentador al principio, pero desglosarlo en pasos manejables hace que el proceso sea mucho más accesible. Aprovechar el paquete rstatix es un enfoque plausible, ya que no solo simplifica los cálculos requeridos para ANOVA, sino que también proporciona una gama de funciones para ayudar a comunicar los resultados de manera efectiva.\nNota: Este conjunto de datos se toma de un artículo que explica cómo calcular ANOVA en jamovi. Esto me permitió comparar directamente los resultados generados por R con los que se pueden recrear usando el software jamovi. Se puede acceder al conjunto de datos aquí.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TEMA 2: ANÁLISIS DE LA VARIANZA</span>"
    ]
  },
  {
    "objectID": "TEMA-2.html#anova-de-un-factor-con-r-base",
    "href": "TEMA-2.html#anova-de-un-factor-con-r-base",
    "title": "2  TEMA 2: ANÁLISIS DE LA VARIANZA",
    "section": "2.3 ANOVA de un factor con R base",
    "text": "2.3 ANOVA de un factor con R base\nClaro, puedes realizar un ANOVA de un factor con R base sin necesidad de paquetes adicionales. La función principal para esto es aov().\nAquí tienes un ejemplo paso a paso utilizando un conjunto de datos ficticio similar al del ejemplo anterior. Primero, vamos a crear un data.frame con los datos del ensayo clínico.\n\n# Crear el data.frame\ndatos_clinicos &lt;- data.frame(\n  mood_gain = c(0.5, 0.3, 0.1, 0.6, 0.4, 0.2, 1.4, 1.7, 1.3,\n                     0.6, 0.9, 0.3, 1.1, 0.8, 1.2, 1.8, 1.3, 1.4),\n  grupo_medicamento = factor(rep(c(\"placebo\", \"anxifree\", \"joyzepam\"), each = 6))\n)\n\n# Describir los datos\nsummary(datos_clinicos)\n\n   mood_gain      grupo_medicamento\n Min.   :0.1000   anxifree:6       \n 1st Qu.:0.4250   joyzepam:6       \n Median :0.8500   placebo :6       \n Mean   :0.8833                    \n 3rd Qu.:1.3000                    \n Max.   :1.8000                    \n\n# Medias por grupo\nlibrary(dplyr)\ndatos_clinicos %&gt;%\n  group_by(grupo_medicamento) %&gt;%\n  summarise(media = mean(mood_gain), sd = sd(mood_gain))\n\n# A tibble: 3 × 3\n  grupo_medicamento media    sd\n  &lt;fct&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 anxifree           1.03 0.528\n2 joyzepam           1.27 0.333\n3 placebo            0.35 0.187\n\n# Visualizar los primeros registros\nhead(datos_clinicos)\n\n  mood_gain grupo_medicamento\n1       0.5           placebo\n2       0.3           placebo\n3       0.1           placebo\n4       0.6           placebo\n5       0.4           placebo\n6       0.2           placebo\n\n\nEs fundamental que la variable que define los grupos (en este caso, grupo_medicamento) sea de tipo factor. Si no lo es, puedes convertirla con as.factor(). Para realizar un ANOVA de un factor en R base, puedes usar la función aov(). Esta función ajusta un modelo lineal y realiza el análisis de varianza. En este caso, queremos evaluar si hay diferencias significativas en la variable mood_gain entre los diferentes grupos de medicamentos (grupo_medicamento).\n\n# Realizar el análisis de varianza\nmodelo_anova &lt;- aov(mood_gain ~ grupo_medicamento, data = datos_clinicos)\n\n# Mostrar el resumen del modelo\nsummary(modelo_anova)\n\n                  Df Sum Sq Mean Sq F value  Pr(&gt;F)   \ngrupo_medicamento  2  2.723  1.3617   9.627 0.00204 **\nResiduals         15  2.122  0.1414                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa salida de summary(modelo_anova) te mostrará la tabla de ANOVA con información clave como la Suma de Cuadrados, los grados de libertad (Df), el valor F y el valor p (Pr(&gt;F)). Si el valor p es menor que tu nivel de significación (comúnmente 0.05), puedes concluir que existen diferencias significativas entre las medias de los grupos.\n\n2.3.1 Realizar comparaciones post-hoc\nSi el ANOVA es significativo, necesitas realizar comparaciones post-hoc para saber qué grupos específicos son diferentes entre sí. Para esto, puedes usar la función TukeyHSD(), que realiza la prueba de diferencia honestamente significativa de Tukey (Tukey’s Honest Significant Difference). La función TukeyHSD() es la única que viene por defecto en R base para una prueba post-hoc completa. Esta función te dará una tabla con las comparaciones por pares de todos los grupos. Los valores p ajustados (p adj) en la tabla te indicarán qué pares de grupos tienen diferencias estadísticamente significativas. Si p adj es menor a 0.05, el par de grupos es significativamente diferente. Para el resto de los métodos, se debe recurrir a la función pairwise.t.test() y especificar el método de ajuste. Este enfoque de R base funciona, pero requiere más pasos manuales, lo que justifica el uso de librerías como rstatix para simplificar y automatizar el proceso. El código anterior sigue siendo funcional, pero ahora puedes ver la diferencia en la complejidad.\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = mood_gain ~ drug, data = data)\n\n$drug\n                       diff        lwr       upr     p adj\nanxifree-placebo  0.2666667 -0.1901184 0.7234518 0.3115006\njoyzepam-placebo  1.0333333  0.5765482 1.4901184 0.0000854\njoyzepam-anxifree 0.7666667  0.3098816 1.2234518 0.0015284\n\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  data$mood_gain and data$drug \n\n         placebo anxifree\nanxifree 0.4506  -       \njoyzepam 9.1e-05 0.0017  \n\nP value adjustment method: bonferroni \n\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  data$mood_gain and data$drug \n\n         placebo anxifree\nanxifree 0.1502  -       \njoyzepam 9.1e-05 0.0011  \n\nP value adjustment method: holm \n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = mood_gain ~ drug, data = data)\n\n$drug\n                       diff        lwr       upr     p adj\nanxifree-placebo  0.2666667 -0.1901184 0.7234518 0.3115006\njoyzepam-placebo  1.0333333  0.5765482 1.4901184 0.0000854\njoyzepam-anxifree 0.7666667  0.3098816 1.2234518 0.0015284\n\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  data$mood_gain and data$drug \n\n         placebo anxifree\nanxifree 0.4506  -       \njoyzepam 9.1e-05 0.0017  \n\nP value adjustment method: bonferroni \n\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  data$mood_gain and data$drug \n\n         placebo anxifree\nanxifree 0.1502  -       \njoyzepam 9.1e-05 0.0011  \n\nP value adjustment method: holm \n\n\n\n\n2.3.2 Verificar las suposiciones del test\nPara asegurarte de que los resultados del ANOVA son válidos, es importante verificar las suposiciones del modelo: normalidad de los residuos y homogeneidad de las varianzas.\n\n# Gráficos de diagnóstico para verificar supuestos\nplot(modelo_anova)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEsto generará cuatro gráficos de diagnóstico que te ayudarán a visualizar:\nNormalidad de los residuos: El gráfico Normal Q-Q debe mostrar los puntos alineados cerca de la línea diagonal.\nHomogeneidad de las varianzas: El gráfico Residuals vs. Fitted debe mostrar los puntos distribuidos aleatoriamente, sin patrones evidentes.\nSi estas suposiciones no se cumplen, podrías considerar utilizar pruebas no paramétricas como la prueba de Kruskal-Wallis, que también está disponible en R base con la función kruskal.test().\nPara usar la prueba de Kruskal-Wallis en R, primero necesitas tener un conjunto de datos donde la variable de grupo sea un factor y la variable de resultado sea numérica. Esta prueba es la alternativa no paramétrica al ANOVA de un factor, utilizada cuando no se cumplen las suposiciones de normalidad u homogeneidad de varianzas [8].",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TEMA 2: ANÁLISIS DE LA VARIANZA</span>"
    ]
  },
  {
    "objectID": "TEMA-2.html#test-no-paramétrico-kruskal-wallis-test",
    "href": "TEMA-2.html#test-no-paramétrico-kruskal-wallis-test",
    "title": "2  TEMA 2: ANÁLISIS DE LA VARIANZA",
    "section": "2.4 Test No Paramétrico: Kruskal-Wallis Test",
    "text": "2.4 Test No Paramétrico: Kruskal-Wallis Test\nAquí tienes un ejemplo con un conjunto de datos ficticio:\n\n2.4.1 Preparar los datos\nVamos a crear un data.frame con los mismos datos del ejemplo anterior, pero supongamos que no cumplen con los supuestos del ANOVA.\n\n# Crear el data.frame\ndatos_clinicos &lt;- data.frame(\n  mood_gain = c(0.5, 0.3, 0.1, 0.6, 0.4, 0.2, 1.4, 1.7, 1.3,\n                     0.6, 0.9, 0.3, 1.1, 0.8, 1.2, 1.8, 1.3, 1.4),\n  grupo_medicamento = factor(rep(c(\"placebo\", \"anxifree\", \"joyzepam\"), each = 6))\n)\n\n# Describir los datos\nsummary(datos_clinicos)\n\n   mood_gain      grupo_medicamento\n Min.   :0.1000   anxifree:6       \n 1st Qu.:0.4250   joyzepam:6       \n Median :0.8500   placebo :6       \n Mean   :0.8833                    \n 3rd Qu.:1.3000                    \n Max.   :1.8000                    \n\n# Medias por grupo\nlibrary(dplyr)\ndatos_clinicos %&gt;%\n  group_by(grupo_medicamento) %&gt;%\n  summarise(media = mean(mood_gain), sd = sd(mood_gain))\n\n# A tibble: 3 × 3\n  grupo_medicamento media    sd\n  &lt;fct&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 anxifree           1.03 0.528\n2 joyzepam           1.27 0.333\n3 placebo            0.35 0.187\n\n# Visualizar los datos\nprint(datos_clinicos)\n\n   mood_gain grupo_medicamento\n1        0.5           placebo\n2        0.3           placebo\n3        0.1           placebo\n4        0.6           placebo\n5        0.4           placebo\n6        0.2           placebo\n7        1.4          anxifree\n8        1.7          anxifree\n9        1.3          anxifree\n10       0.6          anxifree\n11       0.9          anxifree\n12       0.3          anxifree\n13       1.1          joyzepam\n14       0.8          joyzepam\n15       1.2          joyzepam\n16       1.8          joyzepam\n17       1.3          joyzepam\n18       1.4          joyzepam\n\n\n\n\n2.4.2 Realizar la prueba de Kruskal-Wallis\nLa función en R base para esta prueba es kruskal.test(). La sintaxis es similar a aov(), usando una fórmula: variable_dependiente ~ variable_independiente.\n\n# Realizar la prueba de Kruskal-Wallis\nresultado_kruskal &lt;- kruskal.test(mood_gain ~ grupo_medicamento, data = datos_clinicos)\n\n# Mostrar el resultado\nprint(resultado_kruskal)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  mood_gain by grupo_medicamento\nKruskal-Wallis chi-squared = 9.4425, df = 2, p-value = 0.008904\n\n\nLa salida te mostrará la chi-cuadrado, los grados de libertad y el valor p. En este ejemplo, el valor p será muy pequeño (p &lt; 0.05), lo que indica que hay diferencias estadísticamente significativas en las medianas de los grupos.\n\n\n2.4.3 Realizar comparaciones post-hoc\nLa función kruskal.test() solo te dice si hay una diferencia general, pero no entre qué grupos específicos. Para esto, necesitas realizar comparaciones post-hoc. Aunque no hay una función de R base para las comparaciones post-hoc de Kruskal-Wallis, puedes usar paquetes como dunn.test o agricolae [6].\nAquí te muestro cómo hacerlo con el paquete dunn.test:\n\n# Instalar el paquete (solo si no lo tienes)\n# install.packages(\"dunn.test\")\n\n# Cargar el paquete\nlibrary(dunn.test)\n\n# Realizar la prueba post-hoc de Dunn\ndunn.test(datos_clinicos$mood_gain, datos_clinicos$grupo_medicamento, method=\"bonferroni\")\n\n  Kruskal-Wallis rank sum test\n\ndata: x and group\nKruskal-Wallis chi-squared = 9.4425, df = 2, p-value = 0.01\n\n                           Comparison of x by group                            \n                                 (Bonferroni)                                  \nCol Mean-|\nRow Mean |   anxifree   joyzepam\n---------+----------------------\njoyzepam |  -0.650229\n         |     0.7733\n         |\n placebo |   2.275801   2.926031\n         |     0.0343    0.0051*\n\nalpha = 0.05\nReject Ho if p &lt;= alpha/2\n\n\nEl argumento method=\"bonferroni\" ajusta los valores p para controlar la tasa de error por comparaciones múltiples. La salida te mostrará las comparaciones por pares y sus respectivos valores p ajustados. Los pares con valores p ajustados menores a 0.05 son significativamente diferentes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TEMA 2: ANÁLISIS DE LA VARIANZA</span>"
    ]
  },
  {
    "objectID": "TEMA-2.html#anova-de-dos-vías-factorial",
    "href": "TEMA-2.html#anova-de-dos-vías-factorial",
    "title": "2  TEMA 2: ANÁLISIS DE LA VARIANZA",
    "section": "2.5 ANOVA de dos vías (Factorial)",
    "text": "2.5 ANOVA de dos vías (Factorial)\nEl ANOVA de dos vías, también conocido como ANOVA factorial, es un método estadístico utilizado para analizar el efecto de dos variables independientes (factores) sobre una variable dependiente continua. Este tipo de ANOVA permite evaluar no solo los efectos principales de cada factor, sino también la interacción entre ellos. A continuación, se explica cómo realizar un ANOVA de dos vías en R.\n\n2.5.1 Preparar los datos\nPara ilustrar el ANOVA de dos vías, vamos a crear un conjunto de datos ficticio. Supongamos que estamos estudiando el efecto de dos factores: tipo de medicamento (A, B) y dosis (baja, alta) sobre la ganancia de peso de dos muestras de 100 ratones cada una.\n\n# Crear el data.framen datos ganancia peso en gramos ratones \nset.seed(123) # Para reproducibilidad\n# Datos con intereacción entre factores \ndatos &lt;- data.frame(\n  peso_gain = c(rnorm(100, mean=2, sd=5), rnorm(100, mean=10,sd=6),\n                rnorm(100, mean=7, sd=5), rnorm(100, mean=2,sd=7)),\n  medicamento = factor(rep(c(\"A\", \"A\", \"B\", \"B\"), each = 100)),\n  dosis = factor(rep(c(\"alta\", \"baja\"), times = 200))\n)    \n# Describir los datos\nsummary(datos)\n\n   peso_gain        medicamento  dosis    \n Min.   :-15.2613   A:200       alta:200  \n 1st Qu.:  0.9115   B:200       baja:200  \n Median :  5.1518                         \n Mean   :  5.2889                         \n 3rd Qu.:  9.2004                         \n Max.   : 29.4462                         \n\n# Medias por grupo\nlibrary(dplyr)\ndatos %&gt;%\n  group_by(medicamento, dosis) %&gt;%\n  summarise(media = mean(peso_gain), sd = sd(peso_gain))\n\n`summarise()` has grouped output by 'medicamento'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 4\n# Groups:   medicamento [2]\n  medicamento dosis media    sd\n  &lt;fct&gt;       &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A           alta   5.98  6.08\n2 A           baja   5.83  6.45\n3 B           alta   5.11  6.81\n4 B           baja   4.24  6.79\n\n# Visualizar los primeros registros\nhead(datos)\n\n   peso_gain medicamento dosis\n1 -0.8023782           A  alta\n2  0.8491126           A  baja\n3  9.7935416           A  alta\n4  2.3525420           A  baja\n5  2.6464387           A  alta\n6 10.5753249           A  baja\n\n\n\n\n2.5.2 Realizar el ANOVA de dos vías\n\n# Realizar el análisis de varianza de dos vías\nmodelo_anova_dos_vias &lt;- aov(peso_gain ~ medicamento * dosis, \n                             data = datos)\n# Mostrar el resumen del modelo\nsummary(modelo_anova_dos_vias)\n\n                   Df Sum Sq Mean Sq F value Pr(&gt;F)  \nmedicamento         1    151  151.04   3.535 0.0608 .\ndosis               1     26   26.34   0.616 0.4328  \nmedicamento:dosis   1     13   13.02   0.305 0.5813  \nResiduals         396  16920   42.73                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa salida te mostrará los efectos principales de cada factor (medicamento y dosis) y la interacción entre ellos. Si el valor p de alguno de estos efectos es menor que 0.05, se considera que hay una diferencia significativa.\nPara obtener un gráfico que visualice los resultados del ANOVA de dos vías, puedes usar el paquete ggplot2. Aquí tienes un ejemplo de cómo crear un gráfico de interacción:\n\n# Cargar librería ggplot2\nlibrary(ggplot2)\n# Crear un gráfico de interacción\nggplot(datos, aes(x = medicamento, y = peso_gain, color = dosis)) +\n  geom_point(position = position_jitter(width = 0.1, height = 0)) +\n  geom_boxplot(alpha = 0.5, outlier.shape = NA) +\n  stat_summary(fun = mean, geom = \"point\", shape = 18, size = 3, color = \"black\", position = position_dodge(width = 0.75)) +\n  labs(title = \"Interacción entre Medicamento y Dosis en Ganancia de Peso\",\n       x = \"Tipo de Medicamento\",\n       y = \"Ganancia de Peso\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n2.5.3 Visualizando la presencia o no de una interación\n\n# Interaction plot\ninteraction.plot(datos$medicamento, datos$dosis, datos$peso_gain,\n                 col = c(\"blue\", \"red\"), lty = 1, lwd = 2,\n                 xlab = \"Tipo de Medicamento\", ylab = \"Ganancia de Peso\",\n                 main = \"Interacción entre Medicamento y Dosis\")\n\n\n\n\n\n\n\n\n\n\n2.5.4 Comprobando las asunciones del test ANOVA de dos vías\nAl igual que con el ANOVA de un factor, es importante verificar las suposiciones del modelo para el ANOVA de dos vías. Estas suposiciones incluyen la normalidad de los residuos y la homogeneidad de las varianzas. Puedes usar la función performance::check_model() para evaluar estas suposiciones.\n\n# Verificar las suposiciones del ANOVA de dos vías\nassumptions_dos_vias &lt;-\n  performance::check_model(lm(peso_gain ~ medicamento * dosis, data = datos),\n    check = c(\"homogeneity\", \"normality\")\n  )\nassumptions_dos_vias\n\n\n\n\n\n\n\n\n\n\n2.5.5 Narrativa de resultados para publicación científica\nAquí tienes un ejemplo de cómo redactar los resultados del ANOVA de dos vías para su publicación en una revista científica: “Se realizó un ANOVA de dos vías para evaluar el efecto del tipo de medicamento (A, B) y la dosis (baja, alta) sobre la ganancia de peso en ratones. Los resultados indicaron la ausencia de un efecto significativo del tipo de medicamento, F = 3.535, p &gt; 0.05, y de la dosis, F = 0.616, p &gt; 0.05. Además, no se observó una interacción significativa entre el tipo de medicamento y la dosis, F = 0.305, p &gt; 0.05. Estos resultados sugieren que tanto el tipo de medicamento como la dosis NO influyen en la ganancia de peso, y que el efecto de la dosis NO varía según el tipo de medicamento administrado.”",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TEMA 2: ANÁLISIS DE LA VARIANZA</span>"
    ]
  },
  {
    "objectID": "TEMA-2.html#anova-de-medidas-repetidas",
    "href": "TEMA-2.html#anova-de-medidas-repetidas",
    "title": "2  TEMA 2: ANÁLISIS DE LA VARIANZA",
    "section": "2.6 ANOVA de medidas repetidas",
    "text": "2.6 ANOVA de medidas repetidas\nEl ANOVA de medidas repetidas es una extensión del ANOVA que se utiliza cuando las mismas unidades experimentales (por ejemplo, sujetos) son medidas en múltiples condiciones o en diferentes momentos en el tiempo [9]. Este diseño permite controlar la variabilidad entre sujetos, ya que cada sujeto actúa como su propio control. A continuación, se explica cómo realizar un ANOVA de medidas repetidas en R.\nSupongamos que estamos estudiando el efecto de tres tipos de terapia (Terapia A, Terapia B y Terapia C) sobre la reducción del estrés en un grupo de 30 pacientes. Cada paciente recibe las tres terapias en diferentes momentos, y medimos su nivel de estrés después de cada terapia.\n\n# Crear el data.frame\nset.seed(123) # Para reproducibilidad\ndatos_medidas_repetidas &lt;- data.frame(\n  paciente = factor(rep(1:30, each = 3)),\n  terapia = factor(rep(c(\"A\", \"B\", \"C\"), times = 30)),\n  nivel_estres = c(rnorm(30, mean=50, sd=10), \n                   rnorm(30, mean=45, sd=10), \n                   rnorm(30, mean=40, sd=10))\n)\n# Describir los datos\nsummary(datos_medidas_repetidas)\n\n    paciente  terapia  nivel_estres  \n 1      : 3   A:30    Min.   :16.91  \n 2      : 3   B:30    1st Qu.:39.43  \n 3      : 3   C:30    Median :44.42  \n 4      : 3           Mean   :45.52  \n 5      : 3           3rd Qu.:51.44  \n 6      : 3           Max.   :67.87  \n (Other):72                          \n\n# Medias por grupo\nlibrary(dplyr)\ndatos_medidas_repetidas %&gt;%\n  group_by(terapia) %&gt;%\n  summarise(media = mean(nivel_estres), sd = sd(nivel_estres))\n\n# A tibble: 3 × 3\n  terapia media    sd\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 A        47.2  8.09\n2 B        43.6  9.08\n3 C        45.8 11.6 \n\n# Visualizar los primeros registros\nhead(datos_medidas_repetidas)\n\n  paciente terapia nivel_estres\n1        1       A     44.39524\n2        1       B     47.69823\n3        1       C     65.58708\n4        2       A     50.70508\n5        2       B     51.29288\n6        2       C     67.15065\n\n\n\n2.6.1 Realizar el ANOVA de medidas repetidas\n\n# Realizar el análisis de varianza de medidas repetidas\n# install.packages(\"ez\") # Si no tienes instalado el paquete\n# Para evitar notación científica en los resultados\noptions(scipen = 999)\nlibrary(ez)\nmodelo_anova_medidas_repetidas &lt;- ezANOVA(\n  data = datos_medidas_repetidas,\n  dv = .(nivel_estres),\n  wid = .(paciente),\n  within = .(terapia),\n  type = 3,\n  detailed = TRUE\n)\n# Mostrar el resumen del modelo\nprint(modelo_anova_medidas_repetidas)\n\n$ANOVA\n       Effect DFn DFd        SSn      SSd           F\n1 (Intercept)   1  29 186476.913 2759.407 1959.780035\n2     terapia   2  58    201.968 5411.246    1.082389\n                                     p p&lt;.05        ges\n1 0.0000000000000000000000000003509487     * 0.95802335\n2 0.3455290794281173361035541802266380       0.02412244\n\n$`Mauchly's Test for Sphericity`\n   Effect         W         p p&lt;.05\n2 terapia 0.8574288 0.1160841      \n\n$`Sphericity Corrections`\n   Effect      GGe     p[GG] p[GG]&lt;.05       HFe     p[HF] p[HF]&lt;.05\n2 terapia 0.875219 0.3392773           0.9268615 0.3420388          \n\n\nEl ANOVA de medidas repetidas asume la esfericidad, que significa que las varianzas de las diferencias entre todas las combinaciones posibles de condiciones son iguales. Para verificar esta suposición, se utiliza el test de esfericidad de Mauchly. Si el test es significativo (p &lt; 0.05), indica que la suposición de esfericidad ha sido violada, y se deben aplicar correcciones como Greenhouse-Geisser o Huynh-Feldt para ajustar los grados de libertad del ANOVA.\n\n# Verificar la esfericidad con el test de Mauchly\nmauchly_test &lt;- modelo_anova_medidas_repetidas$Mauchly\nprint(mauchly_test)\n\n   Effect         W         p p&lt;.05\n2 terapia 0.8574288 0.1160841      \n\n# Si el p-valor es menor que 0.05, se debe aplicar una corrección\n# Aplicar corrección de Greenhouse-Geisser si es necesario\nif (mauchly_test$p &lt; 0.05) {\n  cat(\"La suposición de esfericidad ha sido violada. Aplicando corrección de Greenhouse-Geisser.\\n\")\n  modelo_anova_medidas_repetidas$ANOVA$`p[GG]` &lt;- modelo_anova_medidas_repetidas$ANOVA$`p[GG]`\n  print(modelo_anova_medidas_repetidas$ANOVA)\n} else {\n  cat(\"La suposición de esfericidad se cumple. No es necesaria una corrección.\\n\")\n}\n\nLa suposición de esfericidad se cumple. No es necesaria una corrección.\n\n\nLa salida te mostrará el efecto principal de la terapia. Si el valor p es menor que 0.05, se considera que hay una diferencia significativa en los niveles de estrés entre las diferentes terapias. Después de un ANOVA de medidas repetidas significativo, es común realizar comparaciones post-hoc para identificar qué terapias específicas difieren entre sí. Puedes usar la función pairwise.t.test() con el argumento p.adjust.method para ajustar los valores p por comparaciones múltiples.\n\n\n2.6.2 Realizar comparaciones post-hoc\n\n# Realizar comparaciones post-hoc con ajuste de Bonferroni\npost_hoc &lt;- pairwise.t.test(datos_medidas_repetidas$nivel_estres, \n                            datos_medidas_repetidas$terapia, \n                            paired = TRUE, \n                            p.adjust.method = \"bonferroni\")\n# Mostrar los resultados de las comparaciones post-hoc\nprint(post_hoc)\n\n\n    Pairwise comparisons using paired t tests \n\ndata:  datos_medidas_repetidas$nivel_estres and datos_medidas_repetidas$terapia \n\n  A    B   \nB 0.29 -   \nC 1.00 1.00\n\nP value adjustment method: bonferroni \n\n\nLos valores p ajustados te indicarán qué pares de terapias tienen diferencias estadísticamente significativas. Si un p-valor ajustado es &lt;0.05, el par de terapias es significativamente diferente. Describir los resultados del ANOVA de medidas repetidas y las comparaciones post-hoc en un formato adecuado para su publicación científica es crucial. Aquí tienes un ejemplo de cómo redactar estos resultados:\n\n\n2.6.3 Narrativo de los resultados para publicación científica basado en el ejemplo anterior\n“Se realizó un ANOVA de medidas repetidas para evaluar el efecto de tres tipos de terapia (A, B y C) sobre la reducción del estrés en 30 pacientes. Los resultados indicaron la ausencia de una diferencia significativa en los niveles de estrés entre las terapias, F = 1.08, p = 0.345, \\(\\eta_G^{2}\\) = 0.02. El test de esfericidad de Mauchly indicó que la suposición de esfericidad se cumplía (p &gt;0.05), por lo que no fue necesaria una corrección, confirmando la ausencia de efecto de las terapias en los niveles de estrés. Las comparaciones post-hoc con ajuste de Bonferroni revelaron que la Terapia A (M = 47.19, SD = 8.08) resultó en niveles de estrés más altos en comparación con la Terapia B (M = 43.56, SD = 9.08, p = 0.29) y la Terapia C (M = 45.79, SD = 11.56, p = 1.00) aunque sin diferencias estadísticamente significativas. Además, la Terapia B mostró niveles de estrés más bajos que la Terapia C pero sin significación estadística (p = 1.00), s. Estos resultados sugieren que las diferentes terapias NO tienen efectos distintos en la reducción del estrés.”",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TEMA 2: ANÁLISIS DE LA VARIANZA</span>"
    ]
  },
  {
    "objectID": "TEMA-2.html#test-de-friedman",
    "href": "TEMA-2.html#test-de-friedman",
    "title": "2  TEMA 2: ANÁLISIS DE LA VARIANZA",
    "section": "2.7 Test de Friedman",
    "text": "2.7 Test de Friedman\nEl test de Friedman es la prueba no paramétrica equivalente al ANOVA de medidas repetidas de un factor. Se utiliza para determinar si existen diferencias estadísticamente significativas entre las medianas de tres o más grupos que están relacionados. Se aplica cuando los datos no siguen una distribución normal o las suposiciones para un ANOVA paramétrico no se cumplen y los mismos sujetos son evaluados en tres o más momentos diferentes en el tiempo [10].\nA continuación, se demuestra cómo realizar un test de Friedman con un conjunto de datos basado en el ejemplo anterior sobre tres fármacos y su efecto en el nivel de estrés de los pacientes. Al ejecutar el código anterior, se obtendrán dos tablas. La primera corresponde al test de Friedman y la segunda tabla muestra los resultados de las pruebas post-hoc de Wilcoxon, que solo se ejecutan si el test de Friedman es significativo.\n\nlibrary(tidyverse)\n# --- 1. Crear un conjunto de datos de ejemplo ---\n# Suponemos un estudio donde 10 sujetos son evaluados en 3 momentos diferentes\n# para medir su nivel de estrés (puntuación del 1 al 10).\n# Este es un diseño de medidas repetidas.\n\nset.seed(123) # Para que los resultados sean reproducibles\ndatos &lt;- data.frame(\n  id = factor(1:10),\n  A = c(8, 7, 6, 9, 5, 8, 7, 6, 5, 9),\n  B = c(7, 6, 5, 8, 4, 7, 6, 5, 4, 8),\n  C = c(5, 5, 4, 6, 3, 6, 5, 4, 3, 7)\n)\n\n# Convertir los datos a un formato largo (long format), que es requerido\n# por la mayoría de las funciones de rstatix.\ndatos_long &lt;- datos %&gt;%\n  gather(key = \"tratamiento\", value = \"puntuacion_estres\", A, B, C) %&gt;%\n  convert_as_factor(id, tratamiento)\n\n# --- 2. Describir las medianas de los tiempos ---\n# Calcule las medianas para cada punto de tiempo.\nmedianas_por_tiempo &lt;- datos_long %&gt;%\n  group_by(tratamiento) %&gt;%\n  summarise(mediana_estres = median(puntuacion_estres))\n\nprint(\"\\nMedianas de las puntuaciones de estrés por tiempo:\")\n\n[1] \"\\nMedianas de las puntuaciones de estrés por tiempo:\"\n\nprint(medianas_por_tiempo)\n\n# A tibble: 3 × 2\n  tratamiento mediana_estres\n  &lt;fct&gt;                &lt;dbl&gt;\n1 A                        7\n2 B                        6\n3 C                        5\n\n# --- 3. Graficar los resultados ---\n\n# Gráfico de caja (box plot) para visualizar la distribución de los datos\n# en cada momento.\ngrafico_caja &lt;- datos_long %&gt;%\n  ggplot(aes(x = tratamiento, y = puntuacion_estres, fill = tratamiento )) + \n  geom_boxplot() +\n  labs(\n    title = \"Distribución de Puntuaciones de Estrés por Tiempo\",\n    x = \"Tratamiento\",\n    y = \"Puntuación de Estrés\"\n  ) +\n  theme_minimal()\n\nprint(grafico_caja)\n\n\n\n\n\n\n\n# Gráfico de líneas para mostrar la tendencia de las medianas.\ngrafico_lineas &lt;- medianas_por_tiempo %&gt;%\n  ggplot(aes(x = tratamiento, y = mediana_estres, group = 1)) +\n  geom_line(color = \"blue\", size = 1.5) +\n  geom_point(color = \"blue\", size = 3) +\n  labs(\n    title = \"Mediana de Puntuaciones de Estrés a lo Largo del Tiempo\",\n    x = \"Tratamiento\",\n    y = \"Mediana de Puntuación de Estrés\"\n  ) +\n  theme_minimal()\n\nprint(grafico_lineas)\n\n\n\n\n\n\n\n\n\n# 1. Realizar el test de Friedman ---\n# La función friedman_test() del paquete rstatix es fácil de usar.\n# dv = variable dependiente\n# wid = identificador del sujeto (subject ID)\n# within = factor de medidas repetidas (el tiempo en este caso)\n\nres_friedman &lt;- datos_long %&gt;%\n  friedman_test(puntuacion_estres ~ tratamiento | id)\n\n# Imprimir los resultados del test de Friedman.\nprint(\"Resultados del Test de Friedman:\")\n\n[1] \"Resultados del Test de Friedman:\"\n\nprint(res_friedman)\n\n# A tibble: 1 × 6\n  .y.                   n statistic    df         p method       \n* &lt;chr&gt;             &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;        \n1 puntuacion_estres    10        20     2 0.0000454 Friedman test\n\n# 2. Realizar pruebas post-hoc si el resultado es significativo ---\n# Si el valor p del test de Friedman es menor a 0.05,\n# significa que hay una diferencia en algún lugar.\n# Necesitamos una prueba post-hoc para saber entre qué grupos específicos\n# se encuentran las diferencias.\n# El test de Wilcoxon de pares es la opción post-hoc no paramétrica.\n\nif (res_friedman$p &lt; 0.05) {\n  print(\"\\nEl test de Friedman es significativo. Realizando pruebas post-hoc...\")\n  \n  res_posthoc &lt;- datos_long %&gt;%\n    pairwise_wilcox_test(\n      puntuacion_estres ~ tratamiento,\n      paired = TRUE,\n      p.adjust.method = \"bonferroni\" # Se utiliza el método de Bonferroni para ajustar el valor p\n    )\n  \n  # Imprimir los resultados de las pruebas post-hoc.\n  print(res_posthoc)\n}\n\n[1] \"\\nEl test de Friedman es significativo. Realizando pruebas post-hoc...\"\n# A tibble: 3 × 9\n  .y.               group1 group2    n1    n2 statistic     p p.adj p.adj.signif\n* &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       \n1 puntuacion_estres A      B         10    10        55 0.002 0.006 **          \n2 puntuacion_estres A      C         10    10        55 0.004 0.011 *           \n3 puntuacion_estres B      C         10    10        55 0.004 0.011 *           \n\n\n\n2.7.1 Narrativo de los resultados para publicación\n“Se utilizó un Test de Friedman para evaluar si existían diferencias estadísticamente significativas en las puntuaciones de estrés a lo largo del tiempo de tres tratamientos (A, B y C). El test reveló una diferencia significativa en las medianas de las puntuaciones de estrés a lo largo del tiempo, \\(\\chi^{2}\\) = 17.5, p &lt;0.001. Dado que la prueba de Friedman fue significativa, se realizaron análisis post-hoc con el test de rangos con signo de Wilcoxon para las comparaciones por pares, ajustando el valor p con el método de Bonferroni. Los resultados indicaron que las puntuaciones de estrés disminuyeron significativamente entre los grupos comparadas de dos en dos. Así las dfirencias entre A y B (p &lt;0.01), A y C (p &lt;0.05), y B y C (p &lt;0.05), fueron estadísticamente significativas. Estos hallazgos sugieren que el nivel de estrés de los participantes se redujo notablemente durante el período del estudio, con una caída principal entre la primera y la segunda medición.”",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TEMA 2: ANÁLISIS DE LA VARIANZA</span>"
    ]
  },
  {
    "objectID": "TEMA-3.html",
    "href": "TEMA-3.html",
    "title": "3  TEMA 3: REGRESIÓN LINEAL MÚLTIPLE",
    "section": "",
    "text": "3.1 INTRODUCCIÓN\nCuando hayamos terminado este tema, seremos capaces de:\nRecuerda que la estadística descriptiva es una rama de la estadística que permite describir los datos que tienes a mano. La estadística inferencial (con las populares pruebas de hipótesis) y los intervalos de confianza) es otra rama que permite hacer inferencias, es decir, sacar conclusiones sobre una población a partir de una muestra.\nLa última rama de la estadística trata sobre modelar la relación entre dos o más variables. Algunos ven el análisis de regresión como parte de la estadística inferencial. Es cierto, ya que se toma una muestra para evaluar la relación entre variables en una población. Tiendo a distinguir la regresión de la estadística inferencial porque (i) las regresiones se usan de forma más amplia (para análisis predictivos, entre otros), y porque (ii) el objetivo principal de la regresión lineal difiere de los objetivos de los intervalos de confianza y las pruebas de hipótesis.] La herramienta estadística más común para describir y evaluar el vínculo entre variables es la regresión lineal.\nExisten dos tipos de regresión lineal:\nEn el mundo real, la regresión lineal múltiple se utiliza con más frecuencia que la simple. Esto se debe principalmente a que:\nAntes de sumergirnos en la regresión lineal múltiple, repasemos brevemente la regresión lineal simple.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>TEMA 3: REGRESIÓN LINEAL MÚLTIPLE</span>"
    ]
  },
  {
    "objectID": "TEMA-3.html#introducción",
    "href": "TEMA-3.html#introducción",
    "title": "3  TEMA 3: REGRESIÓN LINEAL MÚLTIPLE",
    "section": "",
    "text": "Regresión lineal simple: es un enfoque estadístico que permite evaluar la relación lineal entre dos variables cuantitativas. Más precisamente, permite cuantificar la relación y evaluar su significancia.\nRegresión lineal múltiple: es una generalización de la regresión lineal simple, en el sentido de que permite evaluar las relaciones lineales entre una variable de respuesta (cuantitativa) y varias variables explicativas (cuantitativas o cualitativas).\n\n\n\nLa regresión lineal múltiple permite evaluar la relación entre dos variables, controlando el efecto de otras variables.\nCon la creciente facilidad para recopilar datos, se pueden incluir y tener en cuenta más variables al analizar los datos.\n\n\n\n3.1.1 Regresión lineal simple: recordatorio\nLa regresión lineal simple es un procedimiento estadístico en el que:\n\nUna de las variables se considera la respuesta o variable a explicar. También se llama variable dependiente y se representa en el eje \\(Y\\).\nLa otra variable es la explicativa o también llamada variable independiente, y se representa en el eje \\(X\\).\n\nLa regresión lineal simple permite evaluar la existencia de una relación lineal entre dos variables y cuantificar este vínculo.\nLo que hace de la regresión lineal una herramienta estadística poderosa es que permite cuantificar en qué medida varía la variable dependiente cuando la variable independiente aumenta en una unidad.\nEste concepto es clave y ayuda a responder preguntas como:\n\n¿Hay una relación entre el índice de masa corporal (IMC) y la presión arterial de un paciente?\n¿Afecta la dosis de un medicamento al tiempo de recuperación?\n¿Un aumento en las horas de ejercicio semanales reduce los niveles de colesterol?\n\nPor ejemplo, imaginemos que nos interesa evaluar si existe una relación lineal entre la presión arterial sistólica de un paciente y su índice de masa corporal (IMC). Para este ejemplo, usaremos un conjunto de datos simulado de pacientes.\nEl conjunto de datos incluye las siguientes variables para 100 pacientes:\n\npresion_sistolica: Presión arterial sistólica (en mmHg).\nedad: Edad del paciente (en años).\nimc: Índice de Masa Corporal (en kg/m²).\ntabaquismo: Estado de tabaquismo del paciente (Fumador/No fumador).\n\n\n\n3.1.2 Creamos un conjunto de datos médicos simulados para el ejemplo\n\n# Fijamos la semilla para reproducibilidad\nset.seed(42)\nn &lt;- 100 # número de pacientes\nedad &lt;- round(runif(n, 30, 70))\nimc &lt;- round(rnorm(n, mean = 28, sd = 4), 1)\n# Convertimos el tabaquismo en una variable categórica (factor)\ntabaquismo &lt;- factor(sample(c(\"No fumador\", \"Fumador\"), n, replace = TRUE, prob = c(0.7, 0.3)))\n# Creamos la presión sistólica basada en las otras variables + ruido aleatorio\nerror &lt;- rnorm(n, mean = 0, sd = 8)\npresion_sistolica &lt;- round(60 + 0.8 * edad + 1.5 * imc + ifelse(tabaquismo == \"Fumador\", 5, 0) + error)\n# Creamos el dataframe\ndatos_pacientes &lt;- data.frame(\n  presion_sistolica,\n  edad,\n  imc,\n  tabaquismo\n)\n# Vemos las primeras filas del conjunto de datos\ndat &lt;- datos_pacientes\nprint(head(dat))\n\n  presion_sistolica edad  imc tabaquismo\n1               142   67 29.3 No fumador\n2               154   67 24.9 No fumador\n3               154   41 34.3 No fumador\n4               173   63 30.6 No fumador\n5               141   56 28.4    Fumador\n6               140   51 29.1    Fumador\n\n# Visualizamos los datos\nlibrary(ggplot2)\nggplot(dat, aes(x = imc, y = presion_sistolica)) +\n  geom_point() +\n  labs(\n    y = \"Presión arterial sistólica (mmHg)\",\n    x = \"Índice de Masa Corporal (IMC)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEl diagrama de dispersión anterior muestra que parece haber una relación positiva entre la presión arterial sistólica y el IMC. Esto tiene sentido clínico, ya que un mayor IMC a menudo se asocia con una presión arterial más alta.\nEsto ya es una buena visión general, pero una regresión lineal simple va más allá. Nos dirá en cuántos mmHg varía la presión arterial, en promedio, cuando el IMC varía en una unidad (1 kg/m²). Esto es posible gracias al ajuste de la línea de regresión mediante el método de mínimos cuadrados.\nEl principio de la regresión lineal simple es encontrar la línea (es decir, determinar su ecuación) que pasa lo más cerca posible de las observaciones. Para encontrar la línea que mejor se ajusta, se utiliza el método de mínimos cuadrados. Este método minimiza la suma de las distancias verticales al cuadrado entre cada punto de datos y la línea de regresión. Estas distancias se denominan residuos del modelo.\nEl modelo de regresión se puede escribir como:\n\\[Y = \\beta_0 + \\beta_1 X + \\epsilon\\]\ndonde:\n\n\\(Y\\) es la variable dependiente (presión arterial sistólica).\n\\(X\\) es la variable independiente (IMC).\n\\(\\beta_0\\) es la ordenada en el origen o intercepto (el valor medio de \\(Y\\) cuando \\(X=0\\)).\n\\(\\beta_1\\) es la pendiente (el aumento esperado en \\(Y\\) cuando \\(X\\) aumenta en una unidad).\n\\(\\epsilon\\) son los residuos (el término de error).\n\nAl ajustar el modelo, estimamos los parámetros desconocidos \\(\\beta_0\\) y \\(\\beta_1\\) a partir de los datos. Estos estimados se denotan como \\(\\widehat\\beta_0\\) y \\(\\widehat\\beta_1\\).\nLos coeficientes \\(\\widehat\\beta\\) se interpretan de la siguiente manera:\nLa ordenada en el origen \\(\\widehat\\beta_0\\) es el valor medio de la variable dependiente \\(Y\\) cuando la variable independiente \\(X\\) es 0.\nLa pendiente \\(\\widehat\\beta_1\\) corresponde a la variación esperada de \\(Y\\) cuando \\(X\\) varía en una unidad. Nos dice dos cosas:\n\nEl signo de la pendiente indica la dirección de la relación. Una pendiente positiva (\\(\\widehat\\beta_1 &gt; 0\\)) indica una relación positiva (las variables varían en la misma dirección). Una pendiente negativa (\\(\\widehat\\beta_1 &lt; 0\\)) indica una relación negativa.\nEl valor de la pendiente proporciona información sobre la magnitud del cambio.\n\nLas formulas usadas por el método de minimos cuadrados para calcular los coeficientes son: \\[\\widehat\\beta_1 = \\frac{\\sum\\_{i=1}^{n} (X_i - \\overline{X})(Y_i - \\overline{Y})}{\\sum_{i=1}^{n} (X_i - \\overline{X})^2}\\] \\[\\widehat\\beta_0 = \\overline{Y} - \\widehat\\beta_1 \\overline{X}\\] donde \\(\\overline{X}\\) y \\(\\overline{Y}\\) son las medias muestrales de \\(X\\) e \\(Y\\), respectivamente. Una vez que tenemos los coeficientes, podemos escribir la ecuación de la línea de regresión ajustada: \\[\\widehat{Y} = \\widehat\\beta_0 + \\widehat\\beta_1 X\\] donde \\(\\widehat{Y}\\) es el valor predicho de \\(Y\\) para un valor dado de \\(X\\).\nPara realizar una regresión lineal en R, usamos la función lm() (modelo lineal).\nAplicado a nuestro ejemplo de presión arterial e IMC:\n\nmodelo_simple &lt;- lm(presion_sistolica ~ imc, data = dat)\n\nLa función summary() nos da los resultados del modelo:\n\noptions(scipen = 999) # para evitar notación científica\nsummary(modelo_simple)\n\n\nCall:\nlm(formula = presion_sistolica ~ imc, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-31.343  -9.261  -1.945   8.978  30.769 \n\nCoefficients:\n            Estimate Std. Error t value           Pr(&gt;|t|)    \n(Intercept)  86.1928     9.9304    8.68 0.0000000000000881 ***\nimc           2.0747     0.3528    5.88 0.0000000567768822 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.07 on 98 degrees of freedom\nMultiple R-squared:  0.2608,    Adjusted R-squared:  0.2533 \nF-statistic: 34.58 on 1 and 98 DF,  p-value: 0.00000005678\n\n\nLos resultados (columna Estimate) se pueden resumir así:\n\nEl intercepto \\(\\widehat\\beta_0 = 86.19\\) indica que, para un paciente hipotético con un IMC de 0 kg/\\(m^2\\), esperaríamos una presión sistólica promedio de 86.19 mmHg. Esta interpretación no tiene sentido clínico, ya que un IMC de 0 es imposible (en este caso sería relevante centrar la variable IMC para que la interpretación del intercepto sea con respecto a la media del IMC. Para centrar la variable IMC, podemos restar la media del IMC a cada valor de IMC antes de ajustar el modelo).\nLa pendiente \\(\\widehat\\beta_1 = 2.07\\) indica que:\n\nExiste una relación positiva entre el IMC y la presión arterial sistólica (como se esperaba por el gráfico).\nMás importante aún, una pendiente de 2.07 significa que, por un aumento de una unidad en el IMC (1 kg/\\(m^2\\)), la presión arterial sistólica aumenta, en promedio, en 2.07 mmHg.\n\n\nOtra interpretación útil del intercepto es cuando la variable independiente está centrada en torno a su media. En este caso, el intercepto se interpreta como el valor medio de \\(Y\\) para los individuos que tienen un valor de \\(X\\) igual a la media de \\(X\\). Veámoslo en la práctica:\nPrimero centramos la variable IMC en torno a la media y luego volvemos a ejecutar un modelo lineal simple con esta nueva variable:\n\ndat_centered &lt;- dat\ndat_centered$imc_centered &lt;- dat$imc - mean(dat$imc)\n\nmod_centered &lt;- lm(presion_sistolica ~ imc_centered,\n                   data = dat_centered)\n\nsummary(mod_centered)\n\n\nCall:\nlm(formula = presion_sistolica ~ imc_centered, data = dat_centered)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-31.343  -9.261  -1.945   8.978  30.769 \n\nCoefficients:\n             Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)  144.0800     1.3072  110.22 &lt; 0.0000000000000002 ***\nimc_centered   2.0747     0.3528    5.88         0.0000000568 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.07 on 98 degrees of freedom\nMultiple R-squared:  0.2608,    Adjusted R-squared:  0.2533 \nF-statistic: 34.58 on 1 and 98 DF,  p-value: 0.00000005678\n\n\nBasándonos en los resultados, vemos que:\n\nLa pendiente no ha cambiado, la interpretación es la misma que sin el centrado (lo que tiene sentido, ya que la línea de regresión simplemente se ha desplazado a la derecha o a la izquierda).\nMás importante aún, el intercepto es ahora \\(\\widehat\\beta_0 =\\) 144.8, por lo que podemos esperar para un paciente hipotético con un IMC medio de 27.9 kg/\\(m^2\\), esperaríamos una presión sistólica promedio de 144.8 mmHg.\n\n\nround(coef(mod_centered)[1], 2)\n\n(Intercept) \n     144.08 \n\nmean(dat$imc)\n\n[1] 27.901\n\n\nEste centrado alrededor de la media para una variable independiente es particularmente interesante:\n\ncuando la variable independiente continua no tiene una interpretación clínica con un valor de cero, o\ncuando es importante interpretar el intercepto.\n\nHay que tener en cuenta que el centrado no tiene por qué hacerse solo en torno a la media. La variable independiente también puede centrarse en algún valor que esté realmente en el rango de los datos. El valor exacto en el que se centre no importa siempre que sea significativo y esté dentro del rango de los datos. En otro caso, podríamos encontrar que elegir el valor más bajo o el más alto del peso es la mejor opción. Así que nos toca a nosotros decidir el peso en el que es más significativo interpretar el intercepto.\nComo se mencionó anteriormente, el valor de la pendiente no permite, por sí solo, evaluar la significancia de la relación lineal.\nEn otras palabras, una pendiente distinta de 0 no significa necesariamente que sea significativamente distinta de 0, por lo que no significa que exista una relación significativa entre las dos variables en la población. Podría haber una pendiente de 10 que no sea significativa, y una pendiente de 2 que sí lo sea.\nLa significancia de la relación también depende de la variabilidad de la pendiente, que se mide por su error estándar y generalmente se anota como \\(se(\\widehat\\beta_1)\\).\nSin entrar en demasiados detalles, para evaluar la significancia de la relación lineal, dividimos la pendiente por su error estándar. Esta relación es el estadístico de prueba y sigue una distribución t de Student con \\(n - 2\\) grados de libertad: [\\(n\\) es el número de observaciones.]\n\\[T_{n - 2} = \\frac{\\widehat\\beta_1}{se(\\widehat\\beta_1)}\\] Para una prueba bilateral, las hipótesis nula y alternativa son:\n\n\\(H\\_0 : \\beta_1 = 0\\) (no hay relación (lineal) entre las dos variables)\n\\(H\\_1 : \\beta_1 \\ne 0\\) (hay una relación (lineal) entre las dos variables)\n\nA grandes rasgos, si esta relación es mayor que 2 en valor absoluto, entonces la pendiente es significativamente diferente de 0 y, por lo tanto, la relación entre las dos variables es significativa (y en ese caso es positiva o negativa dependiendo del signo de la estimación \\(\\widehat\\beta_1\\)).\nEl error estándar y el estadístico de prueba se muestran en la columna Std. Error y t value en la tabla Coefficients.\nAfortunadamente, R nos da una forma más precisa y fácil de evaluar la significancia de la relación. La información se proporciona en la columna Pr(&gt;|t|) de la tabla Coefficients. Este es el p-valor de la prueba. Como en cualquier prueba estadística, si el p-valor es mayor o igual que el nivel de significancia (normalmente \\(\\alpha = 0.05\\)), no rechazamos la hipótesis nula, y si el p-valor es menor que el nivel de significancia, rechazamos la hipótesis nula.\nSi no rechazamos la hipótesis nula, no rechazamos la hipótesis de que no hay relación entre las dos variables (porque no rechazamos la hipótesis de una pendiente de 0). Por el contrario, si rechazamos la hipótesis nula de no relación, podemos concluir que existe una relación lineal significativa entre las dos variables.\nEn nuestro ejemplo, el p-valor = &lt; 0.0001, por lo que rechazamos la hipótesis nula al nivel de significancia \\(\\alpha = 5%\\). Por lo tanto, concluimos que existe una relación significativa entre el IMC y la preson arterial sistólica.\nConsejo: Para asegurarme de que solo interpreto los parámetros que son significativos, tiendo a comprobar primero la significancia de los parámetros gracias a los p-valores, y luego interpreto las estimaciones en consecuencia. Para completar, ten en cuenta que la prueba también se realiza sobre el intercepto. Siendo el p-valor menor que 0.05, también concluimos que el intercepto es significativamente diferente de 0.\nEs importante remarcar que una relación significativa entre dos variables no significa necesariamente que haya una influencia de una variable sobre la otra o que haya un efecto causal entre estas dos variables. Una relación significativa entre \\(X\\) e \\(Y\\) puede aparecer en varios casos:\n\n\\(X\\) causa \\(Y\\)\n\\(Y\\) causa \\(X\\)\nuna tercera variable causa \\(X\\) e \\(Y\\)\nuna combinación de estas tres razones\n\nUn modelo estadístico por sí solo no puede establecer un vínculo causal entre dos variables. Demostrar la causalidad entre dos variables es más complejo y requiere, entre otras cosas, un diseño experimental específico, la repetibilidad de los resultados a lo largo del tiempo, así como varias muestras.\nEsta es la razón por la que a menudo leerás “Correlación no implica causalidad” y la regresión lineal sigue el mismo principio.\nDesafortunadamente, la regresión lineal no se puede utilizar en todas las situaciones. Además del requisito de que la variable dependiente debe ser una variable cuantitativa continua, la regresión lineal simple requiere que los datos satisfagan las siguientes condiciones:\n\nLinealidad: La relación entre las dos variables debe ser lineal (al menos aproximadamente). Por esta razón, siempre es necesario representar gráficamente los datos con un diagrama de dispersión antes de realizar una regresión lineal simple. Ten en cuenta que la linealidad se puede comprobar con un diagrama de dispersión de las dos variables, o mediante un diagrama de dispersión de los residuos y los valores ajustados. Si la relación no es lineal, la regresión lineal no es adecuada y se deben considerar otros tipos de modelos (por ejemplo, regresión polinómica, regresión no lineal, etc.). A continuación se muestran dos ejemplos: uno en el que la linealidad se respeta y otro en el que no se respeta.\n\n\nlibrary(MASS)\nset.seed(42)\nsigma &lt;- rbind(c(0.8,-0.8,-0.5), c(-0.8,1, 0.7), c(-0.7,0.8,1))\n# crear el vector de medias\nmu&lt;-c(10, 5, 2)\n# generar la distribución normal multivariante\ndf&lt;-as.data.frame(mvrnorm(n=200, mu=mu, Sigma=sigma))\np1 &lt;- ggplot(df, aes(x=V1, y=V2))+\n  geom_point()+\n  geom_smooth(method=\"lm\", se=FALSE)+\n  labs(x = \"X\",\n       y = \"Y\",\n       title = \"Se respeta la linealidad\") +\n  theme_minimal()\np &lt;- 0.5\nq &lt;- seq(from=0, to=20, by=0.1)\ny &lt;- 500 + 0.4 * (q-10)^3\nnoise &lt;- rnorm(length(q), mean=10, sd=50)\nnoisy.y &lt;- y + noise\ndf &lt;- data.frame(q = q,\n                 y = y)\np2 &lt;- ggplot(df, aes(x=q, y=noisy.y))+\n  geom_point()+\n  geom_smooth(se=FALSE)+\n  labs(x = \"X\",\n       y = \"Y\",\n       title = expression(paste(\"La linealidad \", bold(\"no\"), \" se respeta\"))) +\n  theme_minimal()\nlibrary(patchwork)\np1 + p2\n\n\n\n\n\n\n\n\n\nIndependencia: Las observaciones deben ser independientes. Es el plan de muestreo y el diseño experimental lo que suele proporcionar información sobre esta condición. Si los datos proceden de diferentes individuos o unidades experimentales, suelen ser independientes. Por otro lado, si los mismos individuos se miden en diferentes períodos, los datos probablemente no sean independientes.\nNormalidad de los residuos: Para tamaños de muestra grandes, los intervalos de confianza y las pruebas sobre los coeficientes son (aproximadamente) válidos tanto si el error sigue una distribución normal como si no (una consecuencia del teorema del límite central, consulta más en [1] regression y [2]. Para tamaños de muestra pequeños, los residuos deben seguir una distribución normal. Esta condición se puede probar visualmente (mediante un gráfico Q-Q y/o un histograma), o más formalmente (mediante la prueba de Shapiro-Wilk, por ejemplo).\n\n\n# gráfico Q-Q\nplot(modelo_simple, which = 2)\n\n\n\n\n\n\n\n# histograma de los residuos\nhist(residuals(modelo_simple), main = \"Histograma de los residuos\",\n     xlab = \"Residuos\", breaks = 10)\n\n\n\n\n\n\n\n# prueba de Shapiro-Wilk\nshapiro.test(residuals(modelo_simple))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo_simple)\nW = 0.98518, p-value = 0.327\n\n\n\nHomocedasticidad de los residuos: La varianza de los errores debe ser constante. Hay una falta de homocedasticidad cuando la dispersión de los residuos aumenta con los valores predichos (valores ajustados). Esta condición se puede probar visualmente (trazando los residuos estandarizados frente a los valores ajustados) o más formalmente (mediante la prueba de Breusch-Pagan).\n\n\n# gráfico de residuos estandarizados frente a los valores ajustados\nplot(modelo_simple, which = 1)\n\n\n\n\n\n\n\n# prueba de Breusch-Pagan\n# instalar el paquete si no está ya instalado\n# install.packages(\"lmtest\")\nlibrary(lmtest)\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\nbptest(modelo_simple)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_simple\nBP = 1.6674, df = 1, p-value = 0.1966\n\n\n\nSin puntos influyentes: Si los datos contienen valores atípicos, es esencial identificarlos para que no influyan, por sí solos, en los resultados de la regresión. Ten en cuenta que un valor atípico no es un problema per se si el punto está en la alineación de la línea de regresión, por ejemplo, porque no influye en la línea de regresión. Se convierte en un problema en el contexto de la regresión lineal si influye de manera sustancial en las estimaciones (y en particular en la pendiente de la línea de regresión). Esto se puede abordar identificando los valores atípicos (mediante la distancia de Cook. Una observación se considera un valor atípico según la distancia de Cook si su valor es &gt; 1 o el índice de apalancamiento es mayor que \\(2p/n\\), donde \\(p\\) es el número de parámetros en el modelo incluido el intercepto y \\(n\\) es el número de observaciones. Por ejemplo, si comparando los resultados con y sin los posibles valores atípicos los resultados siguen siendo los mismos con los dos enfoques, entonces los valores atípicos no son realmente un problema en este caso. Si los resultados son muy diferentes, deberíamos utilizar el estimador de Theil-Sen, la regresión robusta o la regresión cuantílica, que son todos más robustos a los valores atípicos.\n\n\n# distancia de Cook\nplot(modelo_simple, which = 4)\nabline(h = 1, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n# índice de apalancamiento\nplot(modelo_simple, which = 5)\nabline(h = 2 * (length(coef(modelo_simple)) / nrow(dat)), col = \"red\", lty = 2)\n\n\n\n\n\n\n\n# identificar los puntos influyentes\ninfluential_points &lt;- which(cooks.distance(modelo_simple) &gt; 1 |\n                             hatvalues(modelo_simple) &gt; 2 * (length(coef(modelo_simple)) / nrow(dat)))\ninfluential_points\n\n 9 54 65 68 78 \n 9 54 65 68 78 \n\ndat[influential_points, ]\n\n   presion_sistolica edad  imc tabaquismo\n9                124   56 16.0 No fumador\n54               163   61 35.4 No fumador\n65               143   64 21.4 No fumador\n68               172   63 38.8    Fumador\n78               116   45 19.9 No fumador\n\n# Nuevo modelo con y sin los puntos influyentes\nmodelo_sin_influencers &lt;- lm(presion_sistolica ~ imc, data = dat[-influential_points, ])\nsummary(modelo_sin_influencers)\n\n\nCall:\nlm(formula = presion_sistolica ~ imc, data = dat[-influential_points, \n    ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-31.270  -9.530  -2.014   9.306  30.782 \n\nCoefficients:\n            Estimate Std. Error t value       Pr(&gt;|t|)    \n(Intercept)   87.169     12.138   7.181 0.000000000167 ***\nimc            2.034      0.431   4.721 0.000008283667 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.28 on 93 degrees of freedom\nMultiple R-squared:  0.1933,    Adjusted R-squared:  0.1846 \nF-statistic: 22.28 on 1 and 93 DF,  p-value: 0.000008284\n\n\nConsejo: Recuerdar las 4 primeras condiciones gracias al acrónimo en inglés “LINE”, de Linearity, Independence, Normality y Equality of variance (Linealidad, Independencia, Normalidad e Igualdad de varianza).\nSi no se cumple alguna de las condiciones, las pruebas y las conclusiones podrían ser erróneas, por lo que es mejor evitar el uso e interpretación del modelo. Si este es el caso, a veces las condiciones se pueden cumplir transformando los datos (por ejemplo, transformación logarítmica, cuadrada o raíz cuadrada, transformación de Box-Cox, etc.) o añadiendo un término cuadrático o cúbico (o incluso un polinomio de orden superior) al modelo. Si no ayuda, podría valer la pena pensar en eliminar algunas variables o añadir otras, o incluso considerar otros tipos de modelos como los modelos no lineales.\nTen en cuenta que, en la práctica, las condiciones de aplicación deben verificarse antes de sacar cualquier conclusión basada en el modelo.\nHay numerosas formas de visualizar la relación entre las dos variables de interés, pero la más fácil que he encontrado hasta ahora es a través de la función visreg() del paquete del mismo nombre:\n\n#install.packages(\"visreg\") # instalar el paquete si no está ya instalado\nlibrary(visreg)\nvisreg(modelo_simple, gg=TRUE) +\n  labs(\n    y = \"Presión arterial sistólica (mmHg)\",\n    x = \"Índice de Masa Corporal (IMC)\"\n  ) +\n  theme_minimal()\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nℹ The deprecated feature was likely used in the visreg package.\n  Please report the issue at &lt;https://github.com/pbreheny/visreg/issues&gt;.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\nℹ The deprecated feature was likely used in the ggplot2 package.\n  Please report the issue at &lt;https://github.com/tidyverse/ggplot2/issues&gt;.\n\n\n\n\n\n\n\n\n\nSe podrían mostrar otros elementos en el gráfico de regresión (por ejemplo, la ecuación de regresión y el \\(R^2\\)). Esto se puede hacer fácilmente con las funciones stat_regline_equation() y stat_cor() del paquete {ggpubr}:\n\n# cargar las bibliotecas necesarias\nlibrary(ggpubr)\n# crear un gráfico con la línea de regresión, la ecuación de regresión y el R^2\nggplot(dat, aes(x = imc, y = presion_sistolica)) +\n  geom_smooth(method=\"lm\") +\n  geom_point() +\n  stat_regline_equation(label.x=10, label.y=160) + # para la ecuación de regresión\n  stat_cor(aes(label=after_stat(rr.label)), label.x=10, label.y=170) + # para el R^2\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>TEMA 3: REGRESIÓN LINEAL MÚLTIPLE</span>"
    ]
  },
  {
    "objectID": "TEMA-3.html#regresión-lineal-múltiple",
    "href": "TEMA-3.html#regresión-lineal-múltiple",
    "title": "3  TEMA 3: REGRESIÓN LINEAL MÚLTIPLE",
    "section": "3.2 REGRESIÓN LINEAL MÚLTIPLE",
    "text": "3.2 REGRESIÓN LINEAL MÚLTIPLE\n\n3.2.1 El concepto de ajuste\nLa regresión lineal múltiple (RLM) es una generalización de la regresión lineal simple, en el sentido de que este enfoque permite relacionar una variable con varias variables a través de una función lineal en sus parámetros. La RLM se utiliza para evaluar la relación entre dos variables mientras se tiene en cuenta el efecto de otras variables, esto se conoce como un modelo ajustado dejando constante el efecto de las variables independientes. Al considerar el efecto de otras variables, cancelamos su influencia para aislar y medir la relación entre las dos variables de interés, en nuestro ejemplo presión arterial sistólica e IMC. Este punto es la principal diferencia con la regresión lineal simple.\nPara ilustrar cómo realizar una regresión lineal múltiple en R, utilizamos el mismo conjunto de datos que para la regresión lineal simple (datos_pacientes). A continuación, un breve vistazo a los datos:\n\n# Nota: Este código asume que el dataframe 'dat' y el 'modelo_simple' de la sección anterior ya están cargados.\n# 'modelo_simple' fue: modelo_simple &lt;- lm(presion_sistolica ~ imc, data = dat)\nhead(dat)\n\n  presion_sistolica edad  imc tabaquismo\n1               142   67 29.3 No fumador\n2               154   67 24.9 No fumador\n3               154   41 34.3 No fumador\n4               173   63 30.6 No fumador\n5               141   56 28.4    Fumador\n6               140   51 29.1    Fumador\n\n\nHemos visto que existe una relación lineal significativa y positiva entre la presión arterial sistólica de un paciente y su IMC. Sin embargo, uno podría preguntarse si no existen en realidad otros factores que podrían explicar la presión arterial de un paciente. En medicina, es bien sabido que la edad y el tabaquismo también son factores de riesgo importantes. Para explorar esto, podemos visualizar la relación entre la presión arterial (presion_sistolica), el IMC (imc), la edad (edad) y el tabaquismo (tabaquismo):\n\nggplot(dat) +\n  aes(x = imc, y = presion_sistolica, colour = edad, shape = tabaquismo) +\n  geom_point(alpha = 0.8, size = 3) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  labs(y = \"Presión arterial sistólica (mmHg)\",\n       x = \"Índice de Masa Corporal (IMC)\",\n       color = \"Edad\",\n       shape = \"Tabaquismo\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nParece que, además de la relación positiva entre la presión sistólica y el IMC, también observamos que:\n\nlos puntos con colores más cálidos (indicando mayor edad) tienden a estar más arriba, sugiriendo una relación positiva con la edad.\npodría haber una diferencia sistemática entre fumadores y no fumadores.\n\nPor lo tanto, nos gustaría evaluar la relación entre la presión arterial y el IMC, pero esta vez añadiendo información sobre la edad y el tabaquismo del paciente. Al añadir esta información adicional, podemos capturar solo la relación directa entre la presión arterial y el IMC (el efecto indirecto debido a la edad y el tabaquismo se controla por el modelo). Este es el objetivo principal de la RLM. De hecho, en la RLM, la relación estimada entre la variable dependiente y una variable explicativa es una relación ajustada, es decir, libre de los efectos lineales de las otras variables explicativas.\nIlustremos esta noción de ajuste añadiendo la edad y el tabaquismo a nuestro modelo de regresión lineal:\n\nmodelo_multiple &lt;- lm(presion_sistolica ~ imc + edad + tabaquismo,\n                      data = dat)\nsummary(modelo_multiple)\n\n\nCall:\nlm(formula = presion_sistolica ~ imc + edad + tabaquismo, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.6886  -5.5994  -0.0534   5.1252  19.9078 \n\nCoefficients:\n                     Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)          61.43331    7.17710   8.560    0.000000000000183 ***\nimc                   1.60879    0.22686   7.092    0.000000000224898 ***\nedad                  0.81471    0.06941  11.738 &lt; 0.0000000000000002 ***\ntabaquismoNo fumador -5.35646    1.82008  -2.943              0.00408 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.247 on 96 degrees of freedom\nMultiple R-squared:  0.7118,    Adjusted R-squared:  0.7028 \nF-statistic: 79.03 on 3 and 96 DF,  p-value: &lt; 0.00000000000000022\n\n\nPodemos ver que ahora, la relación entre la presión arterial y el IMC sigue siendo fuerte y positiva (\\(\\widehat\\beta_1 = 1.61\\)), y ahora podemos cuantificar los efectos de la edad y el tabaquismo de forma independiente. El efecto del IMC sobre la presión arterial fue ajustado según el efecto de la edad y el tabaquismo. Este es el efecto restante entre la presión arterial y el IMC después de que se hayan tenido en cuenta los efectos de las otras variables.\nLos modelos de regresión lineal múltiple se definen por la ecuación:\n\\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon\\] Es similar a la ecuación de la regresión lineal simple, excepto que hay más de una variable independiente (\\(X_1, X_2, \\dots, X_p\\)). La estimación de los parámetros \\(\\beta_0, \\dots, \\beta_p\\) por el método de mínimos cuadrados se basa en el mismo principio que el de la regresión lineal simple, pero aplicado a \\(p\\) dimensiones. Ya no se trata de encontrar la mejor línea, sino de encontrar el hiperplano \\(p\\)-dimensional que pasa más cerca de los puntos de coordenadas (\\(y_i, x_{i1}, \\dots, x_{ip}\\)).\nEsto se hace minimizando la suma de los cuadrados de las desviaciones de los puntos al plano. En este gráfico podemos ver el concepto de hiperplano \n\n\n3.2.2 Interpretación de los coeficientes\nEl método de mínimos cuadrados da como resultado una estimación ajustada de los coeficientes. El término “ajustado” significa después de tener en cuenta los efectos lineales de las otras variables independientes sobre la variable dependiente y sobre la variable predictora en cuestión.\nEn otras palabras, el coeficiente \\(\\beta_1\\) corresponde a la pendiente de la relación entre \\(Y\\) y \\(X_1\\) cuando los efectos lineales de las otras variables explicativas (\\(X_2, \\dots, X_p\\)) han sido eliminados.\nAplicado a nuestro modelo con IMC, edad y tabaquismo como variables independientes, tenemos:\n\nsummary(modelo_multiple)\n\n\nCall:\nlm(formula = presion_sistolica ~ imc + edad + tabaquismo, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.6886  -5.5994  -0.0534   5.1252  19.9078 \n\nCoefficients:\n                     Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)          61.43331    7.17710   8.560    0.000000000000183 ***\nimc                   1.60879    0.22686   7.092    0.000000000224898 ***\nedad                  0.81471    0.06941  11.738 &lt; 0.0000000000000002 ***\ntabaquismoNo fumador -5.35646    1.82008  -2.943              0.00408 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.247 on 96 degrees of freedom\nMultiple R-squared:  0.7118,    Adjusted R-squared:  0.7028 \nF-statistic: 79.03 on 3 and 96 DF,  p-value: &lt; 0.00000000000000022\n\n\nLa tabla Coefficients nos da la estimación para cada parámetro (columna Estimate), junto con el p-valor de su significancia (columna Pr(&gt;|t|)).\nLas hipótesis son las mismas que para la regresión simple:\n\n\\(H_0 : \\beta_j = 0\\)\n\\(H_1 : \\beta_j \\ne 0\\)\n\nProbar si \\(\\beta_j = 0\\) es equivalente a probar la hipótesis: ¿está la variable dependiente asociada con la variable independiente estudiada, manteniendo todo lo demás constante?\nEn otras palabras:\n\nLa prueba para imc corresponde a: ¿está la presión arterial asociada con el IMC, a un nivel constante de edad y tabaquismo?\nLa prueba para edad corresponde a: ¿está la presión arterial asociada con la edad, a un nivel constante de IMC y tabaquismo?\nLa prueba para tabaquismo corresponde a: ¿está la presión arterial asociada con el tabaquismo, a un nivel constante de IMC y edad?\n\nBasándonos en el resultado de nuestro modelo, concluimos que:\n\nExiste una relación significativa y positiva entre la presión sistólica y el IMC, manteniendo todo lo demás constante. Por cada aumento de 1 kg/\\(m^2\\) en el IMC, la presión sistólica aumenta, en promedio, en 1.61 mmHg, para un nivel constante de edad y tabaquismo (p-valor &lt; 0.001).\nExiste una relación significativa y positiva entre la presión sistólica y la edad, manteniendo todo lo demás constante. Por cada año adicional de edad, la presión sistólica aumenta, en promedio, 0.81 mmHg, para un nivel constante de IMC y tabaquismo (p-valor &lt; 0.001).\nLa presión arterial de un fumador es, en promedio, 5.35 mmHg más alta que la de un no fumador, manteniendo constantes el IMC y la edad. Esta diferencia es estadísticamente significativa (p-valor = 0.004).\n\n\n\n3.2.3 Condiciones de aplicación\nAl igual que en la regresión simple, la regresión múltiple requiere que se cumplan ciertas condiciones para que el modelo sea válido. Las condiciones son en gran medida las mismas:\n\nLinealidad de las relaciones entre la variable dependiente y las independientes.\nIndependencia de las observaciones (los datos de un paciente no influyen en los de otro).\nNormalidad de los residuos.\nHomocedasticidad (igualdad de varianza) de los residuos.\nAusencia de puntos influyentes (valores atípicos que distorsionen el modelo).\n\nPero hay una condición adicional para la regresión múltiple:\n\nAusencia de multicolinealidad: La multicolinealidad ocurre cuando hay una fuerte correlación lineal entre las variables independientes. Es importante verificarla porque puede desestabilizar las estimaciones de los coeficientes. Se puede evaluar calculando el Factor de Inflación de la Varianza (VIF). Un VIF superior a 5 o 10 suele considerarse problemático [3].\n\nUsaremos la función check_model() del paquete {performance} para verificar todas estas condiciones de manera elegante y eficiente.\n\n# install.packages(\"performance\")\n# install.packages(\"see\")\nlibrary(performance)\ncheck_model(modelo_multiple)\n\n\n\n\n\n\n\n\nBasándonos en estos gráficos de diagnóstico, vemos que:\n\nLa homogeneidad de la varianza se respeta (la dispersión de los residuos es constante).\nLa multicolinealidad no es un problema (todos los valores VIF son cercanos a 1, muy por debajo del umbral problemático).\nNo hay puntos influyentes que distorsionen los resultados.\nLa normalidad de los residuos es aceptable (los puntos se ajustan bien a la línea diagonal en el gráfico Q-Q).\nLa linealidad parece cumplirse (no hay patrones curvos evidentes en los residuos).\n\nConclusión del diagnóstico: Nuestro modelo para la presión arterial es robusto y cumple con los supuestos necesarios.\n\n\n3.2.4 Elección del mejor modelo\nUn modelo que satisface las condiciones de aplicación es el requisito mínimo. Pero, ¿cómo elegimos el “mejor” modelo entre varias opciones válidas?\nLas tres herramientas más comunes son:\n\nEl p-valor global del modelo (Prueba F).\nEl coeficiente de determinación (\\(R^2\\)).\nEl Criterio de Información de Akaike (AIC).\n\n\n3.2.4.1 P-valor global del modelo (Prueba F)\nEste p-valor indica si el modelo es mejor que un modelo nulo (uno que solo contiene el intercepto).\n\n\\(H_0: \\beta_1 = \\beta_2 = \\dots = \\beta_p = 0\\) (ninguna variable predictora es útil).\n\\(H_1:\\) al menos un coeficiente \\(\\beta \\ne 0\\).\n\nEste p-valor se encuentra en la última línea del summary():\n\nsummary(modelo_multiple)\n\n\nCall:\nlm(formula = presion_sistolica ~ imc + edad + tabaquismo, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.6886  -5.5994  -0.0534   5.1252  19.9078 \n\nCoefficients:\n                     Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)          61.43331    7.17710   8.560    0.000000000000183 ***\nimc                   1.60879    0.22686   7.092    0.000000000224898 ***\nedad                  0.81471    0.06941  11.738 &lt; 0.0000000000000002 ***\ntabaquismoNo fumador -5.35646    1.82008  -2.943              0.00408 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.247 on 96 degrees of freedom\nMultiple R-squared:  0.7118,    Adjusted R-squared:  0.7028 \nF-statistic: 79.03 on 3 and 96 DF,  p-value: &lt; 0.00000000000000022\n\n\nEl p-value: &lt; 2.2e-16 es extremadamente pequeño. Rechazamos la hipótesis nula y concluimos que nuestro modelo es significativamente mejor que nada, ya que al menos uno de nuestros predictores (IMC, edad o tabaquismo) es útil para explicar la presión arterial.\n\n\n3.2.4.2 Coeficiente de determinación R2\nEl \\(R^2\\) mide la proporción de la variabilidad de la variable dependiente que es explicada por el modelo. Su formula es: \\[R^2 = 1 - \\frac{\\text{Suma de cuadrados de los residuos}}{\\text{Suma total de cuadrados}}\\] Donde: - La Suma de cuadrados de los residuos mide la variabilidad no explicada por el modelo. - La Suma total de cuadrados mide la variabilidad total de la variable dependiente.\nLas formulas de estas sumas de cuadrados son:\n\\[\\text{Suma de cuadrados de los residuos} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\]\ndonde \\(y_i\\) son los valores observados y \\(\\hat{y}_i\\) son los valores predichos por el modelo.\n\\[\\text{Suma total de cuadrados} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\\] donde \\(\\bar{y}\\) es la media de los valores observados.\nEn R los podriamos computar manualmente así:\n\nsuma_cuadrados_residuos &lt;- sum(residuals(modelo_multiple)^2)\nsuma_total_cuadrados &lt;- sum((dat$presion_sistolica - mean(dat$presion_sistolica))^2)\nR2 &lt;- 1 - (suma_cuadrados_residuos / suma_total_cuadrados); R2\n\n[1] 0.7117912\n\n# El ajustado\nR2_ajustado &lt;- 1 - (1 - R2) * ((nrow(dat) - 1) / (nrow(dat) - length(coef(modelo_multiple)))); R2_ajustado\n\n[1] 0.7027847\n\n\nEn R, el \\(R^2\\) se muestra en el summary() del modelo:\n\nsummary(modelo_multiple)\n\n\nCall:\nlm(formula = presion_sistolica ~ imc + edad + tabaquismo, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.6886  -5.5994  -0.0534   5.1252  19.9078 \n\nCoefficients:\n                     Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)          61.43331    7.17710   8.560    0.000000000000183 ***\nimc                   1.60879    0.22686   7.092    0.000000000224898 ***\nedad                  0.81471    0.06941  11.738 &lt; 0.0000000000000002 ***\ntabaquismoNo fumador -5.35646    1.82008  -2.943              0.00408 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.247 on 96 degrees of freedom\nMultiple R-squared:  0.7118,    Adjusted R-squared:  0.7028 \nF-statistic: 79.03 on 3 and 96 DF,  p-value: &lt; 0.00000000000000022\n\n\nEn nuestro caso, el \\(R^2\\) es 0.7118, pero el \\(R^2\\) ajustado es preferible en regresión múltiple porque penaliza la adición de variables innecesarias y su valor es 0.7028. Esto se interpreta como que aproximadamente el 70% de la variabilidad en la presión arterial sistólica de los pacientes es explicada por el IMC, la edad y el tabaquismo. Este es un poder explicativo bastante alto para un modelo biomédico.\n\n\n3.2.4.3 Parsimonia (Criterio de Información de Akaike - AIC)\nGeneralmente, se prefiere un modelo parsimonioso (con menos variables) a uno complejo, siempre que explique bien los datos. El AIC es un criterio que equilibra la bondad de ajuste con la complejidad del modelo. El mejor modelo es el que tiene el AIC más bajo. Podemos usar un procedimiento “paso a paso” (stepwise) para que R encuentre automáticamente el modelo con el mejor AIC, partiendo de un modelo con todas las variables candidatas.\n\n# En nuestro caso, el modelo ya es bastante simple, pero así se haría:\nmodelo_completo &lt;- lm(presion_sistolica ~ imc + edad + tabaquismo, data = dat)\nmodelo_seleccionado &lt;- step(modelo_completo, trace = FALSE)\nsummary(modelo_seleccionado)\n\n\nCall:\nlm(formula = presion_sistolica ~ imc + edad + tabaquismo, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.6886  -5.5994  -0.0534   5.1252  19.9078 \n\nCoefficients:\n                     Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)          61.43331    7.17710   8.560    0.000000000000183 ***\nimc                   1.60879    0.22686   7.092    0.000000000224898 ***\nedad                  0.81471    0.06941  11.738 &lt; 0.0000000000000002 ***\ntabaquismoNo fumador -5.35646    1.82008  -2.943              0.00408 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.247 on 96 degrees of freedom\nMultiple R-squared:  0.7118,    Adjusted R-squared:  0.7028 \nF-statistic: 79.03 on 3 and 96 DF,  p-value: &lt; 0.00000000000000022\n\n\nEn este caso, el procedimiento step() mantuvo todas nuestras variables (IMC, edad y tabaquismo), confirmando que todas son importantes para el modelo y que no hay necesidad de simplificarlo más.\n\n\n\n3.2.5 Visualizaciones del modelo\nHay muchas formas de visualizar los resultados de una regresión. Aquí hay tres opciones populares:\n\nvisreg(): Muestra la relación ajustada para cada variable predictora, manteniendo las otras constantes.\n\n\nlibrary(visreg)\n# Mostramos el efecto del IMC ajustado por edad y tabaquismo\nvisreg(modelo_multiple, \"imc\", gg = TRUE) + theme_minimal()\n\n\n\n\n\n\n\n# Mostramos el efecto de la edad ajustado por IMC y tabaquismo\nvisreg(modelo_multiple, \"edad\", gg = TRUE) + theme_minimal()\n\n\n\n\n\n\n\n\n\nggcoefstats() del paquete {ggstatsplot}: Crea un gráfico de coeficientes (llamado “diagrama de bosque” o forest plot) que resume los resultados del modelo de forma visual.\n\n\n#install.packages(\"ggstatsplot\") # instalar el paquete si no está ya instalado\nlibrary(ggstatsplot)\nggcoefstats(modelo_multiple)\n\n\n\n\n\n\n\n\nEn este gráfico:\n\nLa línea vertical discontinua está en el cero. Si el intervalo de confianza de un coeficiente (la línea horizontal) no cruza esta línea, el coeficiente es estadísticamente significativo.\nUn punto a la derecha (izquierda) del cero indica una relación positiva (negativa).\nCuanto más lejos del cero esté el punto, más fuerte es el efecto.\n\n\nplot_summs() del paquete {jtools}: Similar al anterior, pero más conciso y excelente para comparar múltiples modelos.\n\n\nlibrary(jtools)\nlibrary(ggstance)\n\n\nAttaching package: 'ggstance'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    geom_errorbarh, GeomErrorbarh\n\nplot_summs(modelo_multiple, omit.coefs = NULL)\n\n\n\n\n\n\n\n\nEste gráfico es similar al anterior, pero más compacto. Nuevamente, los coeficientes significativos son aquellos cuyos intervalos de confianza no cruzan el cero.\nClaro, aquí tienes la traducción y adaptación del texto al contexto médico de la presión arterial.\n\n\n3.2.6 Como presentar los resultados del modelo\nGracias a la función model_parameters() del paquete {parameters}, puedes imprimir un resumen del modelo en un formato agradable para que el resultado sea más legible.\n\n# Nota: Usamos el 'modelo_multiple' que creamos en la sección anterior.\n#install.packages(\"parameters\") # instalar el paquete si no está ya instalado\nlibrary(parameters)\nmodel_parameters(modelo_multiple, summary = TRUE)\n\nParameter               | Coefficient |   SE |         95% CI | t(96) |      p\n------------------------------------------------------------------------------\n(Intercept)             |       61.43 | 7.18 | [47.19, 75.68] |  8.56 | &lt; .001\nimc                     |        1.61 | 0.23 | [ 1.16,  2.06] |  7.09 | &lt; .001\nedad                    |        0.81 | 0.07 | [ 0.68,  0.95] | 11.74 | &lt; .001\ntabaquismo [No fumador] |       -5.36 | 1.82 | [-8.97, -1.74] | -2.94 | 0.004 \n\n\nY si estás usando R Markdown, puedes usar la función print_html() para obtener una tabla de resumen compacta pero completa en tu archivo HTML.\n\n#install.packages(\"gt\") # instalar el paquete si no está ya instalado\nlibrary(gt)\nprint_html(model_parameters(modelo_multiple, summary = TRUE))\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(96)\np\n\n\n\n\n(Intercept)\n61.43\n7.18\n(47.19, 75.68)\n8.56\n&lt; .001\n\n\nimc\n1.61\n0.23\n(1.16, 2.06)\n7.09\n&lt; .001\n\n\nedad\n0.81\n0.07\n(0.68, 0.95)\n11.74\n&lt; .001\n\n\ntabaquismo (No fumador)\n-5.36\n1.82\n(-8.97, -1.74)\n-2.94\n0.004\n\n\n\n\n\n\n\nLa función report() del paquete del mismo nombre permite producir automáticamente informes de modelos de acuerdo con las directrices de buenas prácticas.\n\n#install.packages(\"report\") # instalar el paquete si no está ya instalado\nlibrary(report)\nreport(modelo_multiple)\n\nWe fitted a linear model (estimated using OLS) to predict presion_sistolica\nwith imc, edad and tabaquismo (formula: presion_sistolica ~ imc + edad +\ntabaquismo). The model explains a statistically significant and substantial\nproportion of variance (R2 = 0.71, F(3, 96) = 79.03, p &lt; .001, adj. R2 = 0.70).\nThe model's intercept, corresponding to imc = 0, edad = 0 and tabaquismo =\nFumador, is at 61.43 (95% CI [47.19, 75.68], t(96) = 8.56, p &lt; .001). Within\nthis model:\n\n  - The effect of imc is statistically significant and positive (beta = 1.61, 95%\nCI [1.16, 2.06], t(96) = 7.09, p &lt; .001; Std. beta = 0.40, 95% CI [0.29, 0.51])\n  - The effect of edad is statistically significant and positive (beta = 0.81,\n95% CI [0.68, 0.95], t(96) = 11.74, p &lt; .001; Std. beta = 0.65, 95% CI [0.54,\n0.76])\n  - The effect of tabaquismo [No fumador] is statistically significant and\nnegative (beta = -5.36, 95% CI [-8.97, -1.74], t(96) = -2.94, p = 0.004; Std.\nbeta = -0.35, 95% CI [-0.59, -0.12])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\n3.2.7 Predicciones\nLa regresión lineal se utiliza muy a menudo con fines predictivos. Los intervalos de confianza y de predicción para nuevos datos se pueden calcular con la función predict(). Supongamos que queremos predecir la presión arterial sistólica para un nuevo paciente de 55 años, no fumador, con un IMC de 30:\n\n# creamos el dataframe para el nuevo paciente\nnuevo_paciente &lt;- data.frame(\n  imc = 30,\n  edad = 55,\n  tabaquismo = \"No fumador\"\n)\n\n# intervalo de confianza para los nuevos datos\npredict(modelo_multiple,\n        newdata = nuevo_paciente,\n        interval = \"confidence\",\n        level = .95)\n\n       fit      lwr      upr\n1 149.1495 146.8579 151.4411\n\n\nSegún nuestro modelo, se espera que este paciente tenga una presión arterial sistólica de 149.1 mmHg. La diferencia entre el intervalo de confianza y el de predicción es que: - un intervalo de confianza da el valor predicho para la media de la presión arterial de todos los pacientes con estas características. - un intervalo de predicción da el rango probable para el valor de un individuo específico con estas características.\nPor lo tanto, el intervalo de predicción es más amplio que el de confianza para tener en cuenta la incertidumbre adicional de predecir una respuesta individual en lugar de una media.\nLas formulas para calcular estos intervalos se basan en la distribución t de Student y se pueden encontrar en cualquier libro de estadística sobre regresión lineal (por ejemplo, [4], sección 3.2.4).\nEn concreto estas son: - Intervalo de confianza para la media predicha por el modelo: \\[\\hat{y} \\pm t_{\\alpha/2, n-p-1} \\cdot s \\cdot \\sqrt{\\frac{1}{n} + \\frac{(x_h - \\bar{x})^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}}\\] - Intervalo de predicción para una nueva observación: \\[\\hat{y} \\pm t_{\\alpha/2, n-p-1} \\cdot s \\cdot \\sqrt{1 + \\frac{1}{n} + \\frac{(x_h - \\bar{x})^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}}\\] donde: - \\(\\hat{y}\\) es la predicción puntual, - \\(t_{\\alpha/2, n-p-1}\\) es el valor crítico de la distribución t de Student con \\(n-p-1\\) grados de libertad, - \\(s\\) es el error estándar de la estimación, - \\(n\\) es el número de observaciones en el conjunto de datos, - \\(p\\) es el número de predictores en el modelo, - \\(x_h\\) es el valor del predictor para el cual se realiza la predicción, - \\(\\bar{x}\\) es la media de los valores del predictor en el conjunto de datos, - \\(x_i\\) son los valores individuales del predictor en el conjunto de datos.\n\n\n3.2.8 Pruebas de hipótesis lineales\nLas pruebas de hipótesis lineales permiten generalizar la prueba F y ofrecen la posibilidad de realizar pruebas de comparación de coeficientes o de igualdad de combinaciones lineales de coeficientes. Por ejemplo, para probar la restricción lineal de que los coeficientes de IMC y edad son simultáneamente cero:\n\n\\(H_0: \\beta_{imc} = \\beta_{edad} = 0\\)\n\\(H_1:\\) no \\(H_0\\)\n\nUsamos la función linearHypothesis() del paquete {car}:\n\nlibrary(car)\nlinearHypothesis(modelo_multiple, c(\"imc = 0\", \"edad = 0\"))\n\n\nLinear hypothesis test:\nimc = 0\nedad = 0\n\nModel 1: restricted model\nModel 2: presion_sistolica ~ imc + edad + tabaquismo\n\n  Res.Df     RSS Df Sum of Sq   F                Pr(&gt;F)    \n1     98 21085.0                                           \n2     96  6529.5  2     14556 107 &lt; 0.00000000000000022 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nRechazamos la hipótesis nula y concluimos que al menos uno de los coeficientes (\\(\\beta_{imc}\\) o \\(\\beta_{edad}\\)) es diferente de 0 (p-valor &lt; 2.2e-16).\n\n\n3.2.9 Efecto global de las variables categóricas\nCuando una variable independiente categórica tiene \\(k\\) categorías, la tabla de regresión proporciona \\(k-1\\) p-valores. En nuestro modelo, tabaquismo solo tiene 2 niveles, por lo que su p-valor ya representa su efecto global. Pero, ¿qué pasaría si tuviéramos una variable con más de 2 niveles, como un nivel_actividad_fisica (“Bajo”, “Moderado”, “Alto”)? Para obtener un único p-valor que nos diga si la actividad física en general es un predictor significativo, necesitamos una tabla de análisis de varianza (ANOVA).\nVeamos un ejemplo hipotético:\n\n# Añadimos una variable categórica hipotética al dataset\nset.seed(123)\ndat$actividad_fisica &lt;- factor(sample(c(\"Bajo\", \"Moderado\", \"Alto\"), 100, replace = TRUE))\n\n# Creamos un nuevo modelo\nmodelo_actividad &lt;- lm(presion_sistolica ~ imc + edad + actividad_fisica, data = dat)\n\n# Usamos la función Anova() del paquete {car}\nAnova(modelo_actividad)\n\nAnova Table (Type II tests)\n\nResponse: presion_sistolica\n                 Sum Sq Df  F value                Pr(&gt;F)    \nimc              3297.9  1  45.8146        0.000000001067 ***\nedad             9032.6  1 125.4791 &lt; 0.00000000000000022 ***\nactividad_fisica  280.0  2   1.9451                0.1486    \nResiduals        6838.5 95                                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEn esta tabla ANOVA, ahora tendríamos una sola fila para actividad_fisica con un único p-valor, que nos indicaría si la variable en su conjunto es significativa para predecir la presión arterial. Pero ahora queremos interpretar los valores de los coeficientes para cada uno de los nivels de actividad física:\n\nsummary(modelo_actividad)\n\n\nCall:\nlm(formula = presion_sistolica ~ imc + edad + actividad_fisica, \n    data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.8987  -6.3074   0.2153   5.3885  18.6074 \n\nCoefficients:\n                         Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)              55.78113    7.05763   7.904      0.0000000000048 ***\nimc                       1.60934    0.23776   6.769      0.0000000010666 ***\nedad                      0.80597    0.07195  11.202 &lt; 0.0000000000000002 ***\nactividad_fisicaBajo      3.31391    2.13689   1.551               0.1243    \nactividad_fisicaModerado  3.87089    2.11120   1.834               0.0699 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.484 on 95 degrees of freedom\nMultiple R-squared:  0.6981,    Adjusted R-squared:  0.6854 \nF-statistic: 54.93 on 4 and 95 DF,  p-value: &lt; 0.00000000000000022\n\n\nAquí, los coeficientes para actividad_fisicaModerado y actividad_fisicaAlto nos indican la diferencia en la presión arterial en comparación con el grupo de referencia actividad_fisicaBajo. Si ambos coeficientes son significativos, podemos concluir que tanto el nivel moderado como el alto de actividad física tienen un efecto significativo en la presión arterial en comparación con el nivel bajo. Lo que hemos introducido es el concepto de varialbe dummy y contraste de tipo tratamiento donde el nivel más bajo de la variable categórica es seleccionado como referencia. Este tipo de contraste es el más comúnmente utilizado en los modelos de regresión. La variable dummy convierte una variable categórica en múltiples variables binarias (0/1) para cada nivel, excepto el nivel de referencia. Cada coeficiente asociado a estas variables binarias representa la diferencia en la respuesta (presión arterial) entre ese nivel y el nivel de referencia, manteniendo constantes las otras variables en el modelo.\n\n# Visualización del efecto de la actividad física\nvisreg(modelo_actividad, \"actividad_fisica\", gg = TRUE) + theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3.2.10 Interacciones\nHasta ahora hemos cubierto la regresión lineal múltiple sin ninguna interacción. Existe un efecto de interacción entre los factores A y B si el efecto del factor A sobre la respuesta depende del nivel que tome el factor B. Por ejemplo, ¿podría ser que el efecto del IMC sobre la presión arterial sea diferente para fumadores y no fumadores? Podríamos hipotetizar que el efecto del IMC es peor (más pronunciado) en fumadores. Esto es una interacción.\nEn R, la interacción se añade con * o ::\n\n# Modelo con interacción entre IMC y Tabaquismo, ajustado por edad\nmodelo_interaccion &lt;- lm(presion_sistolica ~ imc * tabaquismo + edad,\n                         data = dat)\n\nsummary(modelo_interaccion)\n\n\nCall:\nlm(formula = presion_sistolica ~ imc * tabaquismo + edad, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.5186  -5.9523  -0.1141   5.0251  19.8884 \n\nCoefficients:\n                          Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)               80.69191   13.03579   6.190         0.0000000152 ***\nimc                        0.94301    0.43955   2.145               0.0345 *  \ntabaquismoNo fumador     -30.84996   14.58376  -2.115               0.0370 *  \nedad                       0.81182    0.06868  11.821 &lt; 0.0000000000000002 ***\nimc:tabaquismoNo fumador   0.89730    0.50938   1.762               0.0814 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.158 on 95 degrees of freedom\nMultiple R-squared:  0.7209,    Adjusted R-squared:  0.7092 \nF-statistic: 61.35 on 4 and 95 DF,  p-value: &lt; 0.00000000000000022\n\n\nEl término imc:tabaquismoFumador representa la interacción. Si su p-valor fuera significativo (en este caso, no lo es con p=0.08), concluiríamos que existe una interacción. Esto significaría que la pendiente que relaciona el IMC con la presión arterial depende de si una persona fuma o no. La forma más fácil de interpretar una interacción es visualizarla:\n\nvisreg(modelo_interaccion, \"imc\", by = \"tabaquismo\", gg = TRUE) + theme_minimal()\n\n\n\n\n\n\n\n\nEl gráfico muestra las dos líneas de regresión (una para fumadores, otra para no fumadores). Si hay una interacción significativa, estas líneas tendrán pendientes notablemente diferentes. En nuestro caso, son casi paralelas, lo que concuerda con la falta de significancia estadística de la interacción. Este es un buen ejemplo para ilustrar que, al estudiar una relación, es importante considerar cómo otras variables pueden modificar dicha relación. Omitir interacciones importantes puede llevar a conclusiones erróneas.\n\n\n3.2.11 Multicolinealidad: VIF\nLa multicolinealidad ocurre cuando dos o más variables independientes están altamente correlacionadas entre sí. Esto puede causar problemas en la estimación de los coeficientes del modelo, ya que dificulta la separación de los efectos individuales de cada variable. Para evaluar la multicolinealidad, podemos calcular el Factor de Inflación de la Varianza (VIF) para cada variable independiente. Un VIF alto indica que una variable está altamente correlacionada con las demás.\n\n# Calcular VIF\nlibrary(car)\nvif_values &lt;- vif(modelo_multiple)\nvif_values\n\n       imc       edad tabaquismo \n  1.038699   1.022739   1.022810 \n\n# Interpretación de VIF\nif(any(vif_values &gt; 5)){\n  print(\"Hay multicolinealidad significativa entre las variables independientes.\")\n} else {\n  print(\"No hay multicolinealidad significativa entre las variables independientes.\")\n}\n\n[1] \"No hay multicolinealidad significativa entre las variables independientes.\"\n\n\n\n\n3.2.12 Validación del modelo via cross-validation\nLa validación cruzada es una técnica utilizada para evaluar la capacidad predictiva de un modelo. Consiste en dividir el conjunto de datos en varios subconjuntos (o “folds”), entrenar el modelo en algunos de estos subconjuntos y luego probarlo en los restantes. Esto ayuda a estimar cómo se desempeñará el modelo en datos no vistos.\n\n# install.packages(\"caret\") # instalar el paquete si no está ya instalado\nlibrary(caret)\nset.seed(123)\n# Definir el control de entrenamiento para 10-fold cross-validation\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n# Entrenar el modelo usando cross-validation\nmodelo_cv &lt;- train(presion_sistolica ~ imc + edad + tabaquismo,\n                   data = dat,\n                   method = \"lm\",\n                   trControl = train_control)\n# Resultados de la validación cruzada\nmodelo_cv\n\nLinear Regression \n\n100 samples\n  3 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 89, 89, 91, 91, 91, 90, ... \nResampling results:\n\n  RMSE      Rsquared   MAE     \n  8.359981  0.7483465  6.828316\n\nTuning parameter 'intercept' was held constant at a value of TRUE\n\n# Obtener el RMSE promedio de la validación cruzada\nmean(modelo_cv$resample$RMSE)\n\n[1] 8.359981\n\n\nEl resultado muestra el rendimiento del modelo en términos de RMSE (Root Mean Squared Error) promedio a través de los 10 folds. Un RMSE más bajo indica un mejor desempeño predictivo del modelo. Esta técnica es especialmente útil para evitar el sobreajuste y asegurar que el modelo generalice bien a nuevos datos. También podemos comparar el desempeño de diferentes modelos en base a la especificación del mismo. Por ejemplo comparemos el RMSE de un modelo con el efecto cuadrático del IMC frente a un modelo lineal simple.\n\n# Modelo con efecto cuadrático del IMC\nmodelo_cuadratico &lt;- train(presion_sistolica ~ poly(imc, 2) + edad + tabaquismo,\n                            data = dat,\n                            method = \"lm\",\n                            trControl = train_control)\n# Resultados de la validación cruzada para el modelo cuadrático\nmodelo_cuadratico\n\nLinear Regression \n\n100 samples\n  3 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 90, 90, 91, 89, 90, 90, ... \nResampling results:\n\n  RMSE      Rsquared   MAE     \n  8.335399  0.7085369  6.821517\n\nTuning parameter 'intercept' was held constant at a value of TRUE\n\n# Obtener el RMSE promedio de la validación cruzada para el modelo cuadrático\nmean(modelo_cuadratico$resample$RMSE)\n\n[1] 8.335399\n\n\nConcluimos que el modelo con el efecto cuadrático del IMC tiene un RMSE más bajo que el modelo lineal simple, lo que sugiere que el modelo cuadrático tiene un mejor desempeño predictivo para este conjunto de datos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>TEMA 3: REGRESIÓN LINEAL MÚLTIPLE</span>"
    ]
  },
  {
    "objectID": "TEMA-4.html",
    "href": "TEMA-4.html",
    "title": "4  TEMA 4: REGRESIÓN LOGISTICA",
    "section": "",
    "text": "4.1 Introducción\nCuando hayamos terminado este tema, seremos capaces de:\nLa regresión es una herramienta común en estadística para probar y cuantificar relaciones entre variables. Las dos regresiones más comunes son la regresión lineal y la logística. Una regresión lineal se utiliza cuando la variable dependiente es cuantitativa, mientras que una regresión logística se utiliza cuando la variable dependiente es cualitativa, en concreto dicotómica (binaria). Tanto la regresión lineal como la logística se dividen en diferentes tipos. Antes de detallarlos, recapitulemos primero qué tipo de variable puede ser:\nUna variable binaria, también conocida como dicotómica, es un caso especial de variable cualitativa nominal cuando hay solo dos categorías.\nAhora que los tipos de variables están claros, resumamos los diferentes tipos de regresión:\nTen en cuenta que existe otro tipo de regresión: la regresión de Poisson. Este tipo de regresión se utiliza cuando el objetivo es estimar la relación entre una variable dependiente que está en forma de datos de conteo (número de ocurrencias de un evento de interés durante un período de tiempo o espacio determinado, por ejemplo, \\(0, 1, 2, \\ldots\\)) y una o más variables independientes.\nLas regresiones logísticas y de Poisson forman parte de un tipo más amplio de modelo llamado modelos lineales generalizados (abreviado como GLM). El nombre “modelos lineales generalizados” proviene del hecho de que estos modelos permiten “generalizar” el modelo lineal clásico. De hecho, se pueden utilizar en muchas situaciones, por ejemplo, al analizar una variable dependiente que no es necesariamente cuantitativa continua o cuando los residuos no se distribuyen normalmente (que son requisitos previos para un modelo lineal). El libro An Introduction to Categorical Data Analysis es una excelente introducción del análisis de datos categóricos, incluidas las regresiones logísticas y de Poisson [1]. Otro referente es el libro Regression Methods in Biostatistics: Linear, Logistic, Survival, and Repeated Measures Models [2].",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TEMA 4: REGRESIÓN LOGISTICA</span>"
    ]
  },
  {
    "objectID": "TEMA-4.html#introducción",
    "href": "TEMA-4.html#introducción",
    "title": "4  TEMA 4: REGRESIÓN LOGISTICA",
    "section": "",
    "text": "Una variable cuantitativa mide una cantidad; los valores que puede tomar son números. Se divide en:\n\nDiscreta: los valores que puede tomar son contables y tienen un número finito de posibilidades (los valores suelen ser enteros, por ejemplo, el número de hijos).\nContinua: los valores que puede tomar no son contables y tienen un número infinito de posibilidades (los valores suelen tener decimales, o al menos los decimales son técnicamente posibles, por ejemplo, el peso).\n\n\nUna variable cualitativa (también conocida como categórica) no es numérica y sus valores se ajustan a categorías. También se divide en dos tipos:\n\nNominal: no es posible ni está implícito un orden en las categorías (por ejemplo, el sexo).\nOrdinal: existe un orden implícito en las categorías (por ejemplo, el estado de salud, como malo/regular/bueno).\n\n\n\n\n\nRegresión lineal:\n- La regresión lineal simple se utiliza cuando el objetivo es estimar la relación entre una variable dependiente cuantitativa continua (también llamada variable de resultado o respuesta) y solo una variable independiente (también llamada variable explicativa, covariable o predictora) de cualquier tipo.\n- La regresión lineal múltiple se utiliza cuando el objetivo es estimar la relación entre una variable dependiente cuantitativa continua y dos o más variables independientes (de nuevo, de cualquier tipo).\n\nRegresión logística: - La regresión logística binaria se utiliza cuando el objetivo es estimar la relación entre una variable dependiente binaria (= dos resultados) y una o más variables independientes (de cualquier tipo).\n- La regresión logística multinomial se utiliza cuando el objetivo es estimar la relación entre una variable dependiente nominal con tres o más resultados no ordenados y una o más variables independientes (de cualquier tipo). - La regresión logística ordinal se utiliza cuando el objetivo es estimar la relación entre una variable dependiente ordinal con tres o más resultados ordenados y una o más variables independientes (de cualquier tipo).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TEMA 4: REGRESIÓN LOGISTICA</span>"
    ]
  },
  {
    "objectID": "TEMA-4.html#regresión-lineal-versus-logística",
    "href": "TEMA-4.html#regresión-lineal-versus-logística",
    "title": "4  TEMA 4: REGRESIÓN LOGISTICA",
    "section": "4.2 Regresión lineal versus logística",
    "text": "4.2 Regresión lineal versus logística\nSabemos que una regresión lineal es una forma conveniente de estimar la relación entre una variable dependiente cuantitativa continua y una o más variables independientes (de cualquier tipo). Por ejemplo, supongamos que nos gustaría estimar la relación entre dos variables cuantitativas, \\(X\\) e \\(Y\\). Usando el método de mínimos cuadrados ordinarios (el estimador más común utilizado en la regresión lineal), obtenemos la siguiente línea de regresión:\n\n\n\n\n\n\n\n\n\nAhora supongamos que estamos interesados en estimar el impacto de la edad en si un paciente tiene o no una determinada enfermedad. La edad se considera una variable cuantitativa continua, mientras que tener la enfermedad es binario (un paciente está enfermo o sano). Visualmente, podríamos tener algo como esto:\n\n\n\n\n\n\n\n\n\nSi ajustamos una línea de regresión (utilizando el método de mínimos cuadrados ordinarios) a los puntos, obtenemos el siguiente gráfico:\n\n\n\n\n\n\n\n\n\nVemos que la línea de regresión va por debajo de 0 y por encima de 1 con respecto al eje \\(y\\). Dado que la variable dependiente enfermedad no puede tomar valores por debajo de 0 (= sano) ni por encima de 1 (= enfermo), ¡es obvio que una regresión lineal no es apropiada para estos datos. Además de esta limitación, los supuestos de normalidad y homocedasticidad, que se requieren en la regresión lineal, claramente no son apropiados con estos datos, ya que la variable dependiente es binaria y sigue una distribución Binomial. R no te impedirá realizar una regresión lineal con datos binarios, pero producirá un modelo de poco interés (incorrectamente especificado con una mala interpretación de la relación entre variables). Aquí es donde una regresión logística se vuelve útil, ya que toma en consideración estas limitaciones [3].\nAplicado a nuestro ejemplo, así es como se ajustan los puntos utilizando una regresión logística binaria:\n\n\n\n\n\n\n\n\n\nEstá claro que este modelo es más apropiado. La curva (conocida como sigmoide) se obtiene mediante una transformación de los valores predichos. Hay varias opciones posibles para la función de enlace, cuyo objetivo es restringir los valores predichos para que estén dentro del rango de los valores observados. La más utilizada en la práctica es la función logit, que relaciona la probabilidad de ocurrencia de un evento (acotada entre 0 y 1) con la combinación lineal de las variables independientes. La función logit también resulta ser la función de enlace canónica para una distribución de Bernoulli o Binomial. Esta transformación asegura que, sin importar en qué rango se encuentren los valores de \\(X\\), \\(Y\\) solo tomará números entre 0 y 1.\nSu formula es:\n\\[logit(\\pi) = \\log\\left(\\frac{\\pi}{1 - \\pi}\\right)\\]\ndonde \\(\\pi\\) es la probabilidad de que ocurra un evento (éxito) y se denota como \\(\\pi = P(éxito)\\).\nSe podría decir que los valores ajustados (= representados por la curva azul) que toman valores entre 0 y 1 tampoco parecen tener sentido, ya que un paciente solo puede estar sano o enfermo (y, por lo tanto, la variable dependiente solo puede tomar el valor 0 o 1, respectivamente). Sin embargo, en una regresión logística binaria no se modela directamente el resultado de no enfermedad/enfermedad, sino la probabilidad de que un paciente tenga la enfermedad o no, dadas sus características. Esta probabilidad se enmarcará en términos de una probabilidad de observar o no la enfermedad en un paciente, que de hecho está incluida entre 0 y 1, o 0% y 100%.\nEn general, con una regresión logística nos gustaría modelar cómo varía la probabilidad de éxito con las variables independientes y determinar si estos cambios son estadísticamente significativos o no. En realidad, vamos a modelar el logaritmo de los odds, y el modelo de regresión logística se escribirá de la siguiente manera:\n\\[\\begin{align}\n\\log(odds(éxito)) &= logit(\\pi) \\\\\n&= \\log\\left(\\frac{\\pi}{1 - \\pi}\\right) \\\\\n&= \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p\n\\end{align}\\]\ndonde \\(\\pi\\) \\((0 \\le \\pi \\le 1)\\) es la probabilidad de que ocurra un evento (éxito) y se denota como \\(\\pi = P(éxito)\\). Encontramos los valores de \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), \\(\\ldots\\), \\(\\hat{\\beta}_p\\), que se utilizan como estimaciones para \\(\\beta_0\\), \\(\\beta_1\\), \\(\\ldots\\), \\(\\beta_p\\), utilizando el método de máxima verosimilitud. Este método es uno de los varios métodos utilizados en estadística para estimar los parámetros de un modelo matemático. El objetivo del estimador es estimar los parámetros \\(\\beta_0\\), \\(\\beta_1\\), \\(\\ldots\\), \\(\\beta_p\\) que maximizan la función de log-verosimilitud. Las regresiones logísticas son muy comunes en el campo de la medicina, por ejemplo, para:\n\nEstimar los factores de riesgo asociados con una enfermedad o una condición dañina.\nPredecir el riesgo de desarrollar una enfermedad basándose en las características de un paciente.\nDeterminar los factores biológicos más importantes asociados con una enfermedad o condición específica.\n\nSin embargo, las regresiones logísticas se utilizan en muchos otros dominios, por ejemplo, en:\n\nSector bancario: estimar la solvencia de un deudor basándose en su perfil (ingresos, activos, pasivos, etc.).\nMarketing: estimar la propensión de un cliente a comprar un producto o servicio basándose en su perfil (edad, sexo, salario, compras anteriores, etc.).\nDeportes: estimar la probabilidad de que un jugador gane contra otro jugador en función de las características de los dos oponentes.\nPolítica: responder a la pregunta “¿Votaría un ciudadano por nuestro partido político en las próximas elecciones?”.\n\nEtc.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TEMA 4: REGRESIÓN LOGISTICA</span>"
    ]
  },
  {
    "objectID": "TEMA-4.html#breve-introducción-al-método-de-estimación-de-máxima-verosimilitud",
    "href": "TEMA-4.html#breve-introducción-al-método-de-estimación-de-máxima-verosimilitud",
    "title": "4  TEMA 4: REGRESIÓN LOGISTICA",
    "section": "4.3 Breve introducción al método de estimación de máxima verosimilitud",
    "text": "4.3 Breve introducción al método de estimación de máxima verosimilitud\nEl método de máxima verosimilitud es un enfoque estadístico utilizado para estimar los parámetros de un modelo matemático. La idea principal detrás de este método es encontrar los valores de los parámetros que maximizan la función de verosimilitud, que mide qué tan probable es observar los datos dados los parámetros del modelo. En el contexto de la regresión logística, el método de máxima verosimilitud se utiliza para estimar los coeficientes del modelo (\\(\\beta_0\\), \\(\\beta_1\\), …, \\(\\beta_p\\)) que describen la relación entre las variables independientes y la variable dependiente binaria. La función de verosimilitud se define como la probabilidad conjunta de observar los datos dados los parámetros del modelo. La función de verosimilitud para la regresión logística se expresa como:\n\\[L(\\beta_0, \\beta_1, \\ldots, \\beta_p) = \\prod_{i=1}^{n} P(Y_i | X_i; \\beta_0, \\beta_1, \\ldots, \\beta_p)\\]\ndonde \\(P(Y_i | X_i; \\beta_0, \\beta_1, \\ldots, \\beta_p)\\) es la probabilidad condicional de observar el valor \\(Y_i\\) dado el vector de variables independientes \\(X_i\\) y los parámetros del modelo.\nPara facilitar el proceso de maximización, se suele trabajar con la función de log-verosimilitud, que es el logaritmo natural de la función de verosimilitud:\n\\[\\ell(\\beta_0, \\beta_1, \\ldots, \\beta_p) = \\log L(\\beta_0, \\beta_1, \\ldots, \\beta_p) = \\sum_{i=1}^{n} \\log P(Y_i | X_i; \\beta_0, \\beta_1, \\ldots, \\beta_p)\\]\nEl objetivo del método de máxima verosimilitud es encontrar los valores de los parámetros (\\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), …, \\(\\hat{\\beta}_p\\)) que maximizan la función de log-verosimilitud. Esto se logra resolviendo el siguiente problema de optimización:\n\\[\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p = \\arg\\max_{\\beta_0, \\beta_1, \\ldots, \\beta_p} \\ell(\\beta_0, \\beta_1, \\ldots, \\beta_p)\\] Para el modelo de regresión logística, la función de log-verosimilitud para la regresión logística binaria se puede expresar como: \\[\\ell(\\beta_0, \\beta_1, \\ldots, \\beta_p) = \\sum_{i=1}^{n} \\left[ Y_i \\log(\\pi_i) + (1 - Y_i) \\log(1 - \\pi_i) \\right]\\] donde \\(\\pi_i\\) es la probabilidad predicha de que \\(Y_i = 1\\) dado el vector de variables independientes \\(X_i\\) y los parámetros del modelo, y se calcula como:\n\\[\\pi_i = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_{i1} + \\ldots + \\beta_p X_{ip})}}\\] Notese que la función de log-verosimilitud es una suma de términos que dependen de los valores observados de la variable dependiente \\(Y_i\\) y las probabilidades predichas \\(\\pi_i\\). El primer término, \\(Y_i \\log(\\pi_i)\\), contribuye a la función de log-verosimilitud cuando \\(Y_i = 1\\), mientras que el segundo término, \\((1 - Y_i) \\log(1 - \\pi_i)\\), contribuye cuando \\(Y_i = 0\\). Esta formula se deriva de la distribución Bernoulli de la variable dependiente en la regresión logística binaria. Asi, la función de log-verosimilitud mide qué tan bien el modelo con los parámetros dados explica los datos observados. La maximización de esta función permite encontrar los valores de los parámetros que mejor explican la relación entre las variables independientes y la variable dependiente binaria. Además la función de log-verosimilitud es más fácil de manejar matemáticamente que la función de verosimilitud original, ya que convierte el producto en una suma, lo que simplifica los cálculos y la optimización.\nEl método de máxima verosimilitud es ampliamente utilizado en estadística y econometría debido a sus propiedades deseables, como la consistencia y la eficiencia de los estimadores. Sin embargo, es importante tener en cuenta que la maximización de la función de log-verosimilitud puede ser un proceso computacionalmente intensivo, especialmente cuando se trabaja con grandes conjuntos de datos o modelos complejos. En R, la función glm() utiliza el método de máxima verosimilitud para estimar los coeficientes de un modelo de regresión logística. Y se computa de forma iterativa utilizando el algoritmo de Newton-Raphson o el método de Fisher Scoring. El primero es un método numérico para encontrar las raíces de una función, mientras que el segundo es una variante del primero que utiliza la información de la varianza de los datos para mejorar la convergencia. Las raíces de la función de log-verosimilitud corresponden a los valores de los parámetros que maximizan la función, es decir, los estimadores de máxima verosimilitud. Y esto se hace iterativamente hasta que se alcanza la convergencia, es decir, hasta que los cambios en los valores de los parámetros entre iteraciones sucesivas son suficientemente pequeños. Este algoritmo es eficiente y converge rápidamente en la mayoría de los casos, lo que lo hace adecuado para estimar los coeficientes de modelos de regresión logística. Y se describe matematicamente como: \\[\\beta^{(t+1)} = \\beta^{(t)} - H^{-1}(\\beta^{(t)}) \\nabla \\ell(\\beta^{(t)})\\] donde \\(\\beta^{(t)}\\) es el vector de parámetros en la iteración \\(t\\), \\(\\nabla \\ell(\\beta^{(t)})\\) es el gradiente de la función de log-verosimilitud evaluado en \\(\\beta^{(t)}\\), y \\(H(\\beta^{(t)})\\) es la matriz Hessiana de la función de log-verosimilitud evaluada en \\(\\beta^{(t)}\\). El proceso se repite hasta que se alcanza la convergencia. Un ejemplo en R es el siguiente:\n\n# Generar datos\nset.seed(42)\nn &lt;- 1000\nX &lt;- rnorm(n)\nlogit_pi &lt;- -1 + 0.05 * X\npi &lt;- exp(logit_pi) / (1 + exp(logit_pi))\nY &lt;- rbinom(n, size = 1, prob = pi)\ndata &lt;- data.frame(X = X, Y = Y)\nhead(data)\n\n           X Y\n1  1.3709584 1\n2 -0.5646982 0\n3  0.3631284 0\n4  0.6328626 1\n5  0.4042683 1\n6 -0.1061245 1\n\n# ajustar modelo de regresión logística\nmodel &lt;- glm(Y ~ X, data = data, family = \"binomial\")\n# manualmente calcular la función de log-verosimilitud\nlog_likelihood &lt;- function(params, data) {\n  beta_0 &lt;- params[1]\n  beta_1 &lt;- params[2]\n  X &lt;- data$X\n  Y &lt;- data$Y\n  logit_pi &lt;- beta_0 + beta_1 * X\n  pi &lt;- exp(logit_pi) / (1 + exp(logit_pi))\n  ll &lt;- sum(Y * log(pi) + (1 - Y) * log(1 - pi))\n  return(-ll) # devolver el negativo para minimizar\n}\n# encontrar los valores de beta_0 y beta_1 que maximizan la función de log-verosimilitud\ninitial_params &lt;- c(0, 0)\noptim_result &lt;- optim(initial_params, log_likelihood, data = data)\n\n# mostrar los resultados de optimización\noptim_result$par\n\n[1] -0.91913376  0.03542776\n\n# comparar con los coeficientes del modelo ajustado\ncoef(model)\n\n(Intercept)           X \n-0.91915123  0.03524851",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TEMA 4: REGRESIÓN LOGISTICA</span>"
    ]
  },
  {
    "objectID": "TEMA-4.html#regresión-logística-univariable-versus-multivariable",
    "href": "TEMA-4.html#regresión-logística-univariable-versus-multivariable",
    "title": "4  TEMA 4: REGRESIÓN LOGISTICA",
    "section": "4.4 Regresión logística univariable versus multivariable",
    "text": "4.4 Regresión logística univariable versus multivariable\nLas regresiones logísticas binarias univariables y luego las regresiones logísticas binarias multivariables. Recuerda que en ambos casos, la variable dependiente debe ser una variable cualitativa con dos resultados (de ahí el nombre de regresión logística binaria). La diferencia entre una regresión logística binaria univariable y multivariable radica en que:\n\nPara una regresión logística binaria univariable, solo hay una variable independiente.\nPara una regresión logística binaria multivariable, hay dos o más variables independientes.\n\nEs cierto que el término “univariable” puede ser confuso aquí porque hay dos variables en el modelo (es decir, una variable dependiente y una variable independiente). Sin embargo, se llama regresión logística binaria univariable para indicar que solo se considera una variable independiente en el modelo, a diferencia de la regresión logística binaria multivariable, donde se consideran varias variables independientes en el modelo.\nPara hacer un paralelismo con la regresión lineal:\n\nUna regresión logística binaria univariable es el equivalente a una regresión lineal simple.\nUna regresión logística binaria multivariable es el equivalente a una regresión lineal múltiple.\n\ncuando la variable dependiente es binaria en lugar de cuantitativa continua. Esta es la razón por la que una regresión logística binaria univariable a veces se llama regresión logística binaria simple y una regresión logística binaria multivariable a veces se llama regresión logística binaria múltiple.\nEl número de variables dependientes caracteriza el modelo como univariado o multivariado; univariado se refiere a un modelo con una sola variable dependiente, mientras que multivariado se refiere a un modelo que predice simultáneamente más de una variable dependiente. Por lo general, la intención es diferenciar los modelos en función del número de variables independientes. Esta distinción se hace gracias a los términos univariable y multivariable. Multivariable se refiere a un modelo que relaciona múltiples variables predictoras con una variable dependiente, mientras que univariable se refiere a un modelo que relaciona una única variable independiente con una variable dependiente.\nPara estas ilustrar la aplicación del método vamos a utilizar el conjunto de datos “Heart Disease”, disponible en el paquete de R {kmed}. Este data frame consta de 14 variables, de las cuales solo vamos a utilizar 5:\n\nage: edad en años\nsex: sexo (FALSE = mujer, TRUE = hombre)\ncp: tipo de dolor torácico (1 = angina típica, 2 = angina atípica, 3 = dolor no anginoso, 4 = asintomático)\nthalach: frecuencia cardíaca máxima alcanzada\nclass: diagnóstico de enfermedad cardíaca (dividido en 4 clases)\n\n\n# importar y renombrar el conjunto de datos\nlibrary(kmed)\ndat &lt;- heart\n\n# seleccionar variables\nlibrary(dplyr)\ndat &lt;- dat |&gt;\n  select(\n    age,\n    sex,\n    cp,\n    thalach,\n    class\n  )\n\n# imprimir la estructura del conjunto de datos\nstr(dat)\n\n'data.frame':   297 obs. of  5 variables:\n $ age    : num  63 67 67 37 41 56 62 57 63 53 ...\n $ sex    : logi  TRUE TRUE TRUE TRUE FALSE TRUE ...\n $ cp     : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 4 4 3 2 2 4 4 4 4 ...\n $ thalach: num  150 108 129 187 172 178 160 163 147 155 ...\n $ class  : int  0 2 1 0 0 0 3 0 2 1 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:6] 88 167 193 267 288 303\n  ..- attr(*, \"names\")= chr [1:6] \"88\" \"167\" \"193\" \"267\" ...\n\n\nTen en cuenta que se utiliza el operador pipe |&gt; y el paquete {dplyr} para seleccionar variables. Consulta más técnicas de manipulación de datos utilizando este paquete si estás interesado. Para mayor legibilidad, renombramos las variables cp, thalach y class con nombres más informativos:\n\n# renombrar variables\ndat &lt;- dat |&gt;\n  rename(\n    chest_pain = cp,\n    max_heartrate = thalach,\n    heart_disease = class\n  )\n\nPara una regresión logística binaria en R, se recomienda que todas las variables cualitativas se transformen en factores. Transformamos las variables sex y chest_pain en factor y establecemos las etiquetas correspondientes:\n\n# recodificar sexo\ndat$sex &lt;- factor(dat$sex,\n  levels = c(FALSE, TRUE),\n  labels = c(\"mujer\", \"hombre\")\n)\n\n# recodificar dolor_torácico\ndat$chest_pain &lt;- factor(dat$chest_pain,\n  levels = 1:4,\n  labels = c(\"angina típica\", \"angina atípica\", \"dolor no anginoso\", \"asintomático\")\n)\n\nLa variable dependiente en el ejemplot, heart_disease (nuestra variable dependiente) está actualmente codificada con valores discretos integers que van de 0 a 4. Por lo tanto, primero la clasificamos en 2 clases estableciendo 0 para los valores 0 y 1 para los valores distintos de 0, utilizando la función ifelse():\n\n# recodificar heart_disease en 2 clases\ndat$heart_disease &lt;- ifelse(dat$heart_disease == 0,\n  0,\n  1\n)\n\nLuego la transformamos en un factor y establecemos las etiquetas correspondientes utilizando la función factor():\n\n# establecer etiquetas para heart_disease\ndat$heart_disease &lt;- factor(dat$heart_disease,\n  levels = c(0, 1),\n  labels = c(\"sin enfermedad\", \"enfermedad\")\n)\n\nTen en cuenta el orden de los niveles de tu variable dependiente, ya que tendrá un impacto en las interpretaciones. En R, el primer nivel dado por levels() siempre se toma como el nivel de referencia. En nuestro caso, el primer nivel es la ausencia de la enfermedad y el segundo nivel es la presencia de la enfermedad:\n\nlevels(dat$heart_disease)\n\n[1] \"sin enfermedad\" \"enfermedad\"    \n\n\nEsto significa que cuando construyamos los modelos, estimaremos el impacto de la(s) variable(s) independiente(s) en la presencia de la enfermedad. Esta es la razón por la que, para variables dependientes del tipo no/sí, falso/verdadero, ausencia/presencia de una condición, etc., se recomienda establecer el nivel no, falso, ausencia de la condición, etc., como el nivel de referencia. De hecho, suele ser más fácil interpretar el impacto de una variable independiente en la presencia de una condición/enfermedad que lo contrario. Si deseas cambiar el nivel de referencia, esto se puede hacer con la función relevel(). Aquí tienes una vista previa del data frame final y algunas básicas:\n\n# imprimir las primeras 6 observaciones\nhead(dat)\n\n  age    sex        chest_pain max_heartrate  heart_disease\n1  63 hombre     angina típica           150 sin enfermedad\n2  67 hombre      asintomático           108     enfermedad\n3  67 hombre      asintomático           129     enfermedad\n4  37 hombre dolor no anginoso           187 sin enfermedad\n5  41  mujer    angina atípica           172 sin enfermedad\n6  56 hombre    angina atípica           178 sin enfermedad\n\n# estadísticas descriptivas básicas\nsummary(dat)\n\n      age            sex                  chest_pain  max_heartrate  \n Min.   :29.00   mujer : 96   angina típica    : 23   Min.   : 71.0  \n 1st Qu.:48.00   hombre:201   angina atípica   : 49   1st Qu.:133.0  \n Median :56.00                dolor no anginoso: 83   Median :153.0  \n Mean   :54.54                asintomático     :142   Mean   :149.6  \n 3rd Qu.:61.00                                        3rd Qu.:166.0  \n Max.   :77.00                                        Max.   :202.0  \n        heart_disease\n sin enfermedad:160  \n enfermedad    :137  \n                     \n                     \n                     \n                     \n\n\nEl data frame está ahora listo para ser analizado más a fondo a través de regresiones logísticas binarias univariables y multivariables.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TEMA 4: REGRESIÓN LOGISTICA</span>"
    ]
  },
  {
    "objectID": "TEMA-4.html#regresión-logística-binaria-univariable",
    "href": "TEMA-4.html#regresión-logística-binaria-univariable",
    "title": "4  TEMA 4: REGRESIÓN LOGISTICA",
    "section": "4.5 Regresión logística binaria univariable",
    "text": "4.5 Regresión logística binaria univariable\nComo se mencionó anteriormente, comenzamos con una regresión logística binaria univariable, es decir, una regresión logística binaria con una sola variable independiente. En R, se puede realizar una regresión logística binaria con la función glm() y el argumento family = \"binomial\". Al igual que en la regresión lineal, la fórmula utilizada dentro de la función debe escribirse como variable dependiente ~ variable independiente (¡en este orden!). Mientras que la variable dependiente debe ser categórica con dos niveles, la variable independiente puede ser de cualquier tipo. Sin embargo, las interpretaciones difieren dependiendo de si la variable independiente es cualitativa o cuantitativa. Para ser exhaustivos, ilustramos este tipo de regresión con una variable independiente tanto cuantitativa como cualitativa, comenzando con una variable independiente cuantitativa.\n\n4.5.1 Variable independiente cuantitativa\nSupongamos que queremos estimar el impacto de la edad de un paciente en la presencia de una enfermedad cardíaca. En este caso, edad es nuestra variable independiente y enfermedad_cardiaca es nuestra variable dependiente:\n\n# guardar modelo\nm1 &lt;- glm(heart_disease ~ age,\n  data = dat,\n  family = \"binomial\"\n)\n\nLos resultados del modelo se guardan en el objeto m1. De nuevo, al igual que en la regresión lineal, se puede acceder a los resultados gracias a la función summary():\n\n# imprimir resultados\nsummary(m1)\n\n\nCall:\nglm(formula = heart_disease ~ age, family = \"binomial\", data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.05122    0.76862  -3.970  7.2e-05 ***\nage          0.05291    0.01382   3.829 0.000128 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 409.95  on 296  degrees of freedom\nResidual deviance: 394.25  on 295  degrees of freedom\nAIC: 398.25\n\nNumber of Fisher Scoring iterations: 4\n\n\nLos resultados más importantes en esta salida se muestran en la tabla después de Coefficients. La parte inferior de la salida resume la distribución de los residuos de devianza. En resumen, los residuos de devianza miden qué tan bien se ajustan las observaciones al modelo. Cuanto más cerca esté el residuo de 0, mejor será el ajuste de la observación. Dentro de la tabla Coefficients, nos centramos en la primera y última columna (las otras dos columnas corresponden al error estándar y al estadístico de prueba, que se utilizan para calcular el valor \\(p\\)):\n\nLa columna Estimate corresponde a los coeficientes \\(\\hat{\\beta}_0\\) y \\(\\hat{\\beta}_1\\).\nLa columna Pr(&gt;|z|) corresponde a los valores \\(p\\).\n\nR realiza una prueba de hipótesis para cada coeficiente, es decir, \\(H_0: \\beta_j = 0\\) versus \\(H_1: \\beta_j \\neq 0\\) para \\(j = 0, 1\\) a través de la prueba de Wald, e imprime los valores \\(p\\) en la última columna. Por lo tanto, podemos comparar estos valores \\(p\\) con el nivel de significancia elegido (generalmente \\(\\alpha = 0.05\\)) para concluir si cada uno de los coeficientes es significativamente diferente de 0 o no. Cuanto menor sea el valor \\(p\\), mayor será la evidencia de que el coeficiente es diferente de 0. Esto es similar a la regresión lineal. Los coeficientes son un poco más difíciles de interpretar en la regresión logística que en la regresión lineal porque la relación entre las variables dependientes e independientes no es lineal. Interpretemos primero el coeficiente de la edad, \\(\\hat{\\beta}_1\\), que es el coeficiente más importante de los dos.\nPrimero, dado que el valor \\(p\\) de la prueba sobre el coeficiente para la edad es &lt; 0.05, concluimos que es significativamente diferente de 0, lo que significa que la edad está significativamente asociada con la presencia de una enfermedad cardíaca (al nivel de significancia del 5%). Ten en cuenta que si la prueba no fuera significativa (es decir, el valor \\(p \\ge \\alpha\\)), nos abstendríamos de interpretar el coeficiente, ya que significa que, basándonos en los datos disponibles, no podemos concluir que la edad esté asociada con la presencia de una enfermedad cardíaca en la población.\nSegundo, recuerda que:\n\nCuando \\(\\beta_1 = 0\\), \\(X\\) e \\(Y\\) son independientes.\nCuando \\(\\beta_1 &gt; 0\\), la probabilidad de que \\(Y = 1\\) aumenta con \\(X\\).\nCuando \\(\\beta_1 &lt; 0\\), la probabilidad de que \\(Y = 1\\) disminuye con \\(X\\).\n\nEn nuestro contexto, tenemos:\n\nCuando \\(\\hat{\\beta}_1 = 0\\), la probabilidad de desarrollar una enfermedad cardíaca es independiente de la edad.\nCuando \\(\\hat{\\beta}_1 &gt; 0\\), la probabilidad de desarrollar una enfermedad cardíaca aumenta con la edad.\nCuando \\(\\hat{\\beta}_1 &lt; 0\\), la probabilidad de desarrollar una enfermedad cardíaca disminuye con la edad.\n\nAquí tenemos \\(\\hat{\\beta}_1 =\\) 0.053 \\(&gt; 0\\), por lo que ya sabemos que cuanto mayor es el paciente, más probable es que desarrolle una enfermedad cardíaca. Esto tiene sentido.\nAhora que conocemos la dirección de la relación, nos gustaría cuantificar esta relación. Esto se hace fácilmente gracias a los odds ratios (OR). Los OR se encuentran tomando el exponencial de los coeficientes. En R, el exponencial se calcula gracias a la función exp(). La odds de un evento es la razón entre la probabilidad de que ocurra el evento y la probabilidad de que no ocurra. Por ejemplo, si la probabilidad de que un paciente desarrolle una enfermedad cardíaca es 0.8, entonces la probabilidad de que no desarrolle la enfermedad es 0.2, y los odds de desarrollar la enfermedad son \\(0.8 / 0.2 = 4\\). Esto significa que los odds a favor de desarrollar una enfermedad cardíaca son 4 a 1. Su formula es: \\[odds(éxito) = \\frac{P(éxito)}{1 - P(éxito)}.\\] La OR es la razón entre dos odds. En nuestro caso, los OR se pueden interpretar como el cambio en los odds de desarrollar una enfermedad cardíaca cuando la edad aumenta en 1 unidad (es decir, 1 año). Matemáticamente, los OR se definen como:\n\\[OR = \\frac{odds(éxito | X + 1)}{odds(éxito | X)}.\\]\nLos OR se pueden interpretar de la siguiente manera: el OR es el cambio multiplicativo en los odds a favor de \\(Y = 1\\) cuando \\(X\\) aumenta en 1 unidad. Aplicado a nuestro contexto, calculamos el OR para la edad calculando \\(\\exp(\\hat{\\beta}_1) =\\) exp(0.053).\nUsando R, esto da:\n\n# OR para la edad\nexp(coef(m1)[\"age\"])\n\n     age \n1.054331 \n\n\nPodríamos tambiém multiplicar este valor por 10 para obtener el porcentaje de aumento en los odds cuando la edad aumenta en 10 años:\n\n# OR para un aumento de 10 años en la edad\nexp(coef(m1)[\"age\"] * 10)\n\n     age \n1.697345 \n\n\nBasándonos en este resultado, podemos decir que un año extra de edad aumenta los odds (es decir, la probabilidad) de desarrollar una enfermedad cardíaca en un factor de 1.054. Por lo tanto, los odds de desarrollar una enfermedad cardíaca aumentan en (1.054 - 1) \\(\\times\\) 100 = 5.4% cuando un paciente envejece un año.\nPara resumir:\n\nCuando el coeficiente \\(\\hat{\\beta}_1 = 0 \\Rightarrow\\) OR \\(= \\exp(\\hat{\\beta}_1) = 1 \\Rightarrow P(Y = 1)\\) es independiente de \\(X \\Rightarrow\\) no hay relación entre \\(X\\) e \\(Y\\).\nCuando el coeficiente \\(\\hat{\\beta}_1 &gt; 0 \\Rightarrow\\) OR \\(= \\exp(\\hat{\\beta}_1) &gt; 1 \\Rightarrow P(Y = 1)\\) aumenta con \\(X \\Rightarrow\\) hay una relación positiva entre \\(X\\) e \\(Y\\).\nCuando el coeficiente \\(\\hat{\\beta}_1 &lt; 0 \\Rightarrow\\) OR \\(= \\exp(\\hat{\\beta}_1) &lt; 1 \\Rightarrow P(Y = 1)\\) disminuye con \\(X \\Rightarrow\\) hay una relación negativa entre \\(X\\) e \\(Y\\).\n\nAhora interpretamos el intercepto \\(\\hat{\\beta}_0\\).\nPrimero, miramos el valor \\(p\\) de la prueba sobre el intercepto. Siendo este valor \\(p\\) &lt; 0.05, concluimos que el intercepto es significativamente diferente de 0 (al nivel de significancia del 5%).\nSegundo, de manera similar a la regresión lineal, para obtener una interpretación del intercepto, necesitamos encontrar una situación en la que el otro coeficiente, \\(\\beta_1\\), se anule.\nEn nuestro caso, ocurre cuando un paciente tiene 0 años. Podemos necesitar o no interpretar los resultados en tal situación, y en muchas situaciones la interpretación no tiene sentido, por lo que es más una interpretación hipotética. Sin embargo, de nuevo para ser exhaustivos, mostramos cómo interpretar el intercepto. Ten en cuenta que también es posible centrar la variable numérica para que el intercepto tenga una interpretación más significativa. Para un paciente de 0 años, los odds de desarrollar una enfermedad cardíaca son \\(\\exp(\\hat{\\beta}_0) =\\) exp(-3.051) = 0.047. Al interpretar un intercepto, a menudo tiene más sentido interpretarlo como la probabilidad de que \\(Y = 1\\), que se puede calcular de la siguiente manera:\n\\[\\frac{\\exp(\\hat{\\beta}_0)}{1 + \\exp(\\hat{\\beta}_0)}.\\]\nEn nuestro caso, corresponde a la probabilidad de que un paciente de 0 años desarrolle una enfermedad cardíaca, que es igual a:\n\n# prob(enfermedad cardíaca) para edad = 0\nexp(coef(m1)[1]) / (1 + exp(coef(m1)[1]))\n\n(Intercept) \n 0.04516478 \n\n\nEsto significa que, si confiamos en nuestro modelo, se espera que un recién nacido desarrolle una enfermedad cardíaca con una probabilidad del 4.52%.\nSe puede calcular un intervalo de confianza para cualquiera de los OR utilizando la función confint(). Por ejemplo, un intervalo de confianza del 95% para el OR para la edad:\n\n# IC del 95% para el OR para la edad\nexp(confint(m1,\n  parm = \"age\"\n))\n\n   2.5 %   97.5 % \n1.026699 1.083987 \n\n\nRecuerda que al evaluar un OR, el valor nulo es 1, no 0. Un OR de 1 en este estudio significaría que no hay asociación entre la edad y la presencia de enfermedad cardíaca. Si el intervalo de confianza del 95% del OR no incluye el 1, concluimos que existe una asociación significativa entre la edad y la presencia de enfermedad cardíaca. Por el contrario, si incluye el 1, no rechazamos la hipótesis de que no hay asociación entre la edad y la presencia de enfermedad cardíaca.\nEn nuestro caso, el IC del 95% no incluye el 1, por lo que concluimos, al nivel de significancia del 5%, que existe una asociación significativa entre la edad y la presencia de enfermedad cardíaca.\nNotarás que es la misma conclusión que con el valor \\(p\\). Esto es normal, siempre será así:\n\nSi el valor \\(p\\) &lt; 0.05, el 1 no estará incluido en el IC del 95%.\nSi el valor \\(p \\ge\\) 0.05, el 1 estará incluido en el IC del 95%.\n\nEsto significa que puedes elegir si sacas tu conclusión sobre la asociación entre las dos variables basándote en el IC del 95% o en el valor \\(p\\).\nEstimar la relación entre variables es la razón principal para construir modelos. Otro objetivo es predecir la variable dependiente basándose en valores recién observados de la(s) variable(s) independiente(s). Esto se puede hacer con la función predict().\nSupongamos que nos gustaría predecir la probabilidad de desarrollar una enfermedad cardíaca para un paciente de 30 años:\n\n# predecir la probabilidad de desarrollar una enfermedad cardíaca\npred &lt;- predict(m1,\n  newdata = data.frame(age = c(30)),\n  type = \"response\"\n)\n\n# imprimir la predicción\npred\n\n        1 \n0.1878525 \n\n\nSe predice que un paciente de 30 años tiene un 18.79% de probabilidad de desarrollar una enfermedad cardíaca.\nTen en cuenta que si deseas construir un intervalo de confianza para esta predicción, se puede hacer añadiendo el argumento se = TRUE en la función predict():\n\n# predecir la probabilidad de desarrollar una enfermedad cardíaca\npred &lt;- predict(m1,\n  newdata = data.frame(age = c(30)),\n  type = \"response\",\n  se = TRUE\n)\n\n# imprimir la predicción\npred$fit\n\n        1 \n0.1878525 \n\n# intervalo de confianza del 95% para la predicción\nlower &lt;- pred$fit - (qnorm(0.975) * pred$se.fit)\nupper &lt;- pred$fit + (qnorm(0.975) * pred$se.fit)\nc(lower, upper)\n\n         1          1 \n0.07873357 0.29697138 \n\n\nLa función plot_model() disponible en el paquete de R {sjPlot} hace un buen trabajo al visualizar los resultados del modelo:\n\n# cargar paquete\nlibrary(sjPlot)\n\n# gráfico\nplot_model(m1,\n  type = \"pred\",\n  terms = \"age\"\n) +\n  labs(y = \"Prob(enfermedad cardíaca)\")\n\n\n\n\n\n\n\n\nEl gráfico muestra la probabilidad de desarrollar una enfermedad cardíaca en función de la edad y confirma los resultados encontrados anteriormente:\n- Vemos que la probabilidad de desarrollar una enfermedad cardíaca aumenta con la edad (lo cual era de esperar dado que el OR para el coeficiente de la edad es &gt; 1).\n- También vemos que la probabilidad de desarrollar una enfermedad cardíaca para un paciente de 30 años es ligeramente inferior al 20%.\n\n\n4.5.2 Variable independiente cualitativa\nSupongamos ahora que estamos interesados en estimar la relación entre la probabilidad de desarrollar una enfermedad cardíaca y el sexo (que es una variable cualitativa). Recuerda que cuando la variable independiente era cuantitativa, \\(\\exp(\\hat{\\beta}_1)\\) era el cambio multiplicativo en los odds a favor de \\(Y = 1\\) cuando \\(X\\) aumenta en 1 unidad. Siendo \\(X\\) el sexo, el único aumento de unidad posible es de 0 a 1 (o de 1 a 2 si el sexo se codifica como un factor), por lo que podemos escribir una interpretación en términos de mujer/hombre. De nuevo, ten en cuenta cuál es el orden de los niveles para la variable sexo. En nuestro caso, el nivel mujer viene antes que el nivel hombre:\n\n# niveles para sexo\nlevels(dat$sex)\n\n[1] \"mujer\"  \"hombre\"\n\n\nAsí que es, en efecto, el cambio multiplicativo de los odds tomando como referencia de \\(Y = 1\\) ** mujer. Si el nivel hombre viniera antes que el nivel mujer en nuestro conjunto por lo tanto \\(\\exp(\\hat{\\beta}_1)\\) es el cambio multiplicativo de los odds a favor de \\(Y = 1\\) para hombres versus mujeres**.\nEn nuestro caso, obtenemos los siguientes resultados:\n\n# guardar modelo\nm2 &lt;- glm(heart_disease ~ sex,\n  data = dat,\n  family = \"binomial\"\n)\n\n# imprimir resultados\nsummary(m2)\n\n\nCall:\nglm(formula = heart_disease ~ sex, family = \"binomial\", data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.0438     0.2326  -4.488 7.18e-06 ***\nsexhombre     1.2737     0.2725   4.674 2.95e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 409.95  on 296  degrees of freedom\nResidual deviance: 386.12  on 295  degrees of freedom\nAIC: 390.12\n\nNumber of Fisher Scoring iterations: 4\n\n# OR para sexo\nexp(coef(m2)[\"sexhombre\"])\n\nsexhombre \n 3.573933 \n\n\nque se pueden interpretar de la siguiente manera:\n\nEl valor \\(p\\) de la prueba sobre el coeficiente para el sexo es &lt; 0.05, por lo que concluimos que el sexo está significativamente asociado con la presencia de enfermedad cardíaca (al nivel de significancia del 5%).\nAdemás, al observar el coeficiente para el sexo, \\(\\hat{\\beta}_1 =\\) 1.274, podemos decir que:\n\nPara los hombres, los odds de desarrollar una enfermedad cardíaca se multiplican por un factor de exp(1.274) = 3.574 en comparación con las mujeres.\nEn otras palabras, los odds de desarrollar una enfermedad cardíaca para los hombres son 3.574 veces los odds para las mujeres.\nEsto significa que los odds de desarrollar una enfermedad cardíaca son (3.574 - 1) \\(\\times\\) 100 = 257.4% más altos para los hombres que para las mujeres.\n\nFinalmente, el OR para el sexo es 3.574, y su IC del 95% es:\n\n\n# IC del 95% para el OR para el sexo\nexp(confint(m2,\n  parm = \"sexhombre\"\n))\n\n   2.5 %   97.5 % \n2.118346 6.183549 \n\n\n  - Dado que el IC del 95% no incluye el 1, concluimos, al nivel de significancia del 5%, que existe una asociación significativa entre el sexo y la presencia de enfermedad cardíaca. Esta es la misma conclusión que con el valor $p$.\n  - Esto significa que los hombres tienen significativamente más probabilidades de desarrollar una enfermedad cardíaca que las mujeres.\n  - Si el IC del 95% hubiera incluido el 1, no habríamos rechazado la hipótesis de que no hay asociación entre el sexo y la presencia de enfermedad cardíaca.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TEMA 4: REGRESIÓN LOGISTICA</span>"
    ]
  },
  {
    "objectID": "TEMA-4.html#regresión-logística-binaria-multivariable",
    "href": "TEMA-4.html#regresión-logística-binaria-multivariable",
    "title": "4  TEMA 4: REGRESIÓN LOGISTICA",
    "section": "4.6 Regresión logística binaria multivariable",
    "text": "4.6 Regresión logística binaria multivariable\nLa interpretación de los coeficientes en la regresión logística multivariable es similar a la interpretación en la regresión univariable, excepto que esta vez estima el cambio multiplicativo en los odds a favor de \\(Y = 1\\) cuando \\(X\\) aumenta en 1 unidad, mientras que las otras variables independientes permanecen sin cambios. Esto es similar a la regresión lineal múltiple, donde un coeficiente da el cambio esperado de \\(Y\\) por un aumento de 1 unidad de \\(X\\), manteniendo constantes todas las demás variables [3].\nLas principales ventajas de utilizar una regresión logística multivariable en comparación con una regresión logística univariable son:\n\nConsiderar el efecto simultáneo (en lugar de aislado) de las variables independientes.\nTener en cuenta posibles efectos de confusión y/o interacción.\nMejorar las predicciones.\n\nPara esta ilustración, supongamos que nos gustaría estimar la relación entre la enfermedad cardíaca y todas las variables presentes en el data frame, es decir, edad, sexo, tipo de dolor torácico y frecuencia cardíaca máxima alcanzada:\n\n# guardar modelo\nm2 &lt;- glm(heart_disease ~ .,\n  data = dat,\n  family = \"binomial\"\n)\n\n# imprimir resultados\nsummary(m2)\n\n\nCall:\nglm(formula = heart_disease ~ ., family = \"binomial\", data = dat)\n\nCoefficients:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -0.060150   1.962091  -0.031 0.975544    \nage                          0.042814   0.019009   2.252 0.024302 *  \nsexhombre                    1.686330   0.349352   4.827 1.39e-06 ***\nchest_painangina atípica    -0.120481   0.641396  -0.188 0.851000    \nchest_paindolor no anginoso -0.124331   0.571093  -0.218 0.827658    \nchest_painasintomático       1.963723   0.548877   3.578 0.000347 ***\nmax_heartrate               -0.030326   0.007975  -3.802 0.000143 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 409.95  on 296  degrees of freedom\nResidual deviance: 275.26  on 290  degrees of freedom\nAIC: 289.26\n\nNumber of Fisher Scoring iterations: 5\n\n\nTen en cuenta que la fórmula heart_disease ~ . es un atajo para incluir en el modelo todas las variables presentes en el data frame como variables independientes, excepto heart_disease. Basándonos en los valores \\(p\\) que se muestran en la última columna de la tabla de coeficientes, concluimos que, a un nivel de significancia del 5%, la edad, el sexo y la frecuencia cardíaca máxima alcanzada están significativamente asociados con la enfermedad cardíaca (valores \\(p\\) &lt; 0.05).\nPara las variables age, sex y max_heartrate, solo hay un valor \\(p\\). Para la variable chest_pain, se muestran 3 valores \\(p\\). Esto es normal: al igual que en la regresión lineal cuando se incluye en el modelo una variable categórica con más de dos niveles, se realiza una prueba para cada comparación entre el nivel de referencia y los otros niveles. En nuestro caso, el nivel de referencia para la variable chest_pain es typical angina (angina típica), ya que aparece primero:\n\nlevels(dat$chest_pain)\n\n[1] \"angina típica\"     \"angina atípica\"    \"dolor no anginoso\"\n[4] \"asintomático\"     \n\n\nPor lo tanto, se realiza una prueba para la comparación entre:\n\ntypical angina y atypical angina (angina atípica),\ntypical angina y non-anginal pain (dolor no anginoso), y\ntypical angina y asymptomatic (asintomático).\n\nPero aquí no nos interesa comparar los niveles de la variable de dolor torácico, nos gustaría probar el efecto general del dolor torácico en la enfermedad cardíaca. Para ello, vamos a comparar dos modelos mediante una prueba de razón de verosimilitud (LRT):\n\nUn modelo que incluye todas las variables de interés y la variable chest_pain.\nEl mismo modelo exacto pero que excluye la variable chest_pain.\n\nEl primero se conoce como modelo completo, mientras que el segundo se conoce como modelo reducido.\nComparamos estos dos modelos con la función anova():\n\n# guardar modelo reducido\nmod_reduced &lt;- glm(heart_disease ~ age + sex + max_heartrate,\n  data = dat,\n  family = \"binomial\"\n)\n\n# comparar modelo reducido con modelo completo\nanova(mod_reduced, m2,\n  test = \"LRT\"\n)\n\nAnalysis of Deviance Table\n\nModel 1: heart_disease ~ age + sex + max_heartrate\nModel 2: heart_disease ~ age + sex + chest_pain + max_heartrate\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1       293     325.12                          \n2       290     275.26  3    49.86 8.558e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nObserva que el modelo reducido debe ir antes que el modelo completo en la función anova(). La hipótesis nula de esta prueba es que los dos modelos son equivalentes.\nA un nivel de significancia del 5% (ver el valor \\(p\\) a la derecha de la salida de R), rechazamos la hipótesis nula y concluimos que el modelo completo es significativamente mejor que el modelo reducido para explicar la presencia de enfermedad cardíaca. Esto significa que el dolor torácico está significativamente asociado con la enfermedad cardíaca (lo cual era de esperar, ya que la comparación entre typical angina y asymptomatic resultó ser significativa). Hemos identificado que las cuatro variables independientes estaban significativamente asociadas con la presencia de enfermedad cardíaca, podemos interpretar los coeficientes para conocer la dirección de las relaciones y, lo más importante, cuantificar la fuerza de estas relaciones.\nAl igual que en la regresión logística binaria univariable, es más fácil interpretar estas relaciones a través de los OR. Pero esta vez, también imprimimos el IC del 95% del OR además del OR (redondeado a 3 decimales) para que podamos ver fácilmente cuáles son significativamente diferentes de 1:\n\n# OR y IC del 95%\nround(exp(cbind(OR = coef(m2), confint(m2))), 3)\n\n                               OR 2.5 % 97.5 %\n(Intercept)                 0.942 0.020 44.353\nage                         1.044 1.006  1.084\nsexhombre                   5.400 2.776 10.971\nchest_painangina atípica    0.886 0.252  3.191\nchest_paindolor no anginoso 0.883 0.293  2.814\nchest_painasintomático      7.126 2.509 22.030\nmax_heartrate               0.970 0.955  0.985\n\n\nA partir de los OR y sus IC del 95% calculados anteriormente, concluimos que:\n\nEdad: los odds de tener una enfermedad cardíaca se multiplican por un factor de 1.04 por cada aumento de una unidad en la edad, manteniendo todo lo demás constante.\nSexo: los odds de desarrollar una enfermedad cardíaca para los hombres son 5.4 veces los odds para las mujeres, manteniendo todo lo demás constante.\nDolor torácico: los odds de desarrollar una enfermedad cardíaca para las personas que sufren de dolor torácico del tipo “asintomático” son 7.13 veces los odds para las personas que sufren de dolor torácico del tipo “angina típica”, manteniendo todo lo demás constante. Nos abstenemos de interpretar las otras comparaciones ya que no son significativas al nivel de significancia del 5% (el 1 está incluido en su IC del 95%).\nFrecuencia cardíaca máxima alcanzada: los odds de tener una enfermedad cardíaca se multiplican por un factor de 0.97 por cada aumento de una unidad en la frecuencia cardíaca máxima alcanzada, manteniendo todo lo demás constante.\nIntercepto: también nos abstenemos de interpretar el intercepto ya que no es significativamente diferente de 0 al nivel de significancia del 5% (el 1 está incluido en el IC del 95%). Recuerda que siempre podemos escribir las interpretaciones en términos del porcentaje de aumento/disminución de los odds con la fórmula \\((OR - 1) \\times 100\\), donde OR corresponde al odds ratio.\n\nPor ejemplo, para la frecuencia cardíaca máxima alcanzada, el OR = 0.97, por lo que la interpretación se convierte en: los odds de desarrollar una enfermedad cardíaca aumentan en (0.97 \\(- 1) \\times 100 =\\) -3% por cada aumento de una unidad en la frecuencia cardíaca máxima alcanzada, lo que equivale a decir que los odds de desarrollar una enfermedad cardíaca disminuyen en 3% por cada aumento de una unidad en la frecuencia cardíaca máxima alcanzada.\nCon fines ilustrativos, supongamos ahora que nos gustaría predecir la probabilidad de que un nuevo paciente desarrolle una enfermedad cardíaca. Supongamos que esta paciente es una mujer de 32 años, que sufre de dolor torácico del tipo no anginoso y alcanzó una frecuencia cardíaca máxima de 150. La probabilidad de que desarrolle una enfermedad cardíaca es:\n\n# crear data frame del nuevo paciente\nnew_patient &lt;- data.frame(\n  age = 32,\n  sex = \"mujer\",\n  chest_pain = \"dolor no anginoso\",\n  max_heartrate = 150\n)\n\n# predecir la probabilidad de desarrollar una enfermedad cardíaca e Intervalo de confianza del 95%\npred &lt;- predict(m2,\n  newdata = new_patient,\n  type = \"response\",\n  se.fit = TRUE\n)\n# Imprimir la predicción e intervalo\nlower &lt;- pred$fit - (qnorm(0.975) * pred$se.fit)\nupper &lt;- pred$fit + (qnorm(0.975) * pred$se.fit)\nc(pred$fit, lower, upper)\n\n           1            1            1 \n 0.033459485 -0.007961903  0.074880872 \n\n\nSi confiamos en nuestro modelo, se predice que la probabilidad de que esta nueva paciente desarrolle una enfermedad cardíaca es del 3.35%. También podemos visualizar los resultados gracias a la función plot_model(), tres efectos al mismo tiempo:\n\nEfecto de la edad, el sexo y el tipo de dolor torácico en la probabilidad predicha de desarrollar una enfermedad cardíaca.\nEfecto de la frecuencia cardíaca máxima alcanzada, el sexo y el tipo de dolor torácico en la probabilidad predicha de desarrollar una enfermedad cardíaca.\n\n\n# 1. edad, sexo y dolor torácico sobre la prob. de enfermedad\nplot_model(m2,\n  type = \"pred\",\n  terms = c(\"age\", \"chest_pain\", \"sex\"),\n  ci.lvl = NA # eliminar bandas de confianza\n) +\n  labs(y = \"Prob(enfermedad cardíaca)\")\n\n\n\n\n\n\n\n# 2. frec. cardíaca máx., dolor torácico y sexo sobre la prob. de enfermedad\nplot_model(m2,\n  type = \"pred\",\n  terms = c(\"max_heartrate\", \"chest_pain\", \"sex\"),\n  ci.lvl = NA # eliminar bandas de confianza\n) +\n  labs(y = \"Prob(enfermedad cardíaca)\")\n\n\n\n\n\n\n\n\nPara mayor claridad en los gráficos, las bandas de confianza se eliminan gracias a ci.lvl = NA.\nEstos gráficos confirman los resultados obtenidos anteriormente, es decir:\n\nHay una relación positiva entre la edad y la presencia de enfermedad cardíaca.\nHay una relación negativa entre la frecuencia cardíaca máxima alcanzada y la presencia de enfermedad cardíaca.\nLos odds de desarrollar una enfermedad cardíaca son mayores para los pacientes que sufren de dolor torácico de tipo asintomático y similares para los otros 3 tipos de dolor torácico.\nLos odds de desarrollar una enfermedad cardíaca son mayores para los hombres que para las mujeres.\n\n\n4.6.1 Interacción\nEn las secciones anteriores, se omitieron los posibles efectos de interacción. Una interacción ocurre cuando la relación entre una variable independiente y la variable de resultado depende del valor o nivel que toma otra variable independiente. Por el contrario, si la relación entre una variable independiente y la variable dependiente permanece sin cambios sin importar el valor que tome otra variable independiente, no podemos concluir que haya un efecto de interacción. En nuestro caso, habría una interacción si, por ejemplo, la relación entre la edad y la enfermedad cardíaca dependiera del sexo. Habría una interacción, por ejemplo, si la relación entre la edad y la enfermedad cardíaca fuera positiva para las mujeres y negativa para los hombres, o viceversa. O si la relación entre la edad y la enfermedad cardíaca fuera mucho más fuerte o mucho más débil para las mujeres que para los hombres.\nVeamos si hay una interacción entre la edad y el sexo y, lo que es más importante, si esta interacción es significativa o no. Para ello, necesitamos construir dos modelos:\n\nUn modelo que contenga solo los efectos principales, es decir, sin la interacción.\nUn modelo que contenga los efectos principales y la interacción.\n\n\n# guardar modelo sin interacción\nm3 &lt;- glm(heart_disease ~ age + sex,\n  data = dat,\n  family = \"binomial\"\n)\n\n# guardar modelo con interacción\nm3_inter &lt;- glm(heart_disease ~ age * sex,\n  data = dat,\n  family = \"binomial\"\n)\nsummary(m3_inter)\n\n\nCall:\nglm(formula = heart_disease ~ age * sex, family = \"binomial\", \n    data = dat)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   -4.21323    1.61745  -2.605  0.00919 **\nage            0.05570    0.02758   2.019  0.04346 * \nsexhombre      0.64180    1.88470   0.341  0.73346   \nage:sexhombre  0.01506    0.03286   0.458  0.64666   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 409.95  on 296  degrees of freedom\nResidual deviance: 364.23  on 293  degrees of freedom\nAIC: 372.23\n\nNumber of Fisher Scoring iterations: 4\n\n\nPrimero evaluamos la interacción visualmente a través de la función plot_model():\n\n# gráfico\nplot_model(m3_inter,\n  type = \"pred\",\n  terms = c(\"age\", \"sex\"),\n  ci.lvl = NA # eliminar bandas de confianza\n) +\n  labs(y = \"Prob(enfermedad cardíaca)\")\n\n\n\n\n\n\n\n\nDado que las dos curvas de las probabilidades predichas son relativamente similares y siguen el mismo patrón, la relación entre la edad y la presencia de enfermedad cardíaca no parece depender del sexo, lo que indica que, de hecho, puede que no haya interacción. Sin embargo, nos gustaría probarlo de manera más formal a través de una prueba estadística.\nPara ello, podemos comparar los dos modelos (el que no tiene interacción frente al que sí la tiene) con una prueba de razón de verosimilitud (LRT), utilizando la función anova():\n\nanova(m3, m3_inter,\n  test = \"LRT\"\n)\n\nAnalysis of Deviance Table\n\nModel 1: heart_disease ~ age + sex\nModel 2: heart_disease ~ age * sex\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1       294     364.43                     \n2       293     364.23  1  0.20741   0.6488\n\n\nRecuerda que siempre es el modelo reducido como primer argumento en la función anova(), y luego el modelo más complejo como segundo argumento.\nLa prueba confirma lo que supusimos basándonos en el gráfico: a un nivel de significancia del 5%, no rechazamos la hipótesis nula de que los dos modelos son equivalentes. Dado que la única diferencia entre los dos modelos es que se añade un término de interacción en el modelo completo, no rechazamos la hipótesis de que no hay interacción entre la edad y el sexo (valor \\(p\\) = 0.649).\nEsta conclusión también podría haberse obtenido de manera más simple con la función drop1():\n\ndrop1(m3_inter,\n  test = \"LRT\"\n)\n\nSingle term deletions\n\nModel:\nheart_disease ~ age * sex\n        Df Deviance    AIC     LRT Pr(&gt;Chi)\n&lt;none&gt;       364.23 372.23                 \nage:sex  1   364.43 370.43 0.20741   0.6488\n\n\nComo puedes ver, esto da el mismo valor \\(p\\) de 0.649.\nEn la práctica, una interacción no significativa se elimina del modelo antes de interpretar sus resultados. En nuestro caso, solo permanecerían en el modelo los efectos principales de la edad y el sexo. Esto nos lleva a la selección de modelos, o qué variables deben incluirse en nuestro modelo final. Esto se discute en la siguiente sección.\n\n\n4.6.2 Selección de modelos\nEn la práctica, a menudo tenemos varios modelos, que corresponden a las diferentes combinaciones de variables independientes y sus interacciones. Encontrar el mejor modelo no es fácil. En general, la mejor práctica es obtener un modelo final que sea lo más parsimonioso posible, es decir, con la menor cantidad de parámetros posible. Un modelo parsimonioso es más fácil de interpretar y generalizar, y también más potente desde un punto de vista estadístico. Por otro lado, no debe ser demasiado simple para que siga capturando las variaciones o patrones en los datos. En general, aunque más variables suelen ser mejores que una, demasiadas suelen ser peor que unas pocas.\nLos dos enfoques más comunes para obtener un modelo final son los siguientes:\n\nAjustar el modelo eliminando los efectos principales y sus interacciones que no son significativos con respecto a sus valores \\(p\\), obtenidos al probar la nulidad de los coeficientes correspondientes mediante una prueba estadística como la prueba de razón de verosimilitud o la prueba de Wald. Si hay varios efectos principales o interacciones que no son significativos, las interacciones deben eliminarse antes de eliminar cualquier efecto principal. Además, se recomienda eliminar las interacciones y las variables independientes una por una (comenzando por la que tiene el valor \\(p\\) más alto), ya que eliminar una variable o una interacción puede hacer que otra variable o interacción que inicialmente no era significativa se vuelva significativa.\nAjustar el modelo utilizando el AIC (Criterio de Información de Akaike) o el BIC (Criterio de Información Bayesiano). Estos procedimientos permiten seleccionar el mejor modelo (según el AIC o el BIC) encontrando un equilibrio entre simplicidad y complejidad. Estos procesos de selección suelen conducir a un modelo final con la menor cantidad de parámetros posible, pero que captura la mayor cantidad de información posible de los datos. Ten en cuenta que solo se pueden comparar modelos con la misma variable dependiente utilizando AIC o BIC. Los modelos con diferentes variables dependientes no se pueden comparar utilizando estos criterios.\n\nEl primer método requiere que:\n\nLos supuestos subyacentes sean válidos.\nEl tamaño de la muestra sea suficientemente grande.\nLos modelos estén anidados (es decir, el modelo completo incluye al menos todas las variables incluidas en el modelo reducido).\n\nAdemás, el segundo método se puede utilizar con criterios ampliamente aceptados al seleccionar variables y, lo que es más importante, de una manera completamente autónoma en R.\nPor esta razón, el segundo método es recomendado y más utilizado en la práctica.\nEste segundo método, conocido como selección por pasos (stepwise), se divide en 3 tipos:\n\nSelección hacia atrás (backward selection): partimos del modelo más completo (que contiene todas las variables independientes y, por lo general, también sus interacciones), y las interacciones/efectos principales se eliminan en cada paso hasta que el modelo no se puede mejorar.\nSelección hacia adelante (forward selection): partimos del modelo más básico que contiene solo el intercepto, y las variables independientes/interacciones se agregan en cada paso hasta que el modelo no se puede mejorar.\nSelección mixta (mixed selection): aplicamos tanto la selección hacia atrás como la selección hacia adelante para determinar el mejor modelo según el criterio deseado.\n\nMostramos cómo seleccionar el mejor modelo según el AIC utilizando la selección mixta por pasos, ilustrada con todas las variables presentes en el data frame como variables independientes y todas las posibles interacciones de segundo orden:\n\n# guardar modelo inicial\nm4 &lt;- glm(heart_disease ~ (age + sex + chest_pain + max_heartrate)^2,\n  data = dat,\n  family = \"binomial\"\n)\n\n# seleccionar el mejor modelo según AIC usando selección mixta\nm4_final &lt;- step(m4,\n  direction = \"both\", # both = selección mixta\n  trace = FALSE # no mostrar los pasos intermedios\n)\n\n# mostrar resultados del modelo final\nsummary(m4_final)\n\n\nCall:\nglm(formula = heart_disease ~ age + sex + chest_pain + max_heartrate + \n    age:max_heartrate, family = \"binomial\", data = dat)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 19.4386591  8.1904201   2.373 0.017628 *  \nage                         -0.3050017  0.1414986  -2.156 0.031122 *  \nsexhombre                    1.7055353  0.3507149   4.863 1.16e-06 ***\nchest_painangina atípica    -0.0086463  0.6547573  -0.013 0.989464    \nchest_paindolor no anginoso -0.0590333  0.5844000  -0.101 0.919538    \nchest_painasintomático       1.9724490  0.5649516   3.491 0.000481 ***\nmax_heartrate               -0.1605658  0.0540933  -2.968 0.002994 ** \nage:max_heartrate            0.0023314  0.0009433   2.471 0.013457 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 409.95  on 296  degrees of freedom\nResidual deviance: 268.60  on 289  degrees of freedom\nAIC: 284.6\n\nNumber of Fisher Scoring iterations: 5\n\n\nSegún el AIC (que es el criterio predeterminado al usar la función step()), el mejor modelo es el que incluye:\n\nage (edad),\nsex (sexo),\nchest_pain (dolor torácico),\nmax_heartrate (frecuencia cardíaca máxima), y\nla interacción entre age y max_heartrate.\n\nPara tu información, también puedes comparar modelos manualmente de forma sencilla utilizando el AIC o el pseudo-\\(R^2\\) con la función tab_model(), también disponible en el paquete de R {sjPlot}:\n\ntab_model(m2, m3_inter, m4_final,\n  show.ci = FALSE, # eliminar IC\n  show.aic = TRUE, # mostrar AIC\n  p.style = \"numeric_stars\" # mostrar valores p y estrellas\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nheart disease\nheart disease\nheart disease\n\n\nPredictors\nOdds Ratios\np\nOdds Ratios\np\nOdds Ratios\np\n\n\n(Intercept)\n0.94 \n0.976\n0.01 **\n0.009\n276759408.51 *\n0.018\n\n\nage\n1.04 *\n0.024\n1.06 *\n0.043\n0.74 *\n0.031\n\n\nsex [hombre]\n5.40 ***\n&lt;0.001\n1.90 \n0.733\n5.50 ***\n&lt;0.001\n\n\nchest pain [angina\natípica]\n0.89 \n0.851\n\n\n0.99 \n0.989\n\n\nchest pain [dolor no\nanginoso]\n0.88 \n0.828\n\n\n0.94 \n0.920\n\n\nchest pain [asintomático]\n7.13 ***\n&lt;0.001\n\n\n7.19 ***\n&lt;0.001\n\n\nmax heartrate\n0.97 ***\n&lt;0.001\n\n\n0.85 **\n0.003\n\n\nage × sex [hombre]\n\n\n1.02 \n0.647\n\n\n\n\nage × max heartrate\n\n\n\n\n1.00 *\n0.013\n\n\nObservations\n297\n297\n297\n\n\nR2 Tjur\n0.393\n0.144\n0.409\n\n\nAIC\n289.263\n372.227\n284.599\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\nEl pseudo-\\(R^2\\) es una generalización del coeficiente de determinación \\(R^2\\) que se usa a menudo en la regresión lineal para juzgar la calidad de un modelo. Al igual que el \\(R^2\\) en la regresión lineal, el pseudo-\\(R^2\\) varía de 0 a 1 y puede interpretarse como el porcentaje de la devianza nula explicado por la(s) variable(s) independiente(s). Cuanto mayor sea el pseudo-\\(R^2\\) y menor el AIC, mejor será el modelo.\nTen en cuenta que existen varios pseudo-\\(R^2\\), como:\n\nRazón de verosimilitud \\(R^2\\_{L}\\),\nCox y Snell \\(R^2\\_{CS}\\),\nNagelkerke \\(R^2\\_{N}\\),\nMcFadden \\(R^2\\_{McF}\\), y\nTjur \\(R^2\\_{T}\\).\n\nLa función tab_model() proporciona el Tjur \\(R^2\\_{T}\\) por defecto.\nBasándonos en el AIC y el Tjur \\(R^2\\_{T}\\), el último modelo se considera el mejor entre los 3 considerados.\nTen en cuenta que, aunque un modelo se considere el mejor entre los que has considerado (basado en uno o varios criterios), no significa necesariamente que se ajuste bien a los datos. Existen varios métodos para verificar la calidad de un modelo y comprobar si es apropiado para los datos disponibles. Este es el tema de la siguiente sección.\n\n\n4.6.3 Calidad de un modelo\nPor lo general, el objetivo de construir un modelo es poder predecir, con la mayor precisión posible, la variable de respuesta para nuevos datos. En las siguientes secciones, presentamos algunas medidas para juzgar la calidad de un modelo, comenzando por la más fácil e intuitiva, seguida de dos ampliamente utilizadas en el ámbito médico, y finalmente otras dos métricas comunes en el campo del aprendizaje automático.\n\n4.6.3.1 Precisión (Accuracy)\nUna buena forma de juzgar la precisión de un modelo es monitorear su rendimiento con nuevos datos y contar con qué frecuencia predice el resultado correcto. Desafortunadamente, cuando tenemos acceso a nuevos datos, a menudo no conocemos el resultado real y, por lo tanto, no podemos verificar si el modelo hace un buen trabajo al predecir el resultado. El truco es:\n\nEntrenar el modelo con el data frame inicial.\nProbar el modelo con los mismos datos exactos (como si fuera un data frame completamente diferente para el cual no conocemos el resultado).\nComparar las predicciones hechas por el modelo con los resultados reales.\n\nPara ilustrar este proceso, tomamos el modelo construido en la sección anterior y lo probamos en el data frame inicial. Además, supongamos que si la probabilidad de que el paciente desarrolle una enfermedad cardíaca es inferior al 50%, consideramos que el resultado predicho es la ausencia de la enfermedad; de lo contrario, el resultado predicho es la presencia de la enfermedad.\n\n# crear un vector de probabilidades predichas\npreds &lt;- predict(m4_final,\n  newdata = select(dat, -heart_disease), # eliminar resultados reales\n  type = \"response\"\n)\n\n# si la probabilidad &lt; umbral, se considera que el paciente no tiene la enfermedad\npreds_outcome &lt;- ifelse(preds &lt; 0.5,\n  0,\n  1\n)\n\n# transformar predicciones en factor y establecer etiquetas\npreds_outcome &lt;- factor(preds_outcome,\n  levels = c(0, 1),\n  labels = c(\"sin enfermedad\", \"enfermedad\")\n)\n\n# comparar resultado observado vs. predicho\ntab &lt;- table(dat$heart_disease, preds_outcome,\n  dnn = c(\"observado\", \"predicho\")\n)\n\n# imprimir resultados\ntab\n\n                predicho\nobservado        sin enfermedad enfermedad\n  sin enfermedad            132         28\n  enfermedad                 33        104\n\n\nDe la tabla de contingencia de los resultados predichos y observados, vemos que el modelo:\n\nPredijo correctamente la ausencia de la enfermedad para 132 pacientes.\nPredijo incorrectamente la presencia de la enfermedad para 28 pacientes.\nPredijo incorrectamente la ausencia de la enfermedad para 33 pacientes.\nPredijo correctamente la presencia de la enfermedad para 104 pacientes.\n\nEl porcentaje de predicciones correctas, conocido como precisión (accuracy), es la suma de las predicciones correctas dividida por el número total de predicciones:\n\naccuracy &lt;- sum(diag(tab)) / sum(tab)\naccuracy\n\n[1] 0.7946128\n\n\nEste modelo tiene una precisión del 79.5%.\nAunque la precisión es la forma más intuitiva y fácil de medir el rendimiento predictivo de un modelo, tiene algunas desventajas, especialmente porque tenemos que elegir un umbral arbitrario más allá del cual clasificamos una nueva observación como 1 o 0. Se puede encontrar una discusión más detallada sobre esto en el blog de Frank Harrell.\nEn esta ilustración, elegimos el 50% como el umbral a partir del cual se consideraba que un paciente tenía la enfermedad. Sin embargo, ¡podríamos haber elegido otro umbral y los resultados habrían sido diferentes!\n\n\n4.6.3.2 Sensibilidad y especificidad\nSi trabajas en el campo de la medicina, o si tu investigación está relacionada con las ciencias médicas, probablemente ya hayas oído hablar de sensibilidad y especificidad.\nLa sensibilidad de un clasificador, también conocida como recall, mide la capacidad de un clasificador para detectar la condición cuando la condición está presente. En nuestro caso, es el porcentaje de personas enfermas que son correctamente identificadas como tales. Formalmente, tenemos:\n\\[ \\text{Sensibilidad} = \\frac{\\text{Verdaderos positivos}}{\\text{Verdaderos positivos} + \\text{Falsos negativos}},\\]\ndonde los verdaderos positivos son personas correctamente diagnosticadas como enfermas y los falsos negativos son personas incorrectamente diagnosticadas como sanas.\nLa especificidad de un clasificador mide la capacidad de un clasificador para excluir correctamente la condición cuando la condición está ausente. En nuestro caso, es el porcentaje de personas sanas que son correctamente identificadas como no enfermas. Formalmente, tenemos:\n\\[\\text{Especificidad} = \\frac{\\text{Verdaderos negativos}}{\\text{Verdaderos negativos} + \\text{Falsos positivos}},\\]\ndonde los verdaderos negativos son personas correctamente diagnosticadas como sanas y los falsos positivos son personas incorrectamente diagnosticadas como enfermas.\nEn R, la sensibilidad y la especificidad se pueden calcular de la siguiente manera:\n\n# sensibilidad\nsensitivity &lt;- tab[2, 2] / (tab[2, 2] + tab[2, 1])\nsensitivity\n\n[1] 0.7591241\n\n# especificidad\nspecificity &lt;- tab[1, 1] / (tab[1, 1] + tab[1, 2])\nspecificity\n\n[1] 0.825\n\n\nCon nuestro modelo, obtenemos:\n\nSensibilidad = 75.9%, y\nEspecificidad = 82.5%.\n\nCuanto más cerca estén la sensibilidad y la especificidad del 100%, mejor será el modelo. El test de Hosmer y Lemeshow, es otra forma común de evaluar la calidad de un modelo. Este test se basa en la comparación entre los resultados observados y los resultados predichos por el modelo. La hipótesis nula de este test es que no hay diferencia entre los resultados observados y los predichos. A un nivel de significancia del 5%, si el valor \\(p\\) es menor que 0.05, rechazamos la hipótesis nula y concluimos que el modelo no se ajusta bien a los datos [4]. Por otro lado, si el valor \\(p\\) es mayor que 0.05, no rechazamos la hipótesis nula y concluimos que el modelo se ajusta bien a los datos. En R, este test se puede realizar fácilmente con la función logitgof() del paquete {generalhoslem}.\n\n# cargar paquete\n# install.packages(\"generalhoslem\")\nlibrary(generalhoslem)\n# realizar test de Hosmer y Lemeshow\nlogitgof(dat$heart_disease, fitted(m4_final))\n\n\n    Hosmer and Lemeshow test (binary model)\n\ndata:  dat$heart_disease, fitted(m4_final)\nX-squared = 6.7718, df = 8, p-value = 0.5614\n\n\nEl valor \\(p\\) es 0.561. A un nivel de significancia del 5%, no rechazamos la hipótesis nula y concluimos que el modelo se ajusta bien a los datos.\n\n\n\n4.6.4 Curva ROC y AUC después de un modelo de regresión logística\nYa hemos visto que cuanto mejor es la calidad del modelo, mejores son las predicciones.\nOtra forma común y menos arbitraria de juzgar la calidad de un modelo es calculando el AUC (Área Bajo la Curva) y trazando la curva ROC (Receiver Operating Characteristic).\nEsto se puede lograr fácilmente gracias al paquete {pROC}:\n\n# cargar paquete\nlibrary(pROC)\n\n# guardar objeto roc\nres &lt;- roc(heart_disease ~ fitted(m4_final),\n  data = dat\n)\n\n# trazar curva ROC\nggroc(res, legacy.axes = TRUE)\n\n\n\n\n\n\n\n# imprimir AUC\nres$auc\n\nArea under the curve: 0.87\n\n\nComo la función ggroc() funciona con capas del paquete {ggplot2}, podemos imprimir el AUC directamente en el título del gráfico de la curva ROC:\n\n# trazar curva ROC con AUC e intervalo de confianza en el título del gráfico\nggroc(res, legacy.axes = TRUE) +\n  labs(title = paste0(\"AUC = \", round(res$auc, 2))) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEstas dos métricas de calidad se pueden interpretar de la siguiente manera:\n\nEn el gráfico, cuanto más cerca esté la curva ROC de la esquina superior izquierda, mejor será el modelo.\nCuanto más cerca esté el AUC de 1, mejor será el modelo.\n\nBasándonos en la curva ROC y el AUC, podemos decir que este modelo es de bueno a muy bueno. Esto significa que el modelo es apropiado para estos datos y que puede ser útil para predecir si un paciente desarrollará o no una enfermedad cardíaca. El intervalo de confianza para la AUC se puede calcular de la siguiente manera:\n\n# IC del 95% para AUC\nci.auc(res)\n\n95% CI: 0.8299-0.9101 (DeLong)\n\n\nEl IC del 95% para la AUC no incluye el valor 0.5, lo que indica que el modelo es significativamente mejor que un modelo aleatorio al nivel de significancia del 5%. Y este se puede graficar de la siguiente manera:\n\n# trazar curva ROC con AUC e intervalo de confianza en el título del gráfico\nggroc(res, legacy.axes = TRUE) +\n  labs(title = paste0(\"AUC = \", round(res$auc, 2), \" (IC 95%: \", round(ci.auc(res)[1], 2), \"-\", round(ci.auc(res)[3], 2), \")\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n4.6.5 Reporte de resultados\nComo hemos visto antes, los odds ratios son útiles al reportar los resultados de las regresiones logísticas binarias. Calcular estos odds ratios junto con sus intervalos de confianza no es particularmente difícil. Sin embargo, presentarlos en una tabla para una publicación o un informe puede convertirse rápidamente en una tarea que consume mucho tiempo, en particular si tienes muchos modelos y muchas variables independientes. Afortunadamente, hay dos paquetes que ahorran mucho tiempo y que recomendamos utilizar para reportar los resultados de una regresión logística [5].\nEl primer paquete, llamado {gtsummary}, es útil para reportar los resultados de una regresión a la vez. El segundo es el paquete {finalfit}. Este paquete es más apropiado si necesitas reportar los resultados de varias regresiones a la vez. Aquí tienes un ejemplo con uno de los modelos construidos anteriormente:\n\n# cargar paquete\n# install.packages(\"gtsummary\")\nlibrary(gtsummary)\n\n# imprimir tabla de resultados\ntbl_regression(m4_final, exponentiate = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nage\n0.74\n0.55, 0.96\n0.031\n\n\nsex\n\n\n\n\n\n\n\n\n    mujer\n—\n—\n\n\n\n\n    hombre\n5.50\n2.82, 11.2\n&lt;0.001\n\n\nchest_pain\n\n\n\n\n\n\n\n\n    angina típica\n—\n—\n\n\n\n\n    angina atípica\n0.99\n0.27, 3.65\n&gt;0.9\n\n\n    dolor no anginoso\n0.94\n0.30, 3.07\n&gt;0.9\n\n\n    asintomático\n7.19\n2.44, 22.8\n&lt;0.001\n\n\nmax_heartrate\n0.85\n0.76, 0.94\n0.003\n\n\nage * max_heartrate\n1.00\n1.00, 1.00\n0.013\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\nLo que me gusta de este paquete es su facilidad de uso y el hecho de que todos los resultados están bien formateados en una tabla. Es un muy buen punto de partida cuando necesito crear una tabla para una publicación o un informe, para una regresión a la vez. El paquete {finalfit} permite reportar los odds ratios, sus intervalos de confianza y los valores \\(p\\) de una manera muy eficiente. Además, es bastante fácil hacerlo para muchas regresiones al mismo tiempo.\nPermíteme presentar el paquete reportando los resultados de:\n\nTodas las regresiones logísticas binarias univariables que son posibles con las variables disponibles en el data frame.\nUna regresión logística binaria multivariable que incluye todas las variables disponibles en el data frame.\nUna regresión logística binaria multivariable que incluye solo algunas de las variables presentes en el data frame.\n\nComenzamos con todas las posibles regresiones logísticas binarias univariables:\n\n# cargar paquetes\n# install.packages(\"finalfit\")\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(finalfit)\n# establecer variables dependientes e independientes\ndependent &lt;- \"heart_disease\"\nindependent &lt;- c(\"age\", \"sex\", \"chest_pain\", \"max_heartrate\")\n# guardar resultados de las regresiones logísticas univariables\nglmuni &lt;- dat |&gt;\n  glmuni(dependent, independent) |&gt;\n  fit2df(\n    explanatory_name = \"Variables\",\n    estimate_name = \"OR Crudo\",\n    estimate_suffix = \" (IC 95%)\"\n  )\n# imprimir resultados\nglmuni |&gt;\n  gt()\n\n\n\n\n\n\n\nVariables\nOR Crudo (IC 95%)\n\n\n\n\nage\n1.05 (1.03-1.08, p&lt;0.001)\n\n\nsexhombre\n3.57 (2.12-6.18, p&lt;0.001)\n\n\nchest_painangina atípica\n0.51 (0.16-1.66, p=0.255)\n\n\nchest_paindolor no anginoso\n0.63 (0.23-1.86, p=0.384)\n\n\nchest_painasintomático\n6.04 (2.39-16.76, p&lt;0.001)\n\n\nmax_heartrate\n0.96 (0.94-0.97, p&lt;0.001)\n\n\n\n\n\n\n\nAlgunas observaciones sobre este código: - Se usa glmuni() porque queremos ejecutar GLM univariables. - Se usa explanatory_name = \"Variables\" para renombrar la primera columna (por defecto es “explanatory”). - Se usa estimate_name = \"OR Crudo\" para renombrar la segunda columna e informar al lector que estamos en el caso univariable. En el caso univariable, los OR a menudo se denominan OR crudos porque no están ajustados por los efectos de las otras variables independientes. - Se usa estimate_suffix = \" (IC 95%)\" para especificar que son los intervalos de confianza del 95% los que están dentro de los paréntesis. - La capa gt() al final del código no es obligatoria. Es solo para que la salida aparezca en una tabla bonita en lugar del formato habitual de las salidas de R. Consulta más información sobre el paquete {gt} en su documentación.\nA continuación, cómo reportar los resultados de una regresión logística binaria multivariable que incluye todas las variables:\n\n# guardar resultados del modelo completo\nglmmulti_full &lt;- dat |&gt;\n  glmmulti(dependent, independent) |&gt;\n  fit2df(\n    explanatory_name = \"Variables\",\n    estimate_name = \"OR Ajustado - modelo completo\",\n  )\n# imprimir resultados\nglmmulti_full |&gt;\n  gt()\n\n\n\n\n\n\n\nVariables\nOR Ajustado - modelo completo\n\n\n\n\nage\n1.04 (1.01-1.08, p=0.024)\n\n\nsexhombre\n5.40 (2.78-10.97, p&lt;0.001)\n\n\nchest_painangina atípica\n0.89 (0.25-3.19, p=0.851)\n\n\nchest_paindolor no anginoso\n0.88 (0.29-2.81, p=0.828)\n\n\nchest_painasintomático\n7.13 (2.51-22.03, p&lt;0.001)\n\n\nmax_heartrate\n0.97 (0.95-0.99, p&lt;0.001)\n\n\n\n\n\n\n\nAlgunas observaciones sobre este código: - Se usa glmmulti() porque queremos ejecutar GLM multivariables. - Se usa estimate_name = \"OR Ajustado - modelo completo\" para recordar al lector que estamos en el caso multivariable con todas las variables incluidas. En el caso multivariable, los OR a menudo se denominan OR ajustados porque están ajustados por los efectos de las otras variables independientes.\nA continuación, cómo reportar los resultados de una regresión logística binaria multivariable que incluye solo una selección de variables:\n\n# seleccionar las variables a incluir en el modelo final\nindependent_final &lt;- c(\"age\", \"sex\", \"chest_pain\")\n\n# guardar resultados del modelo final\nglmmulti_final &lt;- dat |&gt;\n  glmmulti(dependent, independent_final) |&gt;\n  fit2df(\n    explanatory_name = \"Variables\",\n    estimate_name = \"OR Ajustado - modelo final\",\n    estimate_suffix = \" (IC 95%)\"\n  )\n\n# imprimir resultados\nglmmulti_final |&gt;\n  gt()\n\n\n\n\n\n\n\nVariables\nOR Ajustado - modelo final (IC 95%)\n\n\n\n\nage\n1.07 (1.03-1.11, p&lt;0.001)\n\n\nsexhombre\n5.52 (2.88-11.07, p&lt;0.001)\n\n\nchest_painangina atípica\n0.82 (0.24-2.82, p=0.743)\n\n\nchest_paindolor no anginoso\n0.93 (0.32-2.90, p=0.903)\n\n\nchest_painasintomático\n9.48 (3.47-28.53, p&lt;0.001)\n\n\n\n\n\n\n\nTen en cuenta que tienes que seleccionar manualmente las variables (el paquete no elegirá por ti, desafortunadamente). La selección podría hacerse previamente gracias a un procedimiento por pasos, por ejemplo. Ahora la parte más interesante de este paquete:\n\n¡Podemos combinar todos estos resultados juntos!\n¡Además de algunas estadísticas descriptivas para cada nivel de la variable dependiente!\n\nAquí están todos los resultados combinados y mostrados en una tabla:\n\n# guardar estadísticas descriptivas\nsummary &lt;- dat |&gt;\n  summary_factorlist(dependent, independent, fit_id = TRUE)\n\n# guardar resultados de las regresiones\noutput &lt;- summary |&gt;\n  finalfit_merge(glmuni) |&gt;\n  finalfit_merge(glmmulti_full) |&gt;\n  finalfit_merge(glmmulti_final)\n\n# imprimir todos los resultados\noutput |&gt;\n  dplyr::select(-fit_id, -index) |&gt;\n  dplyr::rename(\n    Variables = label,\n    \" \" = levels\n  ) |&gt;\n  gt()\n\n\n\n\n\n\n\nVariables\n\nsin enfermedad\nenfermedad\nOR Crudo (IC 95%)\nOR Ajustado - modelo completo\nOR Ajustado - modelo final (IC 95%)\n\n\n\n\nage\nMean (SD)\n52.6 (9.6)\n56.8 (7.9)\n1.05 (1.03-1.08, p&lt;0.001)\n1.04 (1.01-1.08, p=0.024)\n1.07 (1.03-1.11, p&lt;0.001)\n\n\nsex\nmujer\n71 (44.4)\n25 (18.2)\n-\n-\n-\n\n\n\nhombre\n89 (55.6)\n112 (81.8)\n3.57 (2.12-6.18, p&lt;0.001)\n5.40 (2.78-10.97, p&lt;0.001)\n5.52 (2.88-11.07, p&lt;0.001)\n\n\nchest_pain\nangina típica\n16 (10.0)\n7 (5.1)\n-\n-\n-\n\n\n\nangina atípica\n40 (25.0)\n9 (6.6)\n0.51 (0.16-1.66, p=0.255)\n0.89 (0.25-3.19, p=0.851)\n0.82 (0.24-2.82, p=0.743)\n\n\n\ndolor no anginoso\n65 (40.6)\n18 (13.1)\n0.63 (0.23-1.86, p=0.384)\n0.88 (0.29-2.81, p=0.828)\n0.93 (0.32-2.90, p=0.903)\n\n\n\nasintomático\n39 (24.4)\n103 (75.2)\n6.04 (2.39-16.76, p&lt;0.001)\n7.13 (2.51-22.03, p&lt;0.001)\n9.48 (3.47-28.53, p&lt;0.001)\n\n\nmax_heartrate\nMean (SD)\n158.6 (19.0)\n139.1 (22.7)\n0.96 (0.94-0.97, p&lt;0.001)\n0.97 (0.95-0.99, p&lt;0.001)\n-\n\n\n\n\n\n\n\nAlgunas observaciones sobre este código:\n\nsummary_factorlist(dependent, independent, fit_id = TRUE) se usa para calcular las estadísticas descriptivas por grupo de la variable dependiente.\nfinalfit_merge() se usa para fusionar los resultados.\ndplyr::select(-fit_id, -index) se usa para eliminar columnas innecesarias.\ndplyr::rename(Variables = label, \" \" = levels) se usa para renombrar algunas columnas.\n\nY finalmente, algunas observaciones sobre la tabla resultante:\n\nLa primera columna da el nombre de las variables.\nLa segunda columna especifica:\n\nPara variables cualitativas: los niveles.\nPara variables cuantitativas: que es la media y la desviación estándar (DE) lo que se calculará en las dos columnas siguientes.\n\nLa tercera y cuarta columnas dan las estadísticas descriptivas para cada nivel de la variable dependiente:\n\nPara variables cualitativas: el número de casos y, entre paréntesis, las frecuencias por columna.\nPara variables cuantitativas: la media y, entre paréntesis, la desviación estándar.\n\nLas últimas tres columnas dan el OR y, entre paréntesis, el IC del 95% del OR y el valor \\(p\\) (para el modelo univariable y los dos modelos multivariables, respectivamente).\n\nPara tu comodidad, aquí tienes el código completo para que puedas copiarlo y pegarlo fácilmente en caso de que quieras reproducir el proceso:\n\n# cargar paquetes\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(finalfit)\n\n# establecer variables\ndependent &lt;- \"heart_disease\"\nindependent &lt;- c(\"age\", \"sex\", \"chest_pain\", \"max_heartrate\")\nindependent_final &lt;- c(\"age\", \"sex\", \"chest_pain\")\n\n# guardar estadísticas descriptivas\nsummary &lt;- dat |&gt;\n  summary_factorlist(dependent, independent, fit_id = TRUE)\n\n# guardar resultados de regresiones logísticas univariables\nglmuni &lt;- dat |&gt;\n  glmuni(dependent, independent) |&gt;\n  fit2df(\n    explanatory_name = \"Variables\",\n    estimate_name = \"OR Crudo\",\n    estimate_suffix = \" (IC 95%)\"\n  )\n\n# guardar resultados del modelo completo\nglmmulti_full &lt;- dat |&gt;\n  glmmulti(dependent, independent) |&gt;\n  fit2df(\n    explanatory_name = \"Variables\",\n    estimate_name = \"OR Ajustado - modelo completo\",\n  )\n\n# guardar resultados del modelo final\nglmmulti_final &lt;- dat |&gt;\n  glmmulti(dependent, independent_final) |&gt;\n  fit2df(\n    explanatory_name = \"Variables\",\n    estimate_name = \"OR Ajustado - modelo final\",\n    estimate_suffix = \" (IC 95%)\"\n  )\n\n# guardar resultados fusionados\noutput &lt;- summary |&gt;\n  finalfit_merge(glmuni) |&gt;\n  finalfit_merge(glmmulti_full) |&gt;\n  finalfit_merge(glmmulti_final)\n\n# imprimir todos los resultados\noutput |&gt;\n  dplyr::select(-fit_id, -index) |&gt;\n  dplyr::rename(\n    Variables = label,\n    \" \" = levels\n  ) |&gt;\n  gt()\n\nPor último, pero no menos importante, la función or_plot(), también disponible en el paquete {finalfit}, es útil para visualizar todos los odds ratio y sus intervalos de confianza del 95%:\n\ndat |&gt; or_plot(dependent, independent,\n  table_text_size = 3.5 # reducir tamaño del texto\n)\n\n\n\n\n\n\n\n\nA continuación se explica cómo leer este gráfico:\n\nLos cuadrados representan el OR, y las líneas sus IC del 95%.\nCuando el IC del 95% cruza la línea vertical discontinua, significa que el OR no es significativamente diferente de 1 (a un nivel de significancia del 5%). En estos casos, no podemos rechazar la hipótesis de no asociación con la variable dependiente.\nCuando el IC del 95% no cruza la línea vertical discontinua, significa que el OR es significativamente diferente de 1. En estos casos:\n\nSi el cuadrado se encuentra a la derecha de la línea vertical discontinua, existe una relación positiva entre el resultado y la variable independiente (conocido como factor de riesgo).\nSi el cuadrado se encuentra a la izquierda de la línea vertical discontinua, existe una relación negativa entre el resultado y la variable independiente (conocido como factor protector).\n\n\nEl gráfico confirma lo que se obtuvo anteriormente:\n\nLa edad es un factor de riesgo para la enfermedad cardíaca.\nLa frecuencia cardíaca máxima alcanzada es un factor protector para la enfermedad cardíaca.\nSer hombre y sufrir de dolor torácico asintomático son ambos factores de riesgo de enfermedad cardíaca.\n\nTen cuidado de que a veces el cuadrado es demasiado grande para ver las líneas del IC del 95%. Este es el caso de las variables max_heartrate y age. En estos casos, es mejor verificar la significancia del OR gracias a sus IC del 95% o los valores \\(p\\) impresos entre paréntesis.\nClaro, aquí tienes la traducción de las secciones finales.\n\n\n4.6.6 Condiciones de aplicación\nPara que los resultados sean válidos e interpretables, una regresión logística binaria requiere:\n\nQue la variable dependiente sea binaria.\nIndependencia de las observaciones: que no haya mediciones repetidas o datos pareados; de lo contrario, se deben usar modelos lineales generalizados de efectos mixtos (GLMM).\nLinealidad de las variables independientes continuas y el resultado en log-odds: tomemos como ejemplo la edad y la enfermedad cardíaca. Si la enfermedad cardíaca es más o menos frecuente a medida que aumenta la edad, el modelo funcionará bien. Sin embargo, si los niños y los ancianos tienen un alto riesgo de padecer una enfermedad cardíaca, pero los de mediana edad no, entonces la relación no es lineal, o no es monotónica, lo que significa que la respuesta no va solo en una dirección.\nUn tamaño de muestra suficientemente grande (para que los intervalos de confianza y las pruebas de hipótesis sean válidos).\nNo multicolinealidad: las variables independientes no deben estar altamente correlacionadas entre sí; de lo contrario, los coeficientes y los OR pueden volverse inestables.\n\nA continuación se explica cómo verificar cada una de ellas:\n\nEsto es obvio; comprueba si la variable dependiente tiene efectivamente solo dos niveles.\nEsto a menudo no se prueba formalmente, sino que se verifica a través del diseño del experimento.\nLas variables independientes cuantitativas deben tener una relación lineal entre sus log-odds y sus valores observados. Una comprobación visual es suficiente, mira a continuación con la edad, la frecuencia cardíaca máxima alcanzada y el modelo m2 como ejemplo:\n\n\n# ¿Linealidad con los log-odds?\ndat |&gt;\n  dplyr::select(age, max_heartrate) |&gt;\n  mutate(log_odds = predict(m2)) |&gt;\n  pivot_longer(-log_odds) |&gt;\n  ggplot(aes(log_odds, value)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~name)\n\n\n\n\n\n\n\n\n\nEn la práctica, se recomienda tener al menos 10 veces más eventos que parámetros en el modelo.\nEl factor de inflación de la varianza (VIF) es una medida bien conocida de multicolinealidad. Debería estar por debajo de 10 o 5, dependiendo del campo de investigación. El VIF se puede calcular con la función vif(), disponible en el paquete {car}:\n\n\n# cargar paquete\nlibrary(car)\n\n# calcular VIF para el modelo m3\nvif(m2)\n\n                  GVIF Df GVIF^(1/(2*Df))\nage           1.205246  1        1.097837\nsex           1.155071  1        1.074742\nchest_pain    1.113010  3        1.018005\nmax_heartrate 1.143125  1        1.069170",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>TEMA 4: REGRESIÓN LOGISTICA</span>"
    ]
  },
  {
    "objectID": "TEMA-5.html",
    "href": "TEMA-5.html",
    "title": "5  TEMA 5: ANÁLISIS DE SUPERVIVENCIA",
    "section": "",
    "text": "5.1 Introducción\nCuando hayamos terminado este tema, seremos capaces de:\nPara la última publicación del año, me gustaría presentar un método estadístico bastante desconocido (aunque importante): el análisis de supervivencia. Aunque el análisis de supervivencia es una rama de la estadística, no suele abordarse en los cursos de introducción a la estadística y es bastante desconocido para el público general. Se enseña principalmente en cursos de bioestadística o en programas de estudio de estadística avanzada.\nEn la práctica, el análisis de supervivencia casi siempre se realiza con un programa estadístico y nunca a mano. Sin embargo, como con cualquier concepto estadístico, la computación al menos una vez a mano permite entender realmente los conceptos y lo que estos programas hacen en realidad. Por esta razón, se mostrará un breve ejemplo de cómo realizar un análisis de supervivencia básico a mano.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>TEMA 5: ANÁLISIS DE SUPERVIVENCIA</span>"
    ]
  },
  {
    "objectID": "TEMA-5.html#introducción",
    "href": "TEMA-5.html#introducción",
    "title": "5  TEMA 5: ANÁLISIS DE SUPERVIVENCIA",
    "section": "",
    "text": "5.1.1 ¿Qué es el análisis de supervivencia?\nEl análisis de supervivencia (también llamado análisis de tiempo hasta el evento o análisis de duración) es una rama de la estadística que tiene como objetivo analizar la duración del tiempo desde un origen temporal bien definido hasta que ocurren uno o más eventos, llamados tiempos de supervivencia o tiempos de duración. En otras palabras, en el análisis de supervivencia, nos interesa un evento determinado y queremos analizar el tiempo hasta que ese evento ocurre.\nSi bien el evento de interés suele ser la muerte (en este caso, estudiamos el tiempo hasta la muerte para pacientes con una enfermedad específica) o la recurrencia (en este caso, estudiamos el tiempo hasta la recaída de una enfermedad determinada), no se limita al campo de la medicina o la epidemiología. De hecho, se puede utilizar en muchos ámbitos. El evento de interés no tiene por qué ser la muerte o la aparición de una enfermedad, pero en todas las situaciones estamos interesados en analizar el tiempo hasta que ocurre un evento específico.\nLos datos de supervivencia, también conocidos como datos de tiempo hasta el evento, requieren un conjunto especial de métodos estadísticos por tres razones principales:\n\nLos tiempos de duración son siempre positivos: el tiempo hasta que ocurre un evento de interés no puede ser menor que 0. Además, la distribución de los tiempos de supervivencia tiene un sesgo a la derecha.\nSe utilizan diferentes medidas de interés dependiendo de la pregunta de investigación, el contexto, etc. Por ejemplo, podríamos estar interesados en: La probabilidad de que un paciente con cáncer sobreviva más de 5 años después del diagnóstico o el tiempo de espera hasta la próxima recidiva de cáncer.\nLa censura definida como la falta de observación del evento de interés para algunos individuos durante el período de estudio. Cuando el evento ocurrió antes del final del estudio, el tiempo de supervivencia se conoce, sin embargo, a veces, el evento aún no se ha observado al final del estudio. Supongamos que estudiamos el tiempo hasta la muerte de pacientes con cáncer de mama. Afortunadamente, algunas pacientes no morirán antes de que finalice el estudio. Pero también puede ocurrir que el paciente se pierda durante el seguimiento (por ejemplo, porque se muda a otra ciudad o país) o que el paciente decida abandonar el estudio. En estos casos, no conocemos su tiempo exacto de supervivencia, pero sabemos que sobrevivieron al menos hasta el final del estudio o hasta el momento en que se perdieron o abandonaron el estudio. En todas estas situaciones, su tiempo de supervivencia no puede observarse porque el evento no se observa durante la duración del estudio.\n\nLa censura hace que se requieren métodos estadísticos específicos para tener en cuenta el hecho de que la duración exacta de la supervivencia de algunos pacientes falta. Se sabe que sobrevivieron una cierta cantidad de tiempo (hasta el final del estudio o hasta el momento del abandono), pero se desconoce su tiempo exacto de supervivencia.\nPara tu información, existen tres tipos de censura:\n\nCensura a la derecha (la más frecuente),\nCensura a la izquierda (la menos frecuente) y\nCensura por intervalo.\n\nCuando el evento aún no se ha observado al final del estudio (es decir, el tiempo de supervivencia es mayor que la duración observada), esto se conoce como censura a la derecha. La censura a la izquierda ocurre si un participante entra en el estudio cuando el evento de interés ya ha ocurrido antes de su entrada, pero no sabemos exactamente cuándo. La censura por intervalo implica que el evento ocurrió dentro de un intervalo de tiempo (entre dos fechas conocidas, dos visitas, etc.); no se conoce el momento exacto de la ocurrencia. El objetivo es, por supuesto, analizar todos los datos disponibles, incluida la información sobre los pacientes censurados.\nEl objetivo del análisis de supervivencia es, por tanto, modelar y describir los datos de tiempo hasta el evento de una manera apropiada, teniendo en cuenta las particularidades de este tipo de datos.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>TEMA 5: ANÁLISIS DE SUPERVIVENCIA</span>"
    ]
  },
  {
    "objectID": "TEMA-5.html#funciones-comunes-en-el-análisis-de-supervivencia",
    "href": "TEMA-5.html#funciones-comunes-en-el-análisis-de-supervivencia",
    "title": "5  TEMA 5: ANÁLISIS DE SUPERVIVENCIA",
    "section": "5.2 Funciones comunes en el análisis de supervivencia",
    "text": "5.2 Funciones comunes en el análisis de supervivencia\nNo vamos a entrar en demasiados detalles, pero es importante sentar las bases con las funciones más comunes en el análisis de supervivencia.\nSea \\(T\\) una variable aleatoria continua no negativa, que representa el tiempo hasta el evento de interés. Consideramos las siguientes funciones:\n\nFunción de supervivencia\nFunción de riesgo acumulado\nFunción de riesgo\n\n\n5.2.1 Función de supervivencia (survival function)\nLa más común es la función de supervivencia.\nSea \\(T\\) una variable aleatoria continua no negativa, que representa el tiempo hasta el evento de interés. La función de supervivencia \\(S(t)\\) es la probabilidad de que un individuo elegido al azar siga en riesgo en el tiempo \\(t\\), donde \\(0 \\le t \\le +\\infty\\). Para cada \\(t\\), viene dada por\n\\[\n\\begin{align*}\nS(t) &= P(T &gt; t)\\\\\n&= 1 - P(T \\le t)\\\\\n&= 1 - F(t)\\\\\n&= 1 - \\int^t_0 f(u)\\text{d}u,\n\\end{align*}\n\\]\ndonde \\(f(\\cdot)\\) y \\(F(\\cdot)\\) son las funciones de densidad y de distribución acumulada de \\(T\\), respectivamente.\n\\(S(t)\\) representa, para cada tiempo \\(t\\), la probabilidad de que el tiempo hasta el evento sea mayor que este tiempo \\(t\\). En otras palabras, modela la probabilidad de que el evento de interés ocurra después de \\(t\\). En el contexto de la Bioestadística, la probabilidad de que un paciente seleccionado al azar sobreviva más allá del tiempo \\(t\\) o la proporción de pacientes que siguen vivos después del tiempo \\(t\\),\nLa función de supervivencia \\(S(t)\\) es:\n\nuna función decreciente,\nque toma valores en \\([0, 1]\\) (ya que es una probabilidad), y\nes igual a 1 en \\(t = 0\\) (es decir, \\(S(0) = 1\\)) y 0 en \\(t = \\infty\\) (es decir, \\(S(\\infty) = 0\\)).\n\nVisualmente tenemos:\nLa curva muestra la proporción de individuos (o unidades experimentales) que, a medida que pasa el tiempo, no han experimentado el evento de interés. Con el paso del tiempo, ocurren eventos, por lo que la proporción de quienes no han experimentado el evento disminuye.\n\n\n\n\n\n\n\n\n\n\n\n5.2.2 Función de riesgo acumulado (cummlative hazard function)\nLa función de riesgo acumulado, que es el riesgo total experimentado hasta el tiempo \\(t\\), se define como:\n\\[H(t) = -\\log\\left(S(t)\\right)\\]\ny tiene las siguientes propiedades:\n\nfunción creciente,\ntoma valores en \\([0, +\\infty]\\), y\n\\(S(t) = \\exp(-H(t))\\).\n\n\n\n5.2.3 Función de riesgo (Hazard function)\nLa función de riesgo \\(h(t)\\), o tasa de riesgo, define la tasa instantánea de eventos en el tiempo \\(t\\) para un individuo que todavía está en riesgo en ese momento. Se puede obtener mediante\n\\[\n\\begin{align*}\nh(t) &= \\lim_{\\Delta t \\rightarrow 0} \\frac{P(t \\le T &lt; t + \\Delta t | T \\ge t)}{\\Delta t}\\\\\n&= \\frac{d}{dt} H(t)\\\\\n&= \\frac{f(t)}{S(t)}.\n\\end{align*}\n\\] y tiene las siguientes propiedades:\n\nfunción positiva (no necesariamente creciente o decreciente)\nla función de riesgo \\(h(t)\\) puede tener muchas formas diferentes y, por lo tanto, es una herramienta útil para resumir datos de supervivencia.\n\nEn el contexto de la investigación del cáncer, cuando la muerte es el evento de interés, \\(h(t)\\) mide el riesgo instantáneo de morir justo después del tiempo \\(t\\), dado que el individuo está vivo en el tiempo \\(t\\).\nPara vincular la tasa de riesgo con la función de supervivencia, la curva de supervivencia representa las tasas de riesgo. Una pendiente más pronunciada indica una tasa de riesgo más alta porque los eventos ocurren con más frecuencia, reduciendo la proporción de individuos que no han experimentado el evento a un ritmo más rápido. Por el contrario, una pendiente gradual y más plana indica una tasa de riesgo más baja porque los eventos ocurren con menos frecuencia, reduciendo la proporción de individuos que no han experimentado el evento a un ritmo más lento. Más formalmente:\n\\[S(t) = \\exp\\left(-\\int^t_0 h(u) \\text{d}u\\right).\\] Ten en cuenta que, a diferencia de la función de supervivencia que se centra en no tener un evento, la función de riesgo se centra en que el evento ocurra.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>TEMA 5: ANÁLISIS DE SUPERVIVENCIA</span>"
    ]
  },
  {
    "objectID": "TEMA-5.html#estimación-estadística-de-la-función-de-supervivencia-el-estimador-de-kaplan-meier",
    "href": "TEMA-5.html#estimación-estadística-de-la-función-de-supervivencia-el-estimador-de-kaplan-meier",
    "title": "5  TEMA 5: ANÁLISIS DE SUPERVIVENCIA",
    "section": "5.3 Estimación estadística de la función de supervivencia: el estimador de Kaplan-Meier",
    "text": "5.3 Estimación estadística de la función de supervivencia: el estimador de Kaplan-Meier\nPara estimar la función de supervivencia, necesitamos usar un estimador que sea capaz de manejar la censura. El más común es el estimador no paramétrico de Kaplan-Meier, también conocido a veces como el estimador de producto-límite, o más simplemente, el estimador K-M [1].\nLas ventajas del estimador de Kaplan-Meier son que:\n\nes simple y directo de usar e interpretar.\nes un estimador no paramétrico, por lo que construye una curva de supervivencia a partir de los datos y no se hacen suposiciones sobre la forma de la distribución subyacente.\nproporciona una representación gráfica de la(s) función(es) de supervivencia, útil para fines ilustrativos.\n\nEl principio detrás de este estimador es que sobrevivir más allá del tiempo \\(t_i\\) implica sobrevivir más allá del tiempo \\(t_{i-1}\\) y sobrevivir en el tiempo \\(t_i\\). Ten en cuenta que una suposición importante para que la estimación sea válida es que la censura es independiente de la ocurrencia de eventos. Decimos que la censura no es informativa, es decir, los sujetos censurados tienen las mismas perspectivas de supervivencia que los sujetos que no están censurados y que continúan siendo seguidos.\nPara entender cómo funciona, primero vamos a estimarlo a mano con el siguiente conjunto de datos. Ten en cuenta que en el análisis de supervivencia, la precisión de los estimadores y la potencia de las pruebas no depende del número de pacientes, sino del número de eventos. Por lo tanto, es mejor tener muchas observaciones en las que el evento ocurra para que los análisis sean efectivos. Aquí tenemos 10 sujetos con sus tiempos de supervivencia (en años) y su estado de evento (0 = censurado, 1 = evento ocurrido):\n\n\n\n\n\n\n\n\nsubject\ntime\nevent\n\n\n\n\n1\n3\n0\n\n\n2\n5\n1\n\n\n3\n7\n1\n\n\n4\n2\n1\n\n\n5\n18\n0\n\n\n6\n16\n1\n\n\n7\n2\n1\n\n\n8\n9\n1\n\n\n9\n16\n1\n\n\n10\n5\n0\n\n\n\n\n\n\n\ndonde: - subject es el identificador del individuo - time es el tiempo hasta el evento (en años). Ten en cuenta que la variable time puede expresarse en otras unidades, como segundos, días, semanas, meses, etc. - event es el estado del evento (0 = censurado, 1 = evento ocurrido)\nRecuerda que para cada sujeto, necesitamos conocer al menos 2 datos:\n\nel tiempo hasta el evento de interés o el tiempo hasta la censura, y\nsi hemos observado el evento de interés o si hemos observado censura.\n\nPrimero necesitamos contar el número de tiempos de evento distintos. Ignorando las observaciones censuradas, tenemos 5 tiempos de evento distintos:\n2, 5, 7, 9, 16\nLa forma más fácil de hacer el cálculo a mano es rellenando la siguiente tabla (una tabla con 5 filas ya que hay 5 tiempos de evento distintos):\n\n\n\n\n\n\n\n\n\n\n\\(j\\)\n\\(y_{(j)}\\)\n\\(d_{(j)}\\)\n\\(R_{(j)}\\)\n\\(1 - \\frac{d_{(j)}}{R_{(j)}}\\)\n\n\n\n\n1\n\n\n\n\n\n\n2\n\n\n\n\n\n\n3\n\n\n\n\n\n\n4\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\nRellenamos las columnas una por una:\n\n\\(y_{(j)}\\) = los tiempos de evento distintos y ordenados:\n\n2, 5, 7, 9, 16\nAsí que la tabla queda:\n\n\n\n\n\n\n\n\n\n\n\\(j\\)\n\\(y_{(j)}\\)\n\\(d_{(j)}\\)\n\\(R_{(j)}\\)\n\\(1 - \\frac{d_{(j)}}{R_{(j)}}\\)\n\n\n\n\n1\n2\n\n\n\n\n\n2\n5\n\n\n\n\n\n3\n7\n\n\n\n\n\n4\n9\n\n\n\n\n\n5\n16\n\n\n\n\n\n\n\n\\(d_{(j)}\\) = el número de observaciones para cada tiempo de evento distinto. Para esto, la frecuencia de cada tiempo de evento distinto es útil y la tabla queda:\n\n\n\n\n\n\n\n\n\n\n\n\\(j\\)\n\\(y_{(j)}\\)\n\\(d_{(j)}\\)\n\\(R_{(j)}\\)\n\\(1 - \\frac{d_{(j)}}{R_{(j)}}\\)\n\n\n\n\n1\n2\n2\n\n\n\n\n2\n5\n1\n\n\n\n\n3\n7\n1\n\n\n\n\n4\n9\n1\n\n\n\n\n5\n16\n2\n\n\n\n\n\n\n\\(R\\_{(j)}\\) = el número restante de individuos en riesgo. Para esto, la distribución del tiempo (censurado y no censurado) es útil. Vemos que:\nAl principio hay 10 sujetos\nJusto antes del tiempo \\(t = 5\\), quedan 7 sujetos (10 sujetos - 2 que tuvieron el evento - 1 que está censurado)\nJusto antes del tiempo \\(t = 7\\), quedan 5 sujetos (= 10 - 2 - 1 - 2)\nJusto antes del tiempo \\(t = 9\\), quedan 4 sujetos (= 10 - 2 - 1 - 2 - 1)\nJusto antes del tiempo \\(t = 16\\), quedan 3 sujetos (= 10 - 2 - 1 - 2 - 1 - 1)\n\nLa tabla queda:\n\n\n\n\n\n\n\n\n\n\n\\(j\\)\n\\(y_{(j)}\\)\n\\(d_{(j)}\\)\n\\(R_{(j)}\\)\n\\(1 - \\frac{d_{(j)}}{R_{(j)}}\\)\n\n\n\n\n1\n2\n2\n10\n\n\n\n2\n5\n1\n7\n\n\n\n3\n7\n1\n5\n\n\n\n4\n9\n1\n4\n\n\n\n5\n16\n2\n3\n\n\n\n\n\n\\(1 - \\frac{d_{(j)}}{R_{(j)}}\\) es de cálculo sencillo, así que la tabla queda:\n\n\n\n\n\n\n\n\n\n\n\n\\(j\\)\n\\(y_{(j)}\\)\n\\(d_{(j)}\\)\n\\(R_{(j)}\\)\n\\(1 - \\frac{d_{(j)}}{R_{(j)}}\\)\n\n\n\n\n1\n2\n2\n10\n0.800\n\n\n2\n5\n1\n7\n0.857\n\n\n3\n7\n1\n5\n0.800\n\n\n4\n9\n1\n4\n0.750\n\n\n5\n16\n2\n3\n0.333\n\n\n\nEl estimador de Kaplan-Meier es: \\[\\hat{S}_{KM}(t) = \\prod_{j:y_{(j)} \\le t} \\left(1 - \\frac{d_{(j)}}{R_{(j)}} \\right)\\] que es el producto acumulado de los términos en la última columna para todos los tiempos de evento distintos \\(y_{(j)}\\) menores o iguales a \\(t\\). Para cada \\(j\\), tomamos el producto acumulado:\n\n\\(j_1 = 0.8\\)\n\\(j_2 = 0.8 \\cdot 0.857 = 0.6856\\)\n\\(j_3 = 0.6856 \\cdot 0.8 = 0.54848\\)\n\\(j_4 = 0.54848 \\cdot 0.75 = 0.41136\\)\n\\(j_5 = 0.41136 \\cdot 0.333 = 0.1369829\\)\n\nAsí que finalmente, tenemos las probabilidades de supervivencia (redondeadas a 3 decimales):\n\n\n\n\\(j\\)\n\\(1 - \\frac{d_{(j)}}{R_{(j)}}\\)\n\\(\\hat{S}_{KM}(t)\\)\n\n\n\n\n1\n0.800\n0.800\n\n\n2\n0.857\n0.686\n\n\n3\n0.800\n0.548\n\n\n4\n0.750\n0.411\n\n\n5\n0.333\n0.137\n\n\n\nAhora podemos representar gráficamente el estimador de Kaplan-Meier con las funciones survfit() y Surv():\nObserva que la función Surv() acepta dos argumentos: 1. la variable time, y 2. la variable event.\nEl ~ 1 en la función survfit() indica que estimamos el Kaplan-Meier sin ninguna agrupación. Finalmente, mostramos los resultados y dibujamos el gráfico de Kaplan-Meier en R:\n\n# KM\nlibrary(survival)\nkm &lt;- survfit(Surv(time, event) ~ 1,\n              data = dat)\n\n# resultados\nsummary(km)\n\nCall: survfit(formula = Surv(time, event) ~ 1, data = dat)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    2     10       2    0.800   0.126       0.5868        1.000\n    5      7       1    0.686   0.151       0.4447        1.000\n    7      5       1    0.549   0.172       0.2963        1.000\n    9      4       1    0.411   0.176       0.1782        0.950\n   16      3       2    0.137   0.126       0.0225        0.834\n\n# gráfico\nplot(km,\n     xlab = \"Tiempo\",\n     ylab = \"Probabilidad de supervivencia\",\n     conf.int = FALSE)\n\n\n\n\n\n\n\n\nLas probabilidades de supervivencia se pueden encontrar en la columna survival. Observa que los resultados a mano y en R son similares (cualquier diferencia con los resultados a mano se debe al redondeo).\nAlternativamente, podemos usar la función ggsurvplot() del paquete {survminer}:\n\n#install.packages(\"survminer\")\nlibrary(survminer)\n# gráfico\nggsurvplot(km,\n           conf.int = FALSE,\n           legend = \"none\")\n\n\n\n\n\n\n\n\nNota: las cruces en la curva de supervivencia denotan las observaciones censuradas.\nLa ventaja de la función ggsurvplot() es que es fácil dibujar la mediana de supervivencia directamente en el gráfico. Se prefiere la mediana a la media en el análisis de supervivencia porque las funciones de supervivencia a menudo están sesgadas a la derecha. La media suele estar influenciada por valores atípicos, mientras que la mediana no.\n\n# gráfico con mediana\nggsurvplot(km,\n           conf.int = FALSE,\n           surv.median.line = \"hv\",\n           legend = \"none\")\n\n\n\n\n\n\n\n\nTen en cuenta que si la curva de supervivencia no cruza el 50% es porque la supervivencia es mayor al 50% en el último punto temporal, entonces la mediana de supervivencia no se puede calcular y simplemente está indefinida.\n\nsummary(km)$table[\"median\"]\n\nmedian \n     9 \n\n# o más simple\nkm\n\nCall: survfit(formula = Surv(time, event) ~ 1, data = dat)\n\n      n events median 0.95LCL 0.95UCL\n[1,] 10      7      9       5      NA\n\n\nSupongamos que el evento de interés es la muerte:\n\nEn el tiempo cero, la probabilidad de supervivencia es 1 (el 100% de los sujetos están vivos).\nLa mediana indica que el tiempo mediano de supervivencia es de 9 años. Ten en cuenta que la mediana de supervivencia se expresa en la misma unidad que la variable time en el conjunto de datos inicial. Así, si la unidad de tiempo fueran meses, el tiempo mediano de supervivencia sería de 9 meses. Este es el tiempo en el que la supervivencia \\(S(t)\\) es del 50%. En otras palabras, es el tiempo después del cual se espera que la mitad de los sujetos hayan muerto.\nDel gráfico, también vemos que \\(S(5) = P(T &gt; 5 \\text{ años}) =\\) Probabilidad de supervivencia de más de 5 años para estos sujetos = 75%. Esto significa que el 75% de todos los sujetos sobreviven más de 5 años, y que el 25% de todos los sujetos mueren en los primeros 5 años.\n\nPara ser exhaustivos, hagamos otro ejemplo con un conjunto de datos mucho más grande; el conjunto de datos tongue del paquete {KMsurv}.Puedes encontrar más información sobre el conjunto de datos en CRAN o con ?tongue.\n\n# cargar datos\nlibrary(KMsurv)\ndata(tongue)\n# previsualizar datos\nhead(tongue)\n\n  type time delta\n1    1    1     1\n2    1    3     1\n3    1    3     1\n4    1    4     1\n5    1   10     1\n6    1   13     1\n\n\n\ntype es el perfil de ADN del tumor (1 = tumor aneuploide, 2 = tumor diploide)\ntime es el tiempo hasta la muerte o el tiempo en estudio (en semanas)\ndelta es el indicador de muerte (0 = vivo, 1 = muerto)\n\nPara este ejemplo, nos centramos en el tipo aneuploide:\n\naneuploid &lt;- subset(tongue, type == 1)\n\nAhora podemos graficar la función de supervivencia estimada y estimar el tiempo mediano hasta la muerte. Dado que es un estimador, también podemos construir un intervalo de confianza para la supervivencia estimada en cada tiempo \\(t\\) y para el tiempo mediano de supervivencia estimado.\n\nlibrary(survival)\n# resultados\nfit &lt;- survfit(Surv(time, delta) ~ 1,\n               data = aneuploid,\n               conf.type = \"log-log\")\n\nfit\n\nCall: survfit(formula = Surv(time, delta) ~ 1, data = aneuploid, conf.type = \"log-log\")\n\n      n events median 0.95LCL 0.95UCL\n[1,] 52     31     93      65     157\n\n# gráfico\nggsurvplot(fit,\n           surv.median.line = \"hv\",\n           legend = \"none\")\n\n\n\n\n\n\n\n\nEl tiempo mediano de supervivencia se estima en 93 semanas, con un intervalo de confianza del 95% entre 65 y 157 semanas.\nLas curvas de Kaplan-Meier pueden verse como estadísticas descriptivas para datos de supervivencia. Ahora nos centramos en la segunda rama de la estadística, la prueba de hipótesis, que permite sacar conclusiones sobre la población basándose en una muestra.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>TEMA 5: ANÁLISIS DE SUPERVIVENCIA</span>"
    ]
  },
  {
    "objectID": "TEMA-5.html#prueba-de-hipótesis-log-rank-test",
    "href": "TEMA-5.html#prueba-de-hipótesis-log-rank-test",
    "title": "5  TEMA 5: ANÁLISIS DE SUPERVIVENCIA",
    "section": "5.4 Prueba de hipótesis: Log-rank test",
    "text": "5.4 Prueba de hipótesis: Log-rank test\nLa prueba de hipótesis en el campo del análisis de supervivencia se ocupa principalmente de:\n\nLa función de riesgo de una población: en este caso, probamos si una muestra censurada proviene de una población con una función de riesgo conocida \\(h_0(t)\\). Por ejemplo, podríamos estar interesados en comparar la supervivencia en una muestra de pacientes con la supervivencia en la población general (derivada de las tablas de vida).\nLa comparación de la función de riesgo de dos o más poblaciones: en este caso, nos interesa evaluar si existen diferencias en la supervivencia entre diferentes grupos de sujetos. Por ejemplo nos interesa comparar la supervivencia de pacientes con cáncer de colon hombres y mujeres o más grupos (la supervivencia de pacientes con cáncer de melanoma según sus tratamientos con tratamientos A, B y C, por ejemplo).\n\nEl test Log-rank (también conocido como prueba de Mantel-Cox) es la prueba de hipótesis más común para comparar la supervivencia entre dos grupos [2]. La intuición detrás de la prueba es que si los dos grupos tienen tasas de riesgo diferentes, las dos curvas de supervivencia (y por lo tanto sus pendientes) diferirán. Más precisamente, la prueba de log-rank compara el número observado de eventos en cada grupo con lo que se esperaría si las curvas de supervivencia fueran idénticas (es decir, si la hipótesis nula fuera cierta). Ten en cuenta que, al igual que el estimador de Kaplan-Meier, la prueba de log-rank es una prueba no paramétrica, que no hace suposiciones sobre las distribuciones de supervivencia.\nPara este ejemplo, considera el siguiente conjunto de datos:\n\n\n   patient group time event\n1        1     1  4.1     1\n2        2     1  7.8     0\n3        3     1 10.0     1\n4        4     1 10.0     1\n5        5     1 12.3     0\n6        6     1 17.2     1\n7        7     2  9.7     1\n8        8     2 10.0     1\n9        9     2 11.1     0\n10      10     2 13.1     0\n11      11     2 19.7     1\n12      12     2 24.1     0\n\n\ndonde: - patient es el identificador del paciente - group es el grupo (grupo 1 o 2) - time es el tiempo hasta la muerte (en años) - event es el estado del evento (0 = censurado, 1 = muerte) Supongamos que estamos interesados en comparar el grupo 1 y 2 en términos de supervivencia, es decir, comparamos las curvas de supervivencia entre los 2 grupos:\n\n\\(H_0 : S_1(t) = S_2(t)\\) para todo \\(t\\)\n\\(H_1 : S_1(t) \\ne S_2(t)\\) para algún \\(t\\)\n\nEs una prueba estadística, por lo que si el valor \\(p\\) &lt; \\(\\alpha\\) (generalmente 0.05), rechazamos la hipótesis nula y concluimos que la supervivencia (o el tiempo hasta el evento) es significativamente diferente entre los dos grupos considerados.\nPara realizar la prueba de log-rank, el siguiente estadístico de prueba será útil:\n\\[\n\\begin{eqnarray}\nU &=& \\sum_{j=1}^r w(y_{(j)})\\left(O_j - E_j\\right) \\\\\n&=& \\sum_{j=1}^r w(y_{(j)})\\left( d_{(j)1} - \\frac{d_{(j)}R_{(j)1}}{R_{(j)}}\\right)\n\\end{eqnarray}\n\\]\ncon \\(U^{obs} = \\frac{U}{\\sqrt{Var(U)}} \\sim N(0,1)\\) y este es el caso para muestras grandes. El ejemplo descrito aquí no cumple esta condición, pero aun así lo mostramos como ilustración.\n\\[\n\\begin{eqnarray}\nVar(U) &=& \\sum_{j=1}^r w^2(y_{(j)}) \\frac{N_{(j)}}{ D_{(j)}  }\\\\\n&=& \\sum_{j=1}^r w^2(y_{(j)}) \\frac{ d_{(j)} \\frac{R_{(j)1}}{R_{(j)} } \\left( 1 - \\frac{R_{(j)1}}{R_{(j)} } \\right) \\left( R_{(j)} - d_{(j)}\\right) }{ R_{(j)} - 1  }\n\\end{eqnarray}\n\\] Al igual que con el estimador de Kaplan-Meier a mano, es mejor rellenar una tabla para la prueba de log-rank a mano.\nPresentemos la tabla final y comentemos a continuación cómo rellenarla, columna por columna:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(j\\)\n\\(y_{(j)}\\)\n\\(d_{(j)1}\\)\n\\(R_{(j)1}\\)\n\\(d_{(j)2}\\)\n\\(R_{(j)2}\\)\n\\(d_{(j)}\\)\n\\(R_{(j)}\\)\n\\(E_{j}\\)\n\\(O_{j}\\)\n\\(O_{j} - E_{j}\\)\n\\(N_{(j)}\\)\n\\(D_{(j)}\\)\n\\(N_{(j)}/D_{(j)}\\)\n\n\n\n\n1\n4.1\n1\n6\n0\n6\n1\n12\n0.5\n1\n0.5\n2.75\n11\n0.25\n\n\n2\n9.7\n0\n4\n1\n6\n1\n10\n0.4\n0\n-0.4\n2.16\n9\n0.24\n\n\n3\n10\n2\n4\n1\n5\n3\n9\n1.333\n2\n0.667\n4.44\n8\n0.555\n\n\n4\n17.2\n1\n1\n0\n2\n1\n3\n0.333\n1\n0.667\n0.44\n2\n0.22\n\n\n5\n19.7\n0\n0\n1\n2\n1\n2\n0\n0\n0\n0.00\n1\n0.00\n\n\n\\(Total\\)\n\n4\n\n3\n\n7\n\n2.566\n\n1.433\n\n\n1.265\n\n\n\nColumna \\(j\\) es el número de tiempos de evento distintos. Vemos que hay 5 (ignorando las observaciones censuradas), así que escribimos del 1 al 5 en la tabla. Columna \\(y_{(j)}\\) son los tiempos de evento distintos y ordenados: 4.1, 9.7, 10, 17.2, 19.7 Columna \\(d_{(j)1}\\) es el número de observaciones para cada tiempo de evento distinto, para el grupo 1. Cuando no hay ningún evento, simplemente escribimos 0 en la tabla. Columna \\(R_{(j)1}\\) es el número restante de pacientes en riesgo, para el grupo 1. Para esto, la distribución del tiempo (censurado y no censurado, para el grupo 1) es útil. Vemos que: - Al principio, hay 6 pacientes. - Antes del tiempo 9.7, quedan 4 pacientes (6 - 1 que tuvo el evento en el tiempo 4.1 - 1 que fue censurado en el tiempo 7.8). - Antes del tiempo 10, quedan 4 pacientes (6 - 2). - Antes del tiempo 17.2, queda 1 paciente (6 - 5). - Antes del tiempo 19.7, quedan 0 pacientes (6 - 6). Las columnas \\(d_{(j)2}\\) y \\(R_{(j)2}\\) siguen el mismo principio, pero esta vez para el grupo 2. Las columnas \\(d_{(j)}\\) y \\(R_{(j)}\\) también siguen el mismo principio, pero esta vez considerando ambos grupos. La columna \\(E_{j}\\) es el número esperado de eventos en el primer grupo asumiendo que \\(h_1 \\equiv h_2\\). Se obtiene de la siguiente manera:\n\\[ E_{j} = \\frac{d_{(j)}R_{(j)1}}{R_{(j)}}\\]\nLa columna \\(O_{j}\\) es el número observado de eventos en el primer grupo, por lo que es igual a la columna \\(d_{(j)1}\\). La columna \\(O_{j} - E_{j}\\) es sencilla. La columna \\(N_{(j)}\\) se define de la siguiente manera:\n\\[N_{(j)} = d_{(j)} \\frac{R_{(j)1}}{R_{(j)} } \\left( 1 - \\frac{R_{(j)1}}{R_{(j)} } \\right) \\left( R_{(j)} - d_{(j)}\\right)\\]\nLa columna \\(D_{(j)}\\) es \\(R_{(j)} - 1\\). La columna \\(N_{(j)}/D_{(j)}\\) es sencilla.\nDado que \\(w(y_{(j)}) = w^2(y_{(j)}) = 1\\) para una prueba de log-rank, tenemos\n\\[ U^{obs} = \\frac{U}{\\sqrt{Var(U)}} = \\frac{1.434}{\\sqrt{1.265}} = 1.275.\\]\nRechazamos \\(H_0\\) si \\(|U^{obs}|&gt;z_{1-\\alpha/2}\\), así que a un nivel de significancia del 5% rechazamos \\(H_0\\) si \\(|U^{obs}|&gt;z_{0.975}=1.96\\).\nTenemos \\(|U^{obs}| = 1.275 &lt; z_{0.975}=1.96\\). Por lo tanto, a un nivel de significancia del 5% no rechazamos \\(H_0\\). Esto significa que, basándonos en los datos, no podemos concluir que la supervivencia sea diferente entre los dos grupos (lo que es equivalente a decir que no rechazamos la hipótesis de que la supervivencia es igual entre los dos grupos).\nSi te interesa calcular el valor \\(p\\):\nvalor \\(p\\) \\(= 2\\times P(Z&gt;1.275) = 2 \\times 0.101 = 0.202 &gt; 0.05\\).\nEn R ahora comparamos nuestros resultados con la función survdiff():\n\ndat &lt;- data.frame(\n  group = c(rep(1, 6), rep(2, 6)),\n  time = c(4.1, 7.8, 10, 10, 12.3, 17.2, 9.7, 10, 11.1, 13.1, 19.7, 24.1),\n  event = c(1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0)\n)\n\ndat\n\n   group time event\n1      1  4.1     1\n2      1  7.8     0\n3      1 10.0     1\n4      1 10.0     1\n5      1 12.3     0\n6      1 17.2     1\n7      2  9.7     1\n8      2 10.0     1\n9      2 11.1     0\n10     2 13.1     0\n11     2 19.7     1\n12     2 24.1     0\n\nsurvdiff(Surv(time, event) ~ group,\n         data = dat)\n\nCall:\nsurvdiff(formula = Surv(time, event) ~ group, data = dat)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ngroup=1 6        4     2.57     0.800      1.62\ngroup=2 6        3     4.43     0.463      1.62\n\n Chisq= 1.6  on 1 degrees of freedom, p= 0.2 \n\n\nAlternativamente, podemos usar la función ggsurvplot() para dibujar las curvas de supervivencia y realizar la prueba de log-rank al mismo tiempo:\n\nfit &lt;- survfit(Surv(time, event) ~ group, data = dat)\n\nggsurvplot(fit,\n           pval = TRUE,\n           pval.method = TRUE)\n\n\n\n\n\n\n\n\nComo podemos ver, los valores \\(p\\) y las conclusiones son las mismas (cualquier diferencia con los resultados a mano se debe al redondeo). Al igual que con la estimación de Kaplan-Meier, hacemos otro ejemplo con un conjunto de datos más grande. Considera los datos sobre los tiempos hasta la infección por estafilococo en pacientes con quemaduras, también disponibles en {KMsurv}. Puedes encontrar más información sobre el conjunto de datos en CRAN o con ?burn.]\n\n# cargar datos\ndata(burn)\n\n# previsualizar datos\nhead(burn)\n\n  Obs Z1 Z2 Z3 Z4 Z5 Z6 Z7 Z8 Z9 Z10 Z11 T1 D1 T2 D2 T3 D3\n1   1  0  0  0 15  0  0  1  1  0   0   2 12  0 12  0 12  0\n2   2  0  0  1 20  0  0  1  0  0   0   4  9  0  9  0  9  0\n3   3  0  0  1 15  0  0  0  1  1   0   2 13  0 13  0  7  1\n4   4  0  0  0 20  1  0  1  0  0   0   2 11  1 29  0 29  0\n5   5  0  0  1 70  1  1  1  1  0   0   2 28  1 31  0  4  1\n6   6  0  0  1 20  1  0  1  0  0   0   4 11  0 11  0  8  1\n\n\nUsando la prueba de log-rank, queremos probar la hipótesis de diferencia en el tiempo hasta la infección por estafilococo (variable T3) entre pacientes cuyas quemaduras fueron tratadas con un método de baño rutinario (Z1 = 0) frente a aquellos cuya limpieza corporal se realizó inicialmente con gluconato de clorhexidina al 4% (Z1 = 1). El indicador de evento está en la variable D3.\nPara esta prueba, usamos una alternativa de dos colas y un nivel de significancia del 5%.\n\n# ajuste\nfit &lt;- survfit(Surv(T3, D3) ~ Z1, data = burn)\n\n# gráfico con prueba de log-rank\nggsurvplot(fit,\n           pval = TRUE,\n           pval.method = TRUE)\n\n\n\n\n\n\n\n\nEn la muestra, parece que el tiempo hasta la infección para los pacientes con baño rutinario (Z1 = 0) es menor que para los pacientes con limpieza corporal (Z1 = 1). Esto es así porque el porcentaje de pacientes que no han experimentado la infección disminuye más rápidamente, por lo que la tasa de riesgo es mayor. Sin embargo, esta conclusión no puede generalizarse a la población sin realizar una prueba estadística sólida. Y basándonos en el resultado de la prueba de log-rank, no rechazamos la hipótesis de que el tiempo hasta la infección es el mismo entre los dos grupos de pacientes (valor \\(p\\) = 0.051).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>TEMA 5: ANÁLISIS DE SUPERVIVENCIA</span>"
    ]
  },
  {
    "objectID": "TEMA-5.html#estimación-estadística-de-la-función-de-riesgo-acumulado-el-estimador-de-aalen-nelson",
    "href": "TEMA-5.html#estimación-estadística-de-la-función-de-riesgo-acumulado-el-estimador-de-aalen-nelson",
    "title": "5  TEMA 5: ANÁLISIS DE SUPERVIVENCIA",
    "section": "5.5 Estimación estadística de la función de riesgo acumulado: el estimador de Aalen Nelson",
    "text": "5.5 Estimación estadística de la función de riesgo acumulado: el estimador de Aalen Nelson\nOtra función importante en el análisis de supervivencia es la función de riesgo acumulado \\(H(t)\\), que se define como: \\[H(t) = \\int_0^t h(u) du.\\] El estimador de Aalen-Nelson es un estimador no paramétrico de la función de riesgo acumulado \\(H(t)\\), definido como: \\[\\hat{H}(t) = \\sum_{j:y_{(j)} \\le t} \\frac{d_{(j)}}{R_{(j)}},\\] donde \\(d_{(j)}\\) es el número de eventos en el tiempo \\(y_{(j)}\\) y \\(R_{(j)}\\) es el número de individuos en riesgo justo antes del tiempo \\(y_{(j)}\\). El estimador de Aalen-Nelson se interpreta como la suma acumulativa de las tasas de eventos observadas en cada tiempo de evento distinto hasta el tiempo \\(t\\). Es una función escalonada que aumenta en cada tiempo de evento distinto. El estimador de Aalen-Nelson se puede calcular fácilmente en R utilizando la función survfit() del paquete {survival}. Aquí hay un ejemplo utilizando el conjunto de datos tongue del paquete {KMsurv}:\n\n# cargar datos\nlibrary(KMsurv)\ndata(tongue)\n# previsualizar datos\nhead(tongue)\n\n  type time delta\n1    1    1     1\n2    1    3     1\n3    1    3     1\n4    1    4     1\n5    1   10     1\n6    1   13     1\n\n# ajustar el modelo de supervivencia\nfit &lt;- survfit(Surv(time, delta) ~ 1, data = tongue)\n# calcular el estimador de Aalen-Nelson\naalen_nelson &lt;- cumsum(fit$n.event / fit$n.risk)\n# gráfico del estimador de Aalen-Nelson\nplot(fit$time, aalen_nelson,\n     type = \"s\",\n     xlab = \"Tiempo\",\n     ylab = \"Función de riesgo acumulado\",\n     main = \"Estimador de Aalen-Nelson\")\n\n\n\n\n\n\n\n\nComo puedes ver, el estimador de Aalen-Nelson proporciona una estimación de la función de riesgo acumulado a lo largo del tiempo. La función de riesgo acumulado es útil para comprender la probabilidad acumulada de que ocurra un evento a lo largo del tiempo y puede ser utilizada en conjunto con otras funciones de supervivencia para obtener una visión más completa del proceso de supervivencia.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>TEMA 5: ANÁLISIS DE SUPERVIVENCIA</span>"
    ]
  },
  {
    "objectID": "TEMA-5.html#modelado-de-datos-de-supervivencia-el-modelo-de-riesgos-proporcionales-de-cox",
    "href": "TEMA-5.html#modelado-de-datos-de-supervivencia-el-modelo-de-riesgos-proporcionales-de-cox",
    "title": "5  TEMA 5: ANÁLISIS DE SUPERVIVENCIA",
    "section": "5.6 Modelado de datos de supervivencia: el modelo de riesgos proporcionales de Cox",
    "text": "5.6 Modelado de datos de supervivencia: el modelo de riesgos proporcionales de Cox\nComo habrás notado, no mostramos cómo modelar datos de supervivencia. Existen varios modelos de regresión que se pueden aplicar a los datos de supervivencia, siendo el más común el semiparamétrico o Modelo de riesgos proporcionales de Cox. Este modelo asume que la función de riesgo de un individuo es el producto de una función de riesgo base (que depende del tiempo pero no de las covariables) y un término que depende de las covariables pero no del tiempo. La suposición clave es que las razones de riesgos entre dos individuos son constantes a lo largo del tiempo (de ahí el término “proporcionales”). Este modelo es muy flexible y ampliamente utilizado en análisis de supervivencia.[3]\nLa Regresión de Cox es un método esencial en la Medicina para analizar el tiempo de supervivencia hasta que ocurre un evento de interés (como la muerte, la recurrencia de una enfermedad, o el alta hospitalaria). Permite evaluar el efecto de múltiples variables (covariables) sobre el riesgo (o hazard) de que ocurra el evento.\nCon el modelo de Cox, modelamos el impacto de diferentes factores \\(X_1, X_2, \\ldots, X_q\\) en la supervivencia a través de su impacto en la función de riesgo:\n\\[h(t|\\textbf{X}) = h_0 (t) \\exp(\\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_q X_q),\\] donde:\n\n\\(h(t|\\textbf{X})\\) es la tasa instantánea de muerte (o riesgo instantáneo) condicionada a haber sobrevivido hasta el tiempo \\(t\\).\n\\(h_0 (t)\\) es el riesgo basal a nivel poblacional, es decir, la función de riesgo subyacente. Describe cómo evoluciona el riesgo de una persona promedio a lo largo del tiempo.\n\\(\\exp(\\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_q X_q)\\) describe cómo las covariables afectan al riesgo. En particular, un aumento de una unidad en \\(x_i\\) multiplica el riesgo por un factor de \\(\\exp(\\beta_i)\\).\n\n\n5.6.1 Ejemplo modelo de Cox en oncología médica\nEl modelo de Cox se puede ajustar fácilmente en R utilizando la función coxph() del paquete {survival}. A continuación, te presento un ejemplo contextualizado en oncología médica. Este ejemplo simula el análisis del tiempo hasta la recurrencia del cáncer en pacientes, evaluando el efecto de la Edad y el Estadio del tumor al momento del diagnóstico. El contexto Médico es el siguiente:\nObjetivo: Determinar qué factores (Edad y Estadio del tumor) influyen en el tiempo que transcurre hasta la recurrencia del cáncer de mama en una cohorte de pacientes.\nVariables:\n-Tiempo (en meses): Tiempo de seguimiento hasta la recurrencia o la censura. -Evento (0/1): 1 si ocurrió la recurrencia, 0 si fue censurado (p.ej., el paciente se perdió en el seguimiento o el estudio terminó). -Edad (años): Edad de la paciente al diagnóstico (variable continua). -Estadio (I, II, III): Estadio del tumor al diagnóstico (variable categórica).\nEl análisis de supervivencia mediante la Regresión de Cox se emplea para modelar el tiempo transcurrido hasta un evento, permitiendo la inclusión de covariables. En este estudio, examinaremos la influencia de la edad y el estadio del tumor sobre el tiempo hasta la recurrencia del cáncer.\nCargamos los paquetes necesarios y preparamos datos de ejemplo (utilizaremos un conjunto de datos simulado o uno disponible en un paquete para la demostración).\nVisualizamos la supervivencia por grupos para entender las diferencias crudas antes del ajuste de Cox.\n\n# Crear el objeto de supervivencia\nsurv_object &lt;- Surv(time = datos$Tiempo, event = datos$Evento)\n# Ajuste de Kaplan-Meier por Estadio\nfit_km &lt;- survfit(surv_object ~ Estadio, data = datos)\n\n# Gráfico\nggsurvplot(\n  fit_km,\n  data = datos,\n  pval = TRUE,\n  risk.table = TRUE,\n  legend.title = \"Estadio\",\n  title = \"Curva de Supervivencia de Kaplan-Meier por Estadio del Tumor\",\n  xlab = \"Tiempo de Seguimiento (meses)\",\n  ylab = \"Probabilidad de Supervivencia\"\n)\n\n\n\n\n\n\n\n\nAjustamos el modelo de Cox para estimar los Hazard Ratios (HR) ajustando por la Edad y el Estadio.\n\n# Ajustar el modelo de Cox\nmodelo_cox &lt;- coxph(surv_object ~ Edad + Estadio, data = datos)\n\n# Resumen del modelo\nsummary(modelo_cox)\n\nCall:\ncoxph(formula = surv_object ~ Edad + Estadio, data = datos)\n\n  n= 227, number of events= 164 \n\n              coef exp(coef) se(coef)     z Pr(&gt;|z|)    \nEdad       0.01101   1.01107  0.00938 1.173 0.240653    \nEstadioII  0.35786   1.43027  0.19884 1.800 0.071904 .  \nEstadioIII 0.86995   2.38680  0.22933 3.794 0.000149 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n           exp(coef) exp(-coef) lower .95 upper .95\nEdad           1.011     0.9891    0.9926     1.030\nEstadioII      1.430     0.6992    0.9686     2.112\nEstadioIII     2.387     0.4190    1.5227     3.741\n\nConcordance= 0.61  (se = 0.025 )\nLikelihood ratio test= 18.73  on 3 df,   p=3e-04\nWald test            = 19.52  on 3 df,   p=2e-04\nScore (logrank) test = 20.37  on 3 df,   p=1e-04\n\n\n\n\n5.6.2 Gráfico de Incidencia Acumulada\nEl gráfico de incidencia acumulada es simplemente el complemento de la función de supervivencia: \\(1 - S(t)\\). Representa la probabilidad acumulada de que el evento (recurrencia) haya ocurrido en el tiempo \\(t\\).\n\n# Crear una función para la Incidencia Acumulada: 1 - S(t)\n# Esto invierte las curvas del gráfico anterior.\nggsurvplot(\n  fit_km,\n  data = datos,\n  fun = \"event\", # La función \"event\" grafica la Incidencia Acumulada (1-S(t))\n  conf.int = TRUE,\n  pval = FALSE,\n  risk.table = TRUE,\n  legend.title = \"Estadio\",\n  title = \"Incidencia Acumulada de Recurrencia Ajustada por Modelo de Cox\",\n  xlab = \"Tiempo de Seguimiento (meses)\",\n  ylab = \"Probabilidad de Recurrencia Acumulada (F(t))\",\n  ylim = c(0, 1) # Asegurar el eje y de 0 a 1\n)\n\n\n\n\n\n\n\n\n\n\n5.6.3 Interpretación de Resultados\nEl resumen del modelo muestra los coeficientes (\\(\\beta\\)), los Errores Estándar (se(coef)), el estadístico de Wald, el valor p y el Hazard Ratio (\\(e^{\\beta}\\)) o HR con sus intervalos de confianza.\n\n# Extraer coeficientes y HRs de forma limpia\nresultados_cox &lt;- as.data.frame(summary(modelo_cox)$coefficients)\nresultados_cox$HR &lt;- exp(resultados_cox$`coef`)\nresultados_cox$`IC 95% Inferior` &lt;- exp(resultados_cox$`coef` - 1.96 * resultados_cox$`se(coef)`)\nresultados_cox$`IC 95% Superior` &lt;- exp(resultados_cox$`coef` + 1.96 * resultados_cox$`se(coef)`)\nknitr::kable(\n  resultados_cox %&gt;% select(`HR`, `z`, `Pr(&gt;|z|)`, `IC 95% Inferior`, `IC 95% Superior`),\n  caption = \"Resultados de la Regresión de Cox (Riesgos Proporcionales)\",\n  digits = 3\n)\n\n\nResultados de la Regresión de Cox (Riesgos Proporcionales)\n\n\n\n\n\n\n\n\n\n\n\nHR\nz\nPr(&gt;|z|)\nIC 95% Inferior\nIC 95% Superior\n\n\n\n\nEdad\n1.011\n1.173\n0.241\n0.993\n1.030\n\n\nEstadioII\n1.430\n1.800\n0.072\n0.969\n2.112\n\n\nEstadioIII\n2.387\n3.794\n0.000\n1.523\n3.741\n\n\n\n\n\n\n\n5.6.4 Conclusiones\n\nEdad: Por cada aumento de un año en la edad del paciente, el riesgo de recurrencia (HR) es de aproximadamente \\(HR_{Edad}\\). Un valor de \\(HR_{Edad} &gt; 1\\) (y con \\(p &lt; 0.05\\)) indica que ser mayor aumenta el riesgo.\nEstadio (Categorías):\nEstadio II vs. I (Referencia): El riesgo de recurrencia en pacientes con Estadio II es \\(HR_{Estadio II}\\) veces el riesgo de los pacientes con Estadio I, manteniendo la edad constante.\nEstadio III vs. I (Referencia): El riesgo de recurrencia en pacientes con Estadio III es \\(HR_{Estadio III}\\) veces el riesgo de los pacientes con Estadio I, manteniendo la edad constante.\n\nLa interpretación de los Hazard Ratios (\\(HR\\)) es la clave:\n\n\\(HR &gt; 1\\): La covariable aumenta el riesgo de recurrencia.\n\\(HR &lt; 1\\): La covariable disminuye el riesgo de recurrencia.\n\\(HR = 1\\): La covariable no tiene efecto sobre el riesgo.\n\n\n\n5.6.5 Verificación del Supuesto de Riesgos Proporcionales (RP)\nEl modelo de Cox asume que el Hazard Ratio es constante a lo largo del tiempo. Esto se verifica con el test de los residuos de Schoenfeld.\n\n# Test del supuesto de RP\ntest_rp &lt;- cox.zph(modelo_cox)\nprint(test_rp)\n\n        chisq df    p\nEdad    0.319  1 0.57\nEstadio 2.249  2 0.32\nGLOBAL  2.302  3 0.51\n\n# Gráfico de los residuos de Schoenfeld\nggcoxzph(test_rp, caption = \"Gráfico de Residuos de Schoenfeld para el Test de Riesgos Proporcionales\")\n\n\n\n\n\n\n\n\nSi el p-valor global (\\(p &gt; 0.05\\)) en el test de los residuos de Schoenfeld, se asume que se cumple el supuesto de Riesgos Proporcionales. Los residuos deben mostrar una línea horizontal sin tendencias claras.\n\n\n5.6.6 Narrativo para publicación científica:\nEn un análisis de supervivencia utilizando el modelo de riesgos proporcionales de Cox, se evaluó el impacto de la edad y el estadio del tumor en el tiempo hasta la recurrencia del cáncer de mama en una cohorte de pacientes.\nLos resultados indicaron que por cada aumento de un año en la edad, el riesgo de recurrencia aumentó en un factor de 1.011 (HR; IC 95%: [0.993, 1.030], p = 0.241). Además, los pacientes con Estadio II presentaron un riesgo de recurrencia 1.430 veces mayor (HR; IC 95%: [0.969, 2.112], p = 0.072) en comparación con aquellos en Estadio I, si bien este efecto NO fue significativo. De manera similar, los pacientes en Estadio III mostraron un riesgo estadísticamente significativamente elevado de recurrencia, con un HR de 2.387 (IC 95%: [1.523, 3.741], p = &lt;0.001) en comparación con los pacientes en Estadio I.\nEl gráfico de incidencia acumulada confirmó que la probabilidad acumulada de recurrencia era considerablemente mayor y se alcanzaba más rápidamente en pacientes con estadios más avanzados (Estadio III), en comparación con los estadios I y II. El supuesto de riesgos proporcionales fue verificado y no se encontró evidencia de violación (p-global = 0.512). Estos hallazgos sugieren que tanto la edad como el estadio del tumor son factores críticos que influyen en la probabilidad de recurrencia del cáncer de mama.\n\n\n5.6.7 Ejemplo extendido:\nAmpliamos el ejemplo de Regresión de Cox para incluir una variable categórica adicional, un término de interacción y, crucialmente, el gráfico de incidencia acumulada (o función de supervivencia, que es su complemento).\nEl nuevo ejemplo contextualizado en oncología incluirá:\n\nVariable Categórica: Terapia Recibida (Quimioterapia vs. Radioterapia).\n\nInteracción: Edad * Estadio (para ver si el efecto de la edad en el riesgo de recurrencia depende del estadio del tumor).\n\nEn este ejemplo se modela el tiempo hasta la recurrencia del cáncer, evaluando el efecto de la Edad, el Estadio del tumor, la Terapia Recibida, y la interacción entre Edad y Estadio.\nVariables Adicionales:\n-Terapia (Quimio/Radio): Tipo de tratamiento primario (variable categórica/nominal).\n-Interacción Edad:Estadio: Evalúa si el efecto de la edad en el riesgo de recurrencia difiere en los Estadios II y III comparados con el Estadio I.\nCargamos los paquetes y preparamos los datos, añadiendo la variable Terapia para la demostración.\nAjustamos el modelo de Cox incluyendo la variable categórica Terapia y el término de interacción Edad:Estadio. El término Edad * Estadio es una forma abreviada en R para incluir los efectos principales (Edad + Estadio) y el término de interacción (Edad:Estadio).\n\n# Objeto de supervivencia\nsurv_object &lt;- Surv(time = datos_ext$Tiempo, event = datos_ext$Evento)\n\n# Ajustar el modelo de Cox con interacción y la nueva variable categórica\nmodelo_cox_int &lt;- coxph(surv_object ~ Edad * Estadio + Terapia, data = datos_ext)\n\n# Resumen del modelo\nsummary(modelo_cox_int)\n\nCall:\ncoxph(formula = surv_object ~ Edad * Estadio + Terapia, data = datos_ext)\n\n  n= 227, number of events= 164 \n\n                         coef exp(coef) se(coef)      z Pr(&gt;|z|)   \nEdad                  0.05309   1.05453  0.02233  2.377  0.01744 * \nEstadioII             3.78339  43.96466  1.62346  2.330  0.01978 * \nEstadioIII            3.86698  47.79776  1.97229  1.961  0.04992 * \nTerapiaQuimioterapia  0.52566   1.69157  0.17473  3.008  0.00263 **\nEdad:EstadioII       -0.05374   0.94768  0.02532 -2.122  0.03383 * \nEdad:EstadioIII      -0.04665   0.95442  0.03028 -1.541  0.12336   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                     exp(coef) exp(-coef) lower .95 upper .95\nEdad                    1.0545    0.94829    1.0094    1.1017\nEstadioII              43.9647    0.02275    1.8248 1059.2372\nEstadioIII             47.7978    0.02092    1.0014 2281.5031\nTerapiaQuimioterapia    1.6916    0.59117    1.2010    2.3824\nEdad:EstadioII          0.9477    1.05520    0.9018    0.9959\nEdad:EstadioIII         0.9544    1.04775    0.8994    1.0128\n\nConcordance= 0.654  (se = 0.025 )\nLikelihood ratio test= 34.78  on 6 df,   p=5e-06\nWald test            = 31.44  on 6 df,   p=2e-05\nScore (logrank) test = 33.35  on 6 df,   p=9e-06\n\n\nEl modelo incluye 7 coeficientes (log-HRs):\n\nEfectos Principales: Edad, EstadioII, EstadioIII, TerapiaQuimioterapia.\nInteracciones: Edad:EstadioII, Edad:EstadioIII.\n\n\n\n\n\n\n\n\nCoeficiente\nInterpretación \\(\\mathbf{e^{\\beta}}\\)\n\n\n\n\nEdad\nHR de la edad para pacientes con Estadio I y Radioterapia (grupo de referencia).\n\n\nEstadioII\nHR de un paciente con Estadio II frente a uno con Estadio I, cuando la Edad = 0 (aunque esto no es clínicamente interpretable, establece la línea base).\n\n\nTerapiaQuimioterapia\nHR de recibir Quimioterapia frente a Radioterapia, para un paciente con Estadio I y Edad = 0.\n\n\nEdad:EstadioII\nEl cambio en el log-HR de la Edad por cada año adicional, si el paciente es Estadio II frente a Estadio I.\n\n\n\nUn p-valor bajo para el término de interacción (Edad:EstadioII o Edad:EstadioIII) sugiere que el efecto de la Edad sobre el riesgo de recurrencia es significativamente diferente según el estadio.\nPodemos usar el modelo de Cox para predecir la curva de supervivencia (Probabilidad de Supervivencia) para diferentes perfiles de pacientes.\n\n5.6.7.1 Curvas de Supervivencia Ajustadas (Edad promedio)\nPredeciremos las curvas de supervivencia (probabilidad de no recurrencia) para cada estadio, manteniendo la edad en su promedio y asumiendo una terapia específica.\n\n# 1. Definir los nuevos datos para la predicción\nmedia_edad &lt;- mean(datos_ext$Edad)\nnuevos_datos &lt;- with(datos_ext,\n                     data.frame(\n                       Estadio = factor(levels(Estadio), levels = levels(Estadio)),\n                       Edad = rep(media_edad, 3),\n                       Terapia = factor(\"Quimioterapia\", levels = levels(Terapia)) # Fijamos Terapia en Quimioterapia\n                     ))\n\n# 2. Calcular las curvas de supervivencia ajustadas\nfit_cox_ajustado &lt;- survfit(modelo_cox_int, newdata = nuevos_datos)\n\n# 3. Graficar\nggsurvplot(\n  fit_cox_ajustado,\n  data = nuevos_datos,\n  conf.int = TRUE,\n  pval = FALSE,\n  risk.table = TRUE,\n  legend.title = \"Estadio\",\n  title = \"Probabilidad de Supervivencia Ajustada\",\n  xlab = \"Tiempo de Seguimiento (meses)\",\n  ylab = \"Probabilidad de Supervivencia (S(t))\"\n)\n\n\n\n\n\n\n\n\n\n\n5.6.7.2 Gráfico de Incidencia Acumulada Ajustada\nEl gráfico de incidencia acumulada es simplemente el complemento de la función de supervivencia: \\(1 - S(t)\\). Representa la probabilidad acumulada de que el evento (recurrencia) haya ocurrido en el tiempo \\(t\\).\n\n# Crear una función para la Incidencia Acumulada: 1 - S(t)\n# Esto invierte las curvas del gráfico anterior.\nggsurvplot(\n  fit_cox_ajustado,\n  data = nuevos_datos,\n  fun = \"event\", # La función \"event\" grafica la Incidencia Acumulada (1-S(t))\n  conf.int = TRUE,\n  pval = FALSE,\n  risk.table = TRUE,\n  legend.title = \"Estadio (Edad promedio)\",\n  title = \"Incidencia Acumulada Ajustada\",\n  xlab = \"Tiempo de Seguimiento (meses)\",\n  ylab = \"Probabilidad de Recurrencia Acumulada (F(t))\",\n  ylim = c(0, 1) # Asegurar el eje y de 0 a 1\n)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>TEMA 5: ANÁLISIS DE SUPERVIVENCIA</span>"
    ]
  }
]